

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/background/%E5%9B%BE%E6%A0%87.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="文晋">
  <meta name="keywords" content="">
  
    <meta name="description" content="1 安装1.1 虚拟环境12345conda create -n rerank python&#x3D;3.10 -yconda activate rerankconda install -c conda-forge openjdk&#x3D;21 maven -yconda install -c pytorch faiss-cpu -ypip install pyserini numpy&#x3D;&#x3D;1.26.4 torch">
<meta property="og:type" content="article">
<meta property="og:title" content="【趣味研究】Embedding Rerank">
<meta property="og:url" content="http://xuan-van.github.io/67e5abea4c9d/index.html">
<meta property="og:site_name" content="文心晋意">
<meta property="og:description" content="1 安装1.1 虚拟环境12345conda create -n rerank python&#x3D;3.10 -yconda activate rerankconda install -c conda-forge openjdk&#x3D;21 maven -yconda install -c pytorch faiss-cpu -ypip install pyserini numpy&#x3D;&#x3D;1.26.4 torch">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://xuan-van.github.io/67e5abea4c9d/1.png">
<meta property="og:image" content="http://xuan-van.github.io/67e5abea4c9d/2.png">
<meta property="og:image" content="http://xuan-van.github.io/67e5abea4c9d/3.png">
<meta property="og:image" content="http://xuan-van.github.io/67e5abea4c9d/4.png">
<meta property="article:published_time" content="2025-06-15T04:00:00.000Z">
<meta property="article:modified_time" content="2025-09-27T04:49:41.996Z">
<meta property="article:author" content="文晋">
<meta property="article:tag" content="RAG">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://xuan-van.github.io/67e5abea4c9d/1.png">
  
  
  
  <title>【趣味研究】Embedding Rerank - 文心晋意</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/background/background.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"xuan-van.github.io","root":"/","version":"1.9.8","typing":{"enable":false,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":3},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body><!-- hexo injector body_begin start --><div id="web_bg"></div><!-- hexo injector body_begin end -->
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>文晋的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-image"></i>
                <span>图片</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/images/llama.svg" target="_self">
                    
                    <span>Llama 结构</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/images/rag.svg" target="_self">
                    
                    <span>多跳问答难点</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">【趣味研究】Embedding Rerank</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-06-15 12:00" pubdate>
          2025年6月15日 中午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          4.5k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          38 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar category-bar" style="margin-right: -1rem">
    





<div class="category-list">
  
  
    
    
    
    <div class="category row nomargin-x">
      <a class="category-item 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="研究实践"
        id="heading-47ec0b0984bb15945aeca500b8fbbc73" role="tab" data-toggle="collapse" href="#collapse-47ec0b0984bb15945aeca500b8fbbc73"
        aria-expanded="true"
      >
        研究实践
        <span class="list-group-count">(6)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-47ec0b0984bb15945aeca500b8fbbc73"
           role="tabpanel" aria-labelledby="heading-47ec0b0984bb15945aeca500b8fbbc73">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/566326cfdd99/" title="【Java面向对象程序设计】双色球福利彩票系统"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【Java面向对象程序设计】双色球福利彩票系统</span>
        </a>
      
    
      
      
        <a href="/4dbd2d8100b8/" title="【多元关系抽取】基于大语言模型的地质实体多元关系抽取框架"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【多元关系抽取】基于大语言模型的地质实体多元关系抽取框架</span>
        </a>
      
    
      
      
        <a href="/ba2bb03ca55b/" title="【数据准备】常用问答数据集"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【数据准备】常用问答数据集</span>
        </a>
      
    
      
      
        <a href="/5306a0f67226/" title="【时间序列预测】基于深度学习的多变量时间序列预测家庭电力消耗"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【时间序列预测】基于深度学习的多变量时间序列预测家庭电力消耗</span>
        </a>
      
    
      
      
        <a href="/67e5abea4c9d/" title="【趣味研究】Embedding Rerank"
           class="list-group-item list-group-item-action
           active">
          <span class="category-post">【趣味研究】Embedding Rerank</span>
        </a>
      
    
      
      
        <a href="/aa8d310c63ae/" title="【趣味研究】多跳问答的难点与挑战"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【趣味研究】多跳问答的难点与挑战</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
</div>


  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">【趣味研究】Embedding Rerank</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="1-安装"><a href="#1-安装" class="headerlink" title="1 安装"></a>1 安装</h1><h2 id="1-1-虚拟环境"><a href="#1-1-虚拟环境" class="headerlink" title="1.1 虚拟环境"></a>1.1 虚拟环境</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda create -n rerank python=3.10 -y<br>conda activate rerank<br>conda install -c conda-forge openjdk=21 maven -y<br>conda install -c pytorch faiss-cpu -y<br>pip install pyserini numpy==1.26.4 torch sentence_transformers nvitop accelerate vllm<br></code></pre></td></tr></table></figure>

<h2 id="1-2-模型和数据集"><a href="#1-2-模型和数据集" class="headerlink" title="1.2 模型和数据集"></a>1.2 模型和数据集</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">huggingface-cli download facebook/dpr-question_encoder-single-nq-base --local-dir model/DPR<br>huggingface-cli download --resume-download Salesforce/SFR-Embedding-Mistral --local-dir model/SFR-Embedding-Mistral<br>huggingface-cli download --token Your_token meta-llama/Meta-Llama-3-8B-Instruct --local-dir model/Llama-3-8B-Instruct<br></code></pre></td></tr></table></figure>

<p>数据集详见：<a href="https://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91instructrag/">【论文复现】InstructRAG</a></p>
<h1 id="2-数据准备"><a href="#2-数据准备" class="headerlink" title="2 数据准备"></a>2 数据准备</h1><h2 id="2-1-辅助工具"><a href="#2-1-辅助工具" class="headerlink" title="2.1 辅助工具"></a>2.1 辅助工具</h2><ol>
<li>读取 JSON&#x2F;JSONL 文件；</li>
<li>创建输出文件的目录。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> json<br><br><br><span class="hljs-comment"># 读取JSON/JSONL文件</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_json_data</span>(<span class="hljs-params">file_path</span>):<br>    <span class="hljs-keyword">if</span> file_path.endswith(<span class="hljs-string">&#x27;.json&#x27;</span>):<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-keyword">return</span> json.load(f)<br>    <span class="hljs-keyword">elif</span> file_path.endswith(<span class="hljs-string">&#x27;.jsonl&#x27;</span>):<br>        data = []<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>                data.append(json.loads(line))<br>        <span class="hljs-keyword">return</span> data<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;不支持的文件格式&quot;</span>)<br><br><br><span class="hljs-comment"># 确保输出文件的目录存在，不存在则创建</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ensure_directory_exists</span>(<span class="hljs-params">file_path</span>):<br>    directory = os.path.dirname(file_path)<br>    <span class="hljs-keyword">if</span> directory <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> os.path.exists(directory):<br>        os.makedirs(directory, exist_ok=<span class="hljs-literal">True</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;创建文件夹：<span class="hljs-subst">&#123;directory&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

<h2 id="2-2-检索相关文档"><a href="#2-2-检索相关文档" class="headerlink" title="2.2 检索相关文档"></a>2.2 检索相关文档</h2><ol>
<li>准备工作：读取数据集，选择检索模式，初始化检索器（第一次执行时会下载语料库）；</li>
<li>批量检索：对于每个样本，针对 <code>question</code> 字段到语料库中进行检索；</li>
<li>结果保存：每个样本添加 <code>contexts</code> 列表字段，其中的每个元素包含 <code>id</code> 和 <code>score</code> 两个子字段，分别表示文档序号和检索分数。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> timedelta<br><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> cpu_count<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> read_json_data, ensure_directory_exists<br><span class="hljs-keyword">from</span> pyserini.encode <span class="hljs-keyword">import</span> DprQueryEncoder<br><span class="hljs-keyword">from</span> pyserini.search.lucene <span class="hljs-keyword">import</span> LuceneSearcher<br><span class="hljs-keyword">from</span> pyserini.search.faiss <span class="hljs-keyword">import</span> FaissSearcher<br><span class="hljs-keyword">from</span> pyserini.search.hybrid <span class="hljs-keyword">import</span> HybridSearcher<br><br><br><span class="hljs-comment"># 初始化检索器</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">initialize_searchers</span>(<span class="hljs-params">mode</span>):<br>    <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;sparse&#x27;</span>:<br>        <span class="hljs-keyword">return</span> LuceneSearcher.from_prebuilt_index(<span class="hljs-string">&#x27;wikipedia-dpr&#x27;</span>)<br>    <span class="hljs-keyword">elif</span> mode == <span class="hljs-string">&#x27;dense&#x27;</span>:<br>        encoder = DprQueryEncoder(<span class="hljs-string">&quot;model/DPR&quot;</span>)<br>        <span class="hljs-keyword">return</span> FaissSearcher.from_prebuilt_index(<span class="hljs-string">&#x27;wikipedia-dpr-100w.dpr-single-nq&#x27;</span>, encoder)<br>    <span class="hljs-keyword">elif</span> mode == <span class="hljs-string">&#x27;hybrid&#x27;</span>:<br>        sparse_searcher = LuceneSearcher.from_prebuilt_index(<span class="hljs-string">&#x27;wikipedia-dpr&#x27;</span>)<br>        encoder = DprQueryEncoder(<span class="hljs-string">&quot;model/DPR&quot;</span>)<br>        dense_searcher = FaissSearcher.from_prebuilt_index(<span class="hljs-string">&#x27;wikipedia-dpr-100w.dpr-single-nq&#x27;</span>, encoder)<br>        <span class="hljs-keyword">return</span> HybridSearcher(dense_searcher, sparse_searcher)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f&quot;不支持的检索模式：<span class="hljs-subst">&#123;mode&#125;</span>&quot;</span>)<br><br><br><span class="hljs-comment"># 批量检索</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">batch_search</span>(<span class="hljs-params">searcher, data, mode, top_k</span>):<br>    n = <span class="hljs-built_in">len</span>(data)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;读取到 <span class="hljs-subst">&#123;n&#125;</span> 条数据&quot;</span>)<br><br>    start_time = time.time()<br><br>    <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;sparse&#x27;</span>:<br>        results = searcher.batch_search(<br>            queries=[item[<span class="hljs-string">&#x27;question&#x27;</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> data],<br>            qids=[<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)],<br>            k=top_k,<br>            threads=cpu_count()<br>        )<br>    <span class="hljs-keyword">elif</span> mode == <span class="hljs-string">&#x27;dense&#x27;</span>:<br>        results = searcher.batch_search(<br>            queries=[item[<span class="hljs-string">&#x27;question&#x27;</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> data],<br>            q_ids=[<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)],<br>            k=top_k,<br>            threads=cpu_count()<br>        )<br>    <span class="hljs-keyword">else</span>:<br>        results = searcher.batch_search(<br>            queries=[item[<span class="hljs-string">&#x27;question&#x27;</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> data],<br>            q_ids=[<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)],<br>            k0=args.top_k,<br>            k=args.top_k,<br>            threads=cpu_count()<br>        )<br><br>    end_time = time.time()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;检索完成，耗时 <span class="hljs-subst">&#123;timedelta(seconds=end_time - start_time)&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">return</span> results<br><br><br><span class="hljs-comment"># 解析命令行参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_args</span>():<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&quot;--input_file&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;输入文件路径&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--output_file&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;输出文件路径&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--top_k&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">200</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;每个问题检索的文档数量&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--mode&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, choices=[<span class="hljs-string">&#x27;sparse&#x27;</span>, <span class="hljs-string">&#x27;dense&#x27;</span>, <span class="hljs-string">&#x27;hybrid&#x27;</span>], default=<span class="hljs-string">&#x27;hybrid&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;检索模式：稀疏检索，密集检索，混合检索&quot;</span>)<br><br>    <span class="hljs-keyword">return</span> parser.parse_args()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    args = parse_args()<br><br>    <span class="hljs-comment"># 初始化检索器</span><br>    searcher = initialize_searchers(args.mode)<br><br>    <span class="hljs-comment"># 读取输入数据</span><br>    data = read_json_data(args.input_file)<br><br>    <span class="hljs-comment"># 批量检索</span><br>    results = batch_search(searcher, data, args.mode, args.top_k)<br><br>    <span class="hljs-comment"># 将检索结果添加到数据中</span><br>    <span class="hljs-keyword">for</span> idx, item <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(data):<br>        contexts = []<br>        <span class="hljs-keyword">for</span> hit <span class="hljs-keyword">in</span> results[<span class="hljs-built_in">str</span>(idx)]:<br>            contexts.append(&#123;<br>                <span class="hljs-string">&#x27;id&#x27;</span>: hit.docid,<br>                <span class="hljs-string">&#x27;score&#x27;</span>: hit.score<br>            &#125;)<br>        item[<span class="hljs-string">&#x27;contexts&#x27;</span>] = contexts<br><br>    <span class="hljs-comment"># 保存结果到输出文件</span><br>    ensure_directory_exists(args.output_file)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(args.output_file, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        json.dump(data, f, indent=<span class="hljs-number">4</span>, ensure_ascii=<span class="hljs-literal">False</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;处理完成，结果已保存到 <span class="hljs-subst">&#123;args.output_file&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

<h2 id="2-3-获取文档内容"><a href="#2-3-获取文档内容" class="headerlink" title="2.3 获取文档内容"></a>2.3 获取文档内容</h2><ol>
<li>准备工作：读取数据集，初始化检索器；</li>
<li>遍历处理：对于每个样本的 <code>contexts</code> 字段的每个元素，利用 <code>id</code> 字段获取文档的 <code>title</code> 和 <code>content</code>；</li>
<li>保存结果：对于每个样本的 <code>contexts</code> 字段的每个元素，保存 <code>title</code>、<code>content</code> 和 <code>score</code> 字段。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> read_json_data, ensure_directory_exists<br><span class="hljs-keyword">from</span> pyserini.search.lucene <span class="hljs-keyword">import</span> LuceneSearcher<br><br><br><span class="hljs-comment"># 解析命令行参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_args</span>():<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&quot;--input_file&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;输入文件路径&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--output_file&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;输出文件路径&quot;</span>)<br><br>    <span class="hljs-keyword">return</span> parser.parse_args()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    args = parse_args()<br><br>    <span class="hljs-comment"># 初始化检索器</span><br>    searcher = LuceneSearcher.from_prebuilt_index(<span class="hljs-string">&#x27;wikipedia-dpr&#x27;</span>)<br><br>    <span class="hljs-comment"># 读取输入数据</span><br>    data = read_json_data(args.input_file)<br><br>    <span class="hljs-comment"># 遍历每个对象并处理contexts字段</span><br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> tqdm(data, desc=<span class="hljs-string">&quot;Preprocess&quot;</span>):<br>        updated_contexts = []<br>        <span class="hljs-keyword">for</span> context <span class="hljs-keyword">in</span> item[<span class="hljs-string">&#x27;contexts&#x27;</span>]:<br>            content = json.loads(searcher.doc(context[<span class="hljs-string">&#x27;id&#x27;</span>]).raw())[<span class="hljs-string">&#x27;contents&#x27;</span>]  <span class="hljs-comment"># 获取文档内容</span><br>            title, content = content.split(<span class="hljs-string">&#x27;\n&#x27;</span>, <span class="hljs-number">1</span>)  <span class="hljs-comment"># 分割标题和内容</span><br>            updated_contexts.append(&#123;<br>                <span class="hljs-string">&#x27;title&#x27;</span>: title.strip(<span class="hljs-string">&#x27;&quot;&#x27;</span>),  <span class="hljs-comment"># 去除多余的引号</span><br>                <span class="hljs-string">&#x27;content&#x27;</span>: content,<br>                <span class="hljs-string">&#x27;score&#x27;</span>: context[<span class="hljs-string">&#x27;score&#x27;</span>]  <span class="hljs-comment"># 保留score字段</span><br>            &#125;)<br>        item[<span class="hljs-string">&#x27;contexts&#x27;</span>] = updated_contexts  <span class="hljs-comment"># 更新contexts字段</span><br><br>    <span class="hljs-comment"># 保存结果到输出文件</span><br>    ensure_directory_exists(args.output_file)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(args.output_file, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        json.dump(data, f, indent=<span class="hljs-number">4</span>, ensure_ascii=<span class="hljs-literal">False</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;处理完成，结果已保存到 <span class="hljs-subst">&#123;args.output_file&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

<h1 id="3-相关性评估"><a href="#3-相关性评估" class="headerlink" title="3 相关性评估"></a>3 相关性评估</h1><h2 id="3-1-评估文档是否相关"><a href="#3-1-评估文档是否相关" class="headerlink" title="3.1 评估文档是否相关"></a>3.1 评估文档是否相关</h2><ol>
<li>准备工作：读取数据集，加载模型，批量准备提示词（指令+问答+文档）；</li>
<li>批量推理：让 LLM 判断每个样本中 <code>context</code> 字段的每个文档和问答是否相关；</li>
<li>结果保存：每个样本的 <code>context</code> 列表中的每个元素添加 <code>relevance</code> 字段，记录每个文档是否相关。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> read_json_data, ensure_directory_exists<br><span class="hljs-keyword">from</span> vllm <span class="hljs-keyword">import</span> LLM, SamplingParams<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><br><span class="hljs-comment"># 创建提示模板</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_prompt</span>(<span class="hljs-params">question, answers, context, qa_pairs</span>):<br>    prompt = (<br>        <span class="hljs-string">&quot;Relevant means the passage contains information that helps to answer the question or supports one or more of the given answer choices.\nDetermine if the context is relevant to the question and answers.\nRespond with exactly one word: &#x27;Yes&#x27; or &#x27;No&#x27;.\n\n&quot;</span><br>        <span class="hljs-string">f&quot;Main Question: <span class="hljs-subst">&#123;question&#125;</span>\n&quot;</span><br>        <span class="hljs-string">f&quot;Main Answers: <span class="hljs-subst">&#123;<span class="hljs-string">&#x27;; &#x27;</span>.join(answers)&#125;</span>\n\n&quot;</span><br>    )<br><br>    <span class="hljs-comment"># 添加子问题和子答案</span><br>    <span class="hljs-keyword">if</span> qa_pairs <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(qa_pairs) &gt; <span class="hljs-number">0</span>:<br>        prompt += <span class="hljs-string">&quot;Main Question has their Sub-questions and answers:\n\n&quot;</span><br>        <span class="hljs-keyword">for</span> i, pair <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(qa_pairs, <span class="hljs-number">1</span>):<br>            prompt += (<br>                <span class="hljs-string">f&quot;Sub-question <span class="hljs-subst">&#123;i&#125;</span>: <span class="hljs-subst">&#123;pair[<span class="hljs-string">&#x27;question&#x27;</span>]&#125;</span>\n&quot;</span><br>                <span class="hljs-string">f&quot;Sub-answers <span class="hljs-subst">&#123;i&#125;</span>: <span class="hljs-subst">&#123;<span class="hljs-string">&#x27;; &#x27;</span>.join(pair[<span class="hljs-string">&#x27;answers&#x27;</span>])&#125;</span>\n\n&quot;</span><br>            )<br><br>    prompt += (<br>        <span class="hljs-string">f&quot;Context Title: <span class="hljs-subst">&#123;context[<span class="hljs-string">&#x27;title&#x27;</span>]&#125;</span>\n&quot;</span><br>        <span class="hljs-string">f&quot;Context Content: <span class="hljs-subst">&#123;context[<span class="hljs-string">&#x27;content&#x27;</span>]&#125;</span>\n\n&quot;</span><br>        <span class="hljs-string">&quot;Response:&quot;</span><br>    )<br><br>    <span class="hljs-keyword">return</span> prompt<br><br><span class="hljs-comment"># 判断结果是否为相关</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_relevance</span>(<span class="hljs-params">output</span>):<br>    text = output.strip().lower()<br>    <span class="hljs-keyword">return</span> text == <span class="hljs-string">&quot;yes&quot;</span><br><br><br><span class="hljs-comment"># 解析命令行参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_args</span>():<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&quot;--input_file&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;输入文件路径&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--output_file&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;输出文件路径&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--llm_path&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&quot;model/Llama-3-8B-Instruct&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;LLM模型路径&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--batch_size&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">64</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;批处理大小&quot;</span>)<br>    <span class="hljs-keyword">return</span> parser.parse_args()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    args = parse_args()<br><br>    data = read_json_data(args.input_file)<br><br>    llm = LLM(model=args.llm_path, tensor_parallel_size=torch.cuda.device_count())<br>    sampling_params = SamplingParams(temperature=<span class="hljs-number">0.0</span>, top_p=<span class="hljs-number">1.0</span>, max_tokens=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 批处理上下文</span><br>    all_requests = []<br>    request_indices = []  <span class="hljs-comment"># 记录 (data_index, context_index) 用于结果对应</span><br>    <span class="hljs-keyword">for</span> i, item <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(data):<br>        question = item[<span class="hljs-string">&quot;question&quot;</span>]<br>        answers = item[<span class="hljs-string">&quot;answers&quot;</span>]<br>        qa_pairs = item[<span class="hljs-string">&quot;qa_pairs&quot;</span>]<br>        <span class="hljs-keyword">for</span> j, context <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(item[<span class="hljs-string">&quot;contexts&quot;</span>]):<br>            prompt = build_prompt(question, answers, context, qa_pairs)<br>            all_requests.append(prompt)<br>            request_indices.append((i, j))<br><br>    <span class="hljs-comment"># 分批推理</span><br>    results = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(all_requests), args.batch_size)):<br>        batch_prompts = all_requests[i:i + args.batch_size]<br>        outputs = llm.generate(batch_prompts, sampling_params)<br>        results.extend(outputs)<br><br>    <span class="hljs-comment"># 写入 relevance 字段</span><br>    <span class="hljs-keyword">for</span> output, (data_idx, context_idx) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(results, request_indices):<br>        data[data_idx][<span class="hljs-string">&quot;contexts&quot;</span>][context_idx][<span class="hljs-string">&quot;relevance&quot;</span>] = parse_relevance(output.outputs[<span class="hljs-number">0</span>].text)<br><br>    <span class="hljs-comment"># 保存结果到文件</span><br>    ensure_directory_exists(args.output_file)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(args.output_file, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        json.dump(data, f, indent=<span class="hljs-number">4</span>, ensure_ascii=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>

<h2 id="3-2-评估答案召回率"><a href="#3-2-评估答案召回率" class="headerlink" title="3.2 评估答案召回率"></a>3.2 评估答案召回率</h2><ol>
<li>准备工作：读取数据集，对于每个样本，选择是否只保留 LLM 认为相关的文档；</li>
<li>批量评估：根据输入的文档 top 数，评估答案是否在这些文档中；</li>
<li>打印结果：打印答案召回率。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">import</span> string<br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Pool, cpu_count<br><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> partial<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> read_json_data<br><br><br><span class="hljs-comment"># 标准化答案文本</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalize_answer</span>(<span class="hljs-params">s</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">remove_articles</span>(<span class="hljs-params">text</span>):  <span class="hljs-comment"># 移除冠词（a, an, the）</span><br>        <span class="hljs-keyword">return</span> re.sub(<span class="hljs-string">r&quot;\b(a|an|the)\b&quot;</span>, <span class="hljs-string">&quot; &quot;</span>, text)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">white_space_fix</span>(<span class="hljs-params">text</span>):  <span class="hljs-comment"># 修复多余的空格，确保单词之间只有一个空格</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot; &quot;</span>.join(text.split())<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">remove_punc</span>(<span class="hljs-params">text</span>):  <span class="hljs-comment"># 移除所有标点符号</span><br>        exclude = <span class="hljs-built_in">set</span>(string.punctuation)<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>.join(ch <span class="hljs-keyword">for</span> ch <span class="hljs-keyword">in</span> text <span class="hljs-keyword">if</span> ch <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> exclude)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">lower</span>(<span class="hljs-params">text</span>):  <span class="hljs-comment"># 将文本转换为小写</span><br>        <span class="hljs-keyword">return</span> text.lower()<br><br>    <span class="hljs-comment"># 依次应用上述函数：小写化 -&gt; 移除标点 -&gt; 移除冠词 -&gt; 修复空格</span><br>    <span class="hljs-keyword">return</span> white_space_fix(remove_articles(remove_punc(lower(s))))<br><br><br><span class="hljs-comment"># 初始化合并后的答案列表</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">merge_answers</span>(<span class="hljs-params">item</span>):<br>    merged_answers = []<br><br>    <span class="hljs-comment"># 添加主 answers 中的答案（如果存在且不为空）</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;answers&quot;</span> <span class="hljs-keyword">in</span> item <span class="hljs-keyword">and</span> item[<span class="hljs-string">&quot;answers&quot;</span>]:<br>        merged_answers.extend(item[<span class="hljs-string">&quot;answers&quot;</span>])<br><br>    <span class="hljs-comment"># 添加 qa_pairs 中的答案（如果存在且不为空）</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;qa_pairs&quot;</span> <span class="hljs-keyword">in</span> item <span class="hljs-keyword">and</span> item[<span class="hljs-string">&quot;qa_pairs&quot;</span>]:<br>        <span class="hljs-keyword">for</span> qa_pair <span class="hljs-keyword">in</span> item[<span class="hljs-string">&quot;qa_pairs&quot;</span>]:<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;answers&quot;</span> <span class="hljs-keyword">in</span> qa_pair <span class="hljs-keyword">and</span> qa_pair[<span class="hljs-string">&quot;answers&quot;</span>]:<br>                merged_answers.extend(qa_pair[<span class="hljs-string">&quot;answers&quot;</span>])<br><br>    <span class="hljs-keyword">return</span> merged_answers<br><br><br><span class="hljs-comment"># 检查答案是否出现在任何段落中</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">check_answer_in_contexts</span>(<span class="hljs-params">item, top_k</span>):<br>    <span class="hljs-comment"># 获取所有可能的答案</span><br>    all_answers = merge_answers(item)<br>    all_answers = [normalize_answer(ans) <span class="hljs-keyword">for</span> ans <span class="hljs-keyword">in</span> all_answers <span class="hljs-keyword">if</span> ans.strip()]<br><br>    <span class="hljs-comment"># 如果没有任何答案，直接返回False</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> all_answers:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br><br>    <span class="hljs-comment"># 合并所有段落的文本（title + text）</span><br>    full_text = <span class="hljs-string">&quot; &quot;</span>.join([<br>        <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;p[<span class="hljs-string">&#x27;title&#x27;</span>]&#125;</span> <span class="hljs-subst">&#123;p[<span class="hljs-string">&#x27;content&#x27;</span>]&#125;</span>&quot;</span><br>        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> item[<span class="hljs-string">&quot;contexts&quot;</span>][:top_k]<br>    ])<br>    full_text = normalize_answer(full_text)<br><br>    <span class="hljs-comment"># 检查是否有任何一个答案出现在文本中</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">any</span>(ans <span class="hljs-keyword">in</span> full_text <span class="hljs-keyword">for</span> ans <span class="hljs-keyword">in</span> all_answers <span class="hljs-keyword">if</span> ans)<br><br><br><span class="hljs-comment"># 解析命令行参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_args</span>():<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&quot;input_file&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;输入文件路径&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--relevant&quot;</span>, action=<span class="hljs-string">&quot;store_true&quot;</span>, default=<span class="hljs-literal">False</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;仅处理相关问题（默认处理所有问题）&quot;</span>)<br><br>    <span class="hljs-keyword">return</span> parser.parse_args()<br><br><br><span class="hljs-comment"># 获取输入的数字列表</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_user_input</span>():<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        user_input = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;请输入一组数字（用空格隔开），默认 1 5 10 20 50 100 150 200：&quot;</span>)<br>        <span class="hljs-keyword">if</span> user_input.strip() == <span class="hljs-string">&quot;&quot;</span>:<br>            <span class="hljs-keyword">return</span> [<span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">50</span>, <span class="hljs-number">100</span>, <span class="hljs-number">150</span>, <span class="hljs-number">200</span>]<br>        <span class="hljs-keyword">try</span>:<br>            numbers = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, user_input.split()))<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">all</span>(<span class="hljs-number">1</span> &lt;= num &lt;= <span class="hljs-number">200</span> <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> numbers):<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;输入的数字必须在1到200之间，请重新输入&quot;</span>)<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">sorted</span>(numbers)<br>        <span class="hljs-keyword">except</span> ValueError:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;输入无效，请确保输入的是数字并用空格隔开&quot;</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    args = parse_args()<br><br>    <span class="hljs-comment"># 读取输入数据</span><br>    data = read_json_data(args.input_file)<br><br>    <span class="hljs-comment"># 仅保留相关问题</span><br>    <span class="hljs-keyword">if</span> args.relevant:<br>        data = [<br>            &#123;<br>                **item,  <span class="hljs-comment"># 保留其他字段</span><br>                <span class="hljs-string">&quot;contexts&quot;</span>: [context <span class="hljs-keyword">for</span> context <span class="hljs-keyword">in</span> item[<span class="hljs-string">&quot;contexts&quot;</span>] <span class="hljs-keyword">if</span> context.get(<span class="hljs-string">&quot;relevance&quot;</span>, <span class="hljs-literal">False</span>)]<br>            &#125;<br>            <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> data<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(context.get(<span class="hljs-string">&quot;relevance&quot;</span>, <span class="hljs-literal">False</span>) <span class="hljs-keyword">for</span> context <span class="hljs-keyword">in</span> item[<span class="hljs-string">&quot;contexts&quot;</span>])<br>        ]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;读取到 <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(data)&#125;</span> 条数据&quot;</span>)<br><br>    <span class="hljs-comment"># 获取输入的数字列表</span><br>    numbers = get_user_input()<br>    total_result = &#123;&#125;<br><br>    <span class="hljs-comment"># 使用多进程并行处理</span><br>    <span class="hljs-keyword">with</span> Pool(processes=cpu_count()) <span class="hljs-keyword">as</span> pool:<br>        <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> numbers:<br>            processor = partial(check_answer_in_contexts, top_k=num)<br>            results = <span class="hljs-built_in">list</span>(pool.imap(processor, data))<br>            total_result[num] = <span class="hljs-built_in">sum</span>(results) / <span class="hljs-built_in">len</span>(results)<br><br>    <span class="hljs-comment"># 打印结果</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;分析完成，共检查 <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(data)&#125;</span> 个可回答的问题&quot;</span>)<br>    <span class="hljs-keyword">for</span> num, result <span class="hljs-keyword">in</span> total_result.items():<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Recall@<span class="hljs-subst">&#123;num&#125;</span>: <span class="hljs-subst">&#123;result:<span class="hljs-number">.2</span>%&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

<h1 id="4-文档重排序"><a href="#4-文档重排序" class="headerlink" title="4 文档重排序"></a>4 文档重排序</h1><h2 id="4-1-Embedding-重排"><a href="#4-1-Embedding-重排" class="headerlink" title="4.1 Embedding 重排"></a>4.1 Embedding 重排</h2><p>核心思想：利用 LLM 的输入 Embedding Layer 的 Hidden States 之间的余弦相似度&#x2F;皮尔逊相关系数进行重排。</p>
<ol>
<li>准备工作：读取数据集，加载分词器和模型；</li>
<li>遍历处理：对于每个样本，构建文档输入（文档+指令+问题），获取每个文档和问题对应的 embedding（均值池化），计算余弦相似度&#x2F;皮尔逊相关系数；</li>
<li>保存结果：对于每个样本，更新 <code>contexts</code> 字段中每个文档的 <code>score</code>，并按其降序排序 <code>contexts</code>。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel, AutoTokenizer<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> read_json_data, ensure_directory_exists<br><br><br><span class="hljs-comment"># 构造模型输入</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">construct_model_input</span>(<span class="hljs-params">item</span>):<br>    sorted_contexts = <span class="hljs-built_in">sorted</span>(item[<span class="hljs-string">&#x27;contexts&#x27;</span>], key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&#x27;score&#x27;</span>])<br>    sub_texts = [<span class="hljs-string">&quot;&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;&quot;</span>]<br>    <span class="hljs-keyword">for</span> i, context <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sorted_contexts):<br>        chunk = <span class="hljs-string">f&quot;\n\nDocument <span class="hljs-subst">&#123;i + <span class="hljs-number">1</span>&#125;</span> (Title: <span class="hljs-subst">&#123;context[<span class="hljs-string">&#x27;title&#x27;</span>]&#125;</span>): <span class="hljs-subst">&#123;context[<span class="hljs-string">&#x27;content&#x27;</span>]&#125;</span>&quot;</span><br>        sub_texts.append(chunk)<br><br>    sub_texts += [<br>        <span class="hljs-string">&quot;\n\nBased on your knowledge and the provided information, answer the question:&quot;</span>,<br>        <span class="hljs-string">f&quot;\n<span class="hljs-subst">&#123;item[<span class="hljs-string">&#x27;question&#x27;</span>]&#125;</span>&quot;</span>,<br>        <span class="hljs-string">&quot;\n\n&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;&quot;</span><br>    ]<br>    <span class="hljs-keyword">return</span> sub_texts, sorted_contexts<br><br><br><span class="hljs-comment"># 查找子字符串在整个字符串中的起止位置</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">find_subtexts_positions</span>(<span class="hljs-params">sub_texts, tokenizer</span>):<br>    result = &#123;&#125;<br>    input_text = <span class="hljs-string">&quot;&quot;</span>.join(sub_texts)<br><br>    <span class="hljs-comment"># 获取整个输入文本的token位置映射</span><br>    encoding = tokenizer(input_text, return_offsets_mapping=<span class="hljs-literal">True</span>)<br>    offset_mapping = encoding[<span class="hljs-string">&quot;offset_mapping&quot;</span>]<br><br>    <span class="hljs-keyword">for</span> i, sub_text <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(sub_texts):<br>        <span class="hljs-comment"># 检查sub_text是否是input_text的子串</span><br>        <span class="hljs-keyword">if</span> sub_text <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> input_text:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f&quot;子文本&#x27;<span class="hljs-subst">&#123;i&#125;</span>&#x27;不在整个文本中&quot;</span>)<br><br>        <span class="hljs-comment"># 查找字符串位置</span><br>        start_char = input_text.find(sub_text)<br>        end_char = start_char + <span class="hljs-built_in">len</span>(sub_text)<br><br>        <span class="hljs-comment"># 查找token位置</span><br>        start_token = <span class="hljs-literal">None</span><br>        end_token = <span class="hljs-literal">None</span><br><br>        <span class="hljs-keyword">for</span> j, (start, end) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(offset_mapping):<br>            <span class="hljs-comment"># 检查token是否与子串的起始位置重叠</span><br>            <span class="hljs-keyword">if</span> start &lt;= start_char &lt; end <span class="hljs-keyword">and</span> start_token <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                start_token = j<br>            <span class="hljs-comment"># 检查token是否与子串的结束位置重叠</span><br>            <span class="hljs-keyword">if</span> start &lt; end_char &lt;= end <span class="hljs-keyword">and</span> end_token <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                end_token = j<br>                <span class="hljs-keyword">break</span>  <span class="hljs-comment"># 找到结束token后可以提前退出</span><br><br>        <span class="hljs-comment"># 确保找到了起始和结束token</span><br>        <span class="hljs-keyword">if</span> start_token <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> end_token <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f&quot;没能定位到子文本&#x27;<span class="hljs-subst">&#123;i&#125;</span>&#x27;的token序列位置&quot;</span>)<br><br>        <span class="hljs-comment"># 键: 字符串起止位置，值: token起止位置</span><br>        result[(start_char, end_char)] = [start_token, end_token]<br><br>    <span class="hljs-keyword">return</span> result<br><br><br><span class="hljs-comment"># 计算文档与问题的余弦相似度</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_score</span>(<span class="hljs-params">data, tokenizer, model, method</span>):<br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> tqdm(data, desc=<span class="hljs-string">&quot;Processing&quot;</span>):<br>        sub_texts, sorted_contexts = construct_model_input(item)<br>        input_text = <span class="hljs-string">&quot;&quot;</span>.join(sub_texts)<br>        positions = find_subtexts_positions(sub_texts, tokenizer)<br><br>        <span class="hljs-comment"># 将input_text转换为token id序列并获取embedding</span><br>        inputs = tokenizer(input_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).to(device)<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            embeddings = model.get_input_embeddings()(inputs.input_ids)<br><br>        <span class="hljs-comment"># 对每个sub_text获取其embedding的均值池化</span><br>        subtext_embeddings = &#123;&#125;<br>        <span class="hljs-keyword">for</span> (char_start, char_end), (token_start, token_end) <span class="hljs-keyword">in</span> positions.items():<br>            sub_embeddings = embeddings[<span class="hljs-number">0</span>, token_start:token_end+<span class="hljs-number">1</span>, :]<br>            mean_embedding = torch.mean(sub_embeddings, dim=<span class="hljs-number">0</span>)<br>            subtext_embeddings[(char_start, char_end)] = mean_embedding<br><br>        <span class="hljs-comment"># 分离出question和documents的embedding</span><br>        question_pos = <span class="hljs-built_in">list</span>(positions.keys())[-<span class="hljs-number">2</span>]<br>        question_embedding = subtext_embeddings[question_pos]<br><br>        <span class="hljs-keyword">for</span> doc_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sorted_contexts)):<br>            doc_pos = <span class="hljs-built_in">list</span>(positions.keys())[doc_idx + <span class="hljs-number">1</span>]<br>            doc_embedding = subtext_embeddings[doc_pos]<br>            <span class="hljs-keyword">if</span> method == <span class="hljs-string">&#x27;similarity&#x27;</span>:<br>                score = F.cosine_similarity(question_embedding.unsqueeze(<span class="hljs-number">0</span>), doc_embedding.unsqueeze(<span class="hljs-number">0</span>))<br>            <span class="hljs-keyword">else</span>:<br>                score = torch.corrcoef(torch.stack([question_embedding, doc_embedding]))[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]<br>            sorted_contexts[doc_idx][<span class="hljs-string">&#x27;score&#x27;</span>] = score.item()<br><br>        item[<span class="hljs-string">&#x27;contexts&#x27;</span>] = <span class="hljs-built_in">sorted</span>(sorted_contexts, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&#x27;score&#x27;</span>], reverse=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">return</span> data<br><br><br><span class="hljs-comment"># 解析命令行参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_args</span>():<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&quot;--input_file&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;输入文件路径&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--output_file&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;输出文件路径&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--model_path&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&quot;model/Llama-3-8B-Instruct&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;LLM模型路径&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--method&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, choices=[<span class="hljs-string">&#x27;similarity&#x27;</span>, <span class="hljs-string">&#x27;relevance&#x27;</span>], <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;排序得分计算方法&quot;</span>)<br><br>    <span class="hljs-keyword">return</span> parser.parse_args()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    args = parse_args()<br><br>    <span class="hljs-comment"># 读取输入数据</span><br>    data = read_json_data(args.input_file)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;读取到 <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(data)&#125;</span> 条数据&quot;</span>)<br><br>    <span class="hljs-comment"># 载入分词器和模型</span><br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>    tokenizer = AutoTokenizer.from_pretrained(args.model_path)<br>    model = AutoModel.from_pretrained(args.model_path).to(device).<span class="hljs-built_in">eval</span>()<br><br>    <span class="hljs-comment"># 更新分数</span><br>    updated_data = calculate_score(data, tokenizer, model, args.method)<br><br>    <span class="hljs-comment"># 保存结果到输出文件</span><br>    ensure_directory_exists(args.output_file)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(args.output_file, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        json.dump(updated_data, f, indent=<span class="hljs-number">4</span>, ensure_ascii=<span class="hljs-literal">False</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;处理完成，结果已保存到 <span class="hljs-subst">&#123;args.output_file&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

<h2 id="4-2-Attend-Embedding-重排"><a href="#4-2-Attend-Embedding-重排" class="headerlink" title="4.2 Attend Embedding 重排"></a>4.2 Attend Embedding 重排</h2><p>核心思想：将文档和问题进行向量化，输入 LLM 后利用注意力矩阵对 embedding 重新排序：</p>
<ul>
<li>为什么不使用 LLM 向量化：向量化速度慢，而且未经特定训练的 LLM 向量化效果差；</li>
<li>为什么选择均值池化的向量化方式：最后一层池化长文本鲁棒性差，CLS 池化表示语法结束符，而均值池化覆盖了句法和语义，有现成的第三方库；</li>
<li>为什么问题不选择 token 化，而是向量化：确保问题和文档的向量化方式一致。</li>
</ul>
<ol>
<li>准备工作：读取数据集，加载 LLM 和 Retriever 模型；</li>
<li>批量处理：Retriever 将文档和问题编码成 embdeeing 矩阵，输入 LLM 中，获取每个检索头的注意力矩阵的最后一行（from question embedding to every document），然后求和（shape: (1, 文档数)，排除了问题本身）；</li>
<li>保存结果：对于每个样本，更新 <code>contexts</code> 字段中每个文档的 <code>score</code> 为对应的注意力分数，并按其降序排序 <code>contexts</code>。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> read_json_data, ensure_directory_exists<br><span class="hljs-keyword">from</span> sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel<br><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process, Queue<br><br><br><span class="hljs-comment"># 获取最后一行的注意力分数之和</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_attention_sums</span>(<span class="hljs-params">outputs</span>):<br>    num_layers = <span class="hljs-built_in">len</span>(outputs.attentions)<br>    num_heads = outputs.attentions[<span class="hljs-number">0</span>].shape[<span class="hljs-number">1</span>]<br>    layer_head_pairs = [[layer_idx, head_idx]<br>                        <span class="hljs-keyword">for</span> layer_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_layers)<br>                        <span class="hljs-keyword">for</span> head_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_heads)]<br><br>    attention_sum = torch.zeros((<span class="hljs-number">1</span>, outputs.attentions[<span class="hljs-number">0</span>].shape[-<span class="hljs-number">1</span>]), device=outputs.attentions[<span class="hljs-number">0</span>].device)<br><br>    <span class="hljs-keyword">for</span> layer_idx, head_idx <span class="hljs-keyword">in</span> layer_head_pairs:<br>        attention_sum += outputs.attentions[layer_idx][<span class="hljs-number">0</span>, head_idx, -<span class="hljs-number">1</span>, :].unsqueeze(<span class="hljs-number">0</span>)<br><br>    <span class="hljs-keyword">return</span> attention_sum  <span class="hljs-comment"># 形状: (1, seq_len)</span><br><br><br><span class="hljs-comment"># 并行处理数据</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">worker</span>(<span class="hljs-params">data_chunk, gpu_pair_idx, retriever_path, llm_path, result_queue</span>):<br>    device_retriever = <span class="hljs-string">f&#x27;cuda:<span class="hljs-subst">&#123;<span class="hljs-number">2</span> * gpu_pair_idx&#125;</span>&#x27;</span><br>    device_llm = <span class="hljs-string">f&#x27;cuda:<span class="hljs-subst">&#123;<span class="hljs-number">2</span> * gpu_pair_idx + <span class="hljs-number">1</span>&#125;</span>&#x27;</span><br><br>    retriever = SentenceTransformer(retriever_path, device=device_retriever).<span class="hljs-built_in">eval</span>()<br>    llm = AutoModel.from_pretrained(llm_path, output_attentions=<span class="hljs-literal">True</span>, device_map=&#123;<span class="hljs-string">&#x27;&#x27;</span>: device_llm&#125;).<span class="hljs-built_in">eval</span>()<br><br>    results = []<br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> tqdm(data_chunk, desc=<span class="hljs-string">f&quot;Worker <span class="hljs-subst">&#123;gpu_pair_idx&#125;</span>&quot;</span>, position=gpu_pair_idx):<br>        item[<span class="hljs-string">&#x27;contexts&#x27;</span>] = <span class="hljs-built_in">sorted</span>(item[<span class="hljs-string">&#x27;contexts&#x27;</span>], key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&#x27;score&#x27;</span>])<br>        contexts = [<span class="hljs-string">f&quot;Title: <span class="hljs-subst">&#123;c[<span class="hljs-string">&#x27;title&#x27;</span>]&#125;</span>\nContent: <span class="hljs-subst">&#123;c[<span class="hljs-string">&#x27;content&#x27;</span>]&#125;</span>&quot;</span> <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> item[<span class="hljs-string">&#x27;contexts&#x27;</span>]]<br>        contexts.append(<span class="hljs-string">f&#x27;Question: <span class="hljs-subst">&#123;item[<span class="hljs-string">&quot;question&quot;</span>]&#125;</span>&#x27;</span>)<br><br>        embeddings = retriever.encode(contexts, convert_to_tensor=<span class="hljs-literal">True</span>, batch_size=<span class="hljs-number">16</span>).unsqueeze(<span class="hljs-number">0</span>)<br><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            outputs = llm(inputs_embeds=embeddings.to(device_llm))<br><br>        attention_sums = get_attention_sums(outputs)<br>        context_attention = attention_sums[<span class="hljs-number">0</span>, :-<span class="hljs-number">1</span>]  <span class="hljs-comment"># 排除question自身</span><br><br>        <span class="hljs-keyword">for</span> i, context <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(item[<span class="hljs-string">&#x27;contexts&#x27;</span>]):<br>            context[<span class="hljs-string">&#x27;score&#x27;</span>] = context_attention[i].item()<br><br>        item[<span class="hljs-string">&#x27;contexts&#x27;</span>] = <span class="hljs-built_in">sorted</span>(item[<span class="hljs-string">&#x27;contexts&#x27;</span>], key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&#x27;score&#x27;</span>], reverse=<span class="hljs-literal">True</span>)<br>        results.append(item)<br><br>    result_queue.put(results)<br><br><br><span class="hljs-comment"># 解析命令行参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_args</span>():<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&quot;--input_file&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;输入文件路径&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--output_file&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;输出文件路径&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--llm_path&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&quot;model/Llama-3-8B-Instruct&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;LLM模型路径&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--retriever_path&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&quot;model/SFR-Embedding-Mistral&quot;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;Embedding模型路径&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--num_gpus&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=torch.cuda.device_count(), <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;使用的GPU数量&quot;</span>)<br>    <span class="hljs-keyword">return</span> parser.parse_args()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    args = parse_args()<br><br>    <span class="hljs-comment"># 检查GPU数量</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;使用 <span class="hljs-subst">&#123;args.num_gpus&#125;</span> 个GPU进行计算&quot;</span>)<br>    <span class="hljs-keyword">if</span> args.num_gpus % <span class="hljs-number">2</span> != <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;使用的GPU数量必须为偶数&quot;</span>)<br><br>    <span class="hljs-comment"># 读取输入数据</span><br>    data = read_json_data(args.input_file)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;读取到 <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(data)&#125;</span> 条数据&quot;</span>)<br><br>    num_proc = args.num_gpus // <span class="hljs-number">2</span><br>    chunk_size = (<span class="hljs-built_in">len</span>(data) + num_proc - <span class="hljs-number">1</span>) // num_proc<br>    result_queue = Queue()<br>    processes = []<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_proc):<br>        chunk = data[i * chunk_size: (i + <span class="hljs-number">1</span>) * chunk_size]<br>        p = Process(target=worker, args=(chunk, i, args.retriever_path, args.llm_path, result_queue))<br>        p.start()<br>        processes.append(p)<br><br>    all_results = []<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_proc):<br>        all_results.extend(result_queue.get())<br><br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> processes:<br>        p.join()<br><br>    <span class="hljs-comment"># 保存结果到输出文件</span><br>    ensure_directory_exists(args.output_file)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(args.output_file, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        json.dump(all_results, f, indent=<span class="hljs-number">4</span>, ensure_ascii=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>

<h1 id="5-研究结果"><a href="#5-研究结果" class="headerlink" title="5 研究结果"></a>5 研究结果</h1><h2 id="5-1-混合检索召回率"><a href="#5-1-混合检索召回率" class="headerlink" title="5.1 混合检索召回率"></a>5.1 混合检索召回率</h2><figure>
    <style>.xwavtjcmgnls{}</style><img src="/67e5abea4c9d/1.png" srcset="/img/loading.gif" lazyload class="xwavtjcmgnls" alt="混合检索召回率">
    <figcaption>不同数据集的不同 Top-K 的答案召回率</figcaption>
</figure>

<ol>
<li>随着 Top-K 的增加，所有数据集的答案召回率均呈上升趋势，但增长逐渐放缓。  </li>
<li>PopQA、NaturalQuestions、2WikiMultiHopQA 的训练集和测试集存在召回率差距。  </li>
<li>数据集间差异显著，ASQA 和 NaturalQuestions 召回率最高，2WikiMultiHopQA 最低，PopQA 与 TriviaQA 居中。</li>
</ol>
<h2 id="5-2-混合检索与-Embedding-重排"><a href="#5-2-混合检索与-Embedding-重排" class="headerlink" title="5.2 混合检索与 Embedding 重排"></a>5.2 混合检索与 Embedding 重排</h2><figure>
    <style>.hedlirxwsdkf{}</style><img src="/67e5abea4c9d/2.png" srcset="/img/loading.gif" lazyload class="hedlirxwsdkf" alt="混合检索与 Embedding 重排">
    <figcaption>不同数据集的不同方法的不同 Top-K 的答案召回率</figcaption>
</figure>

<h2 id="5-3-混合检索与稀疏检索"><a href="#5-3-混合检索与稀疏检索" class="headerlink" title="5.3 混合检索与稀疏检索"></a>5.3 混合检索与稀疏检索</h2><figure>
    <style>.xiftcxurxqkv{}</style><img src="/67e5abea4c9d/3.png" srcset="/img/loading.gif" lazyload class="xiftcxurxqkv" alt="混合检索与稀疏检索">
    <figcaption>测试集的不同方法的不同 Top-K 的答案召回率</figcaption>
</figure>

<h2 id="5-4-重排召回率"><a href="#5-4-重排召回率" class="headerlink" title="5.4 重排召回率"></a>5.4 重排召回率</h2><figure>
    <style>.msmfycetgdot{}</style><img src="/67e5abea4c9d/4.png" srcset="/img/loading.gif" lazyload class="msmfycetgdot" alt="重排召回率">
    <figcaption>测试集的不同方法的不同 Top-K 的答案召回率</figcaption>
</figure>

<h2 id="5-5-全部结果"><a href="#5-5-全部结果" class="headerlink" title="5.5 全部结果"></a>5.5 全部结果</h2><table>
<thead>
<tr>
<th>Dataset</th>
<th>Set</th>
<th>Retrieval</th>
<th>Rerank</th>
<th>Recall@1</th>
<th>Recall@5</th>
<th>Recall@10</th>
<th>Recall@20</th>
<th>Recall@50</th>
<th>Recall@100</th>
<th>Recall@150</th>
<th>Recall@200</th>
</tr>
</thead>
<tbody><tr>
<td>PopQA</td>
<td>Train</td>
<td>Hybrid</td>
<td>None</td>
<td>0.3269</td>
<td>0.5120</td>
<td>0.5868</td>
<td>0.6495</td>
<td>0.7230</td>
<td>0.7769</td>
<td>0.8122</td>
<td>0.8387</td>
</tr>
<tr>
<td>PopQA</td>
<td>Train</td>
<td>Hybrid</td>
<td>Embedding Similarity</td>
<td>0.2952</td>
<td>0.4867</td>
<td>0.5818</td>
<td>0.6724</td>
<td>0.7718</td>
<td>0.8154</td>
<td>0.8307</td>
<td>0.8387</td>
</tr>
<tr>
<td>PopQA</td>
<td>Test</td>
<td>Hybrid</td>
<td>None</td>
<td>0.3059</td>
<td>0.4496</td>
<td>0.4968</td>
<td>0.5475</td>
<td>0.6090</td>
<td>0.6776</td>
<td>0.7241</td>
<td>0.7548</td>
</tr>
<tr>
<td>PopQA</td>
<td>Test</td>
<td>Hybrid</td>
<td>Embedding Similarity</td>
<td>0.3753</td>
<td>0.5540</td>
<td>0.6054</td>
<td>0.6548</td>
<td>0.6998</td>
<td>0.7277</td>
<td>0.7455</td>
<td>0.7548</td>
</tr>
<tr>
<td>PopQA</td>
<td>Test</td>
<td>Hybrid</td>
<td>Embedding Relevance</td>
<td>0.3746</td>
<td>0.5540</td>
<td>0.6061</td>
<td>0.6548</td>
<td>0.7005</td>
<td>0.7277</td>
<td>0.7455</td>
<td>0.7548</td>
</tr>
<tr>
<td>PopQA</td>
<td>Test</td>
<td>Sparse</td>
<td>None</td>
<td>0.4196</td>
<td>0.5297</td>
<td>0.5726</td>
<td>0.6069</td>
<td>0.6455</td>
<td>0.6791</td>
<td>0.6941</td>
<td>0.7048</td>
</tr>
<tr>
<td>PopQA</td>
<td>Test</td>
<td>Sparse</td>
<td>Embedding Similarity</td>
<td>0.3417</td>
<td>0.4889</td>
<td>0.5440</td>
<td>0.5990</td>
<td>0.6512</td>
<td>0.6798</td>
<td>0.6891</td>
<td>0.7048</td>
</tr>
<tr>
<td>PopQA</td>
<td>Test</td>
<td>Hybrid</td>
<td>Attention Score</td>
<td>0.2773</td>
<td>0.4425</td>
<td>0.5111</td>
<td>0.5761</td>
<td>0.6576</td>
<td>0.7148</td>
<td>0.7420</td>
<td>0.7548</td>
</tr>
<tr>
<td>PopQA</td>
<td>Test</td>
<td>Hybrid</td>
<td>LLM Relevance</td>
<td>0.5293</td>
<td>0.6646</td>
<td>0.6978</td>
<td>0.7128</td>
<td>0.7342</td>
<td>0.7373</td>
<td>0.7389</td>
<td>0.7389</td>
</tr>
<tr>
<td>TriviaQA</td>
<td>Train</td>
<td>Hybrid</td>
<td>None</td>
<td>0.4339</td>
<td>0.6228</td>
<td>0.6829</td>
<td>0.7342</td>
<td>0.7923</td>
<td>0.8355</td>
<td>0.8637</td>
<td>0.8794</td>
</tr>
<tr>
<td>TriviaQA</td>
<td>Test</td>
<td>Hybrid</td>
<td>None</td>
<td>0.4302</td>
<td>0.6206</td>
<td>0.6814</td>
<td>0.7339</td>
<td>0.7881</td>
<td>0.8371</td>
<td>0.8671</td>
<td>0.8838</td>
</tr>
<tr>
<td>TriviaQA</td>
<td>Test</td>
<td>Hybrid</td>
<td>Embedding Similarity</td>
<td>0.3690</td>
<td>0.6174</td>
<td>0.7141</td>
<td>0.7853</td>
<td>0.8423</td>
<td>0.8668</td>
<td>0.8779</td>
<td>0.8838</td>
</tr>
<tr>
<td>TriviaQA</td>
<td>Test</td>
<td>Sparse</td>
<td>None</td>
<td>0.5024</td>
<td>0.6949</td>
<td>0.7489</td>
<td>0.7921</td>
<td>0.8321</td>
<td>0.8562</td>
<td>0.8671</td>
<td>0.8744</td>
</tr>
<tr>
<td>TriviaQA</td>
<td>Test</td>
<td>Sparse</td>
<td>Embedding Similarity</td>
<td>0.3273</td>
<td>0.5535</td>
<td>0.6430</td>
<td>0.7239</td>
<td>0.8015</td>
<td>0.8454</td>
<td>0.8630</td>
<td>0.8744</td>
</tr>
<tr>
<td>NaturalQuestions</td>
<td>Train</td>
<td>Hybrid</td>
<td>None</td>
<td>0.6035</td>
<td>0.7830</td>
<td>0.8180</td>
<td>0.8418</td>
<td>0.8633</td>
<td>0.8772</td>
<td>0.8868</td>
<td>0.8948</td>
</tr>
<tr>
<td>NaturalQuestions</td>
<td>Test</td>
<td>Hybrid</td>
<td>None</td>
<td>0.4831</td>
<td>0.6970</td>
<td>0.7568</td>
<td>0.8036</td>
<td>0.8432</td>
<td>0.8604</td>
<td>0.8778</td>
<td>0.8922</td>
</tr>
<tr>
<td>NaturalQuestions</td>
<td>Test</td>
<td>Hybrid</td>
<td>Embedding Similarity</td>
<td>0.1579</td>
<td>0.3903</td>
<td>0.5155</td>
<td>0.6526</td>
<td>0.7911</td>
<td>0.8504</td>
<td>0.8776</td>
<td>0.8922</td>
</tr>
<tr>
<td>NaturalQuestions</td>
<td>Test</td>
<td>Sparse</td>
<td>None</td>
<td>0.2366</td>
<td>0.4571</td>
<td>0.5601</td>
<td>0.6449</td>
<td>0.7366</td>
<td>0.7859</td>
<td>0.8091</td>
<td>0.8222</td>
</tr>
<tr>
<td>NaturalQuestions</td>
<td>Test</td>
<td>Sparse</td>
<td>Embedding Similarity</td>
<td>0.1233</td>
<td>0.2972</td>
<td>0.3928</td>
<td>0.5064</td>
<td>0.6468</td>
<td>0.7410</td>
<td>0.7881</td>
<td>0.8222</td>
</tr>
<tr>
<td>2WikiMultiHopQA</td>
<td>Train</td>
<td>Hybrid</td>
<td>None</td>
<td>0.2243</td>
<td>0.3487</td>
<td>0.3876</td>
<td>0.4294</td>
<td>0.4945</td>
<td>0.5686</td>
<td>0.6290</td>
<td>0.6694</td>
</tr>
<tr>
<td>2WikiMultiHopQA</td>
<td>Test</td>
<td>Hybrid</td>
<td>None</td>
<td>0.0930</td>
<td>0.1811</td>
<td>0.2323</td>
<td>0.2909</td>
<td>0.3931</td>
<td>0.5101</td>
<td>0.6151</td>
<td>0.6759</td>
</tr>
<tr>
<td>2WikiMultiHopQA</td>
<td>Test</td>
<td>Hybrid</td>
<td>Embedding Similarity</td>
<td>0.1667</td>
<td>0.3131</td>
<td>0.3929</td>
<td>0.4674</td>
<td>0.5601</td>
<td>0.6212</td>
<td>0.6523</td>
<td>0.6759</td>
</tr>
<tr>
<td>2WikiMultiHopQA</td>
<td>Test</td>
<td>Sparse</td>
<td>None</td>
<td>0.1854</td>
<td>0.3289</td>
<td>0.4095</td>
<td>0.4834</td>
<td>0.5738</td>
<td>0.6367</td>
<td>0.6723</td>
<td>0.6937</td>
</tr>
<tr>
<td>2WikiMultiHopQA</td>
<td>Test</td>
<td>Sparse</td>
<td>Embedding Similarity</td>
<td>0.1570</td>
<td>0.2930</td>
<td>0.3635</td>
<td>0.4365</td>
<td>0.5339</td>
<td>0.6096</td>
<td>0.6555</td>
<td>0.6935</td>
</tr>
<tr>
<td>ASQA</td>
<td>Train</td>
<td>Hybrid</td>
<td>None</td>
<td>0.5982</td>
<td>0.7926</td>
<td>0.8390</td>
<td>0.8771</td>
<td>0.9001</td>
<td>0.9173</td>
<td>0.9286</td>
<td>0.9405</td>
</tr>
<tr>
<td>ASQA</td>
<td>Train</td>
<td>Hybrid</td>
<td>Embedding Similarity</td>
<td>0.1918</td>
<td>0.4620</td>
<td>0.6010</td>
<td>0.7349</td>
<td>0.8548</td>
<td>0.9079</td>
<td>0.9292</td>
<td>0.9405</td>
</tr>
<tr>
<td>ASQA</td>
<td>Test</td>
<td>Hybrid</td>
<td>None</td>
<td>0.5243</td>
<td>0.7669</td>
<td>0.8249</td>
<td>0.8629</td>
<td>0.8977</td>
<td>0.9188</td>
<td>0.9357</td>
<td>0.9451</td>
</tr>
<tr>
<td>ASQA</td>
<td>Test</td>
<td>Hybrid</td>
<td>Embedding Similarity</td>
<td>0.2068</td>
<td>0.4747</td>
<td>0.6171</td>
<td>0.7479</td>
<td>0.8576</td>
<td>0.9219</td>
<td>0.9378</td>
<td>0.9451</td>
</tr>
<tr>
<td>ASQA</td>
<td>Test</td>
<td>Hybrid</td>
<td>Embedding Relevance</td>
<td>0.2068</td>
<td>0.4736</td>
<td>0.6181</td>
<td>0.7479</td>
<td>0.8586</td>
<td>0.9219</td>
<td>0.9378</td>
<td>0.9451</td>
</tr>
<tr>
<td>ASQA</td>
<td>Test</td>
<td>Sparse</td>
<td>None</td>
<td>0.3249</td>
<td>0.5738</td>
<td>0.6867</td>
<td>0.7637</td>
<td>0.8312</td>
<td>0.8797</td>
<td>0.8914</td>
<td>0.9051</td>
</tr>
<tr>
<td>ASQA</td>
<td>Test</td>
<td>Sparse</td>
<td>Embedding Similarity</td>
<td>0.1582</td>
<td>0.3713</td>
<td>0.4852</td>
<td>0.6086</td>
<td>0.7511</td>
<td>0.8376</td>
<td>0.8861</td>
<td>0.9051</td>
</tr>
<tr>
<td>ASQA</td>
<td>Test</td>
<td>Hybrid</td>
<td>Attention Score</td>
<td>0.2289</td>
<td>0.5496</td>
<td>0.6973</td>
<td>0.8143</td>
<td>0.9030</td>
<td>0.9367</td>
<td>0.9451</td>
<td>0.9451</td>
</tr>
<tr>
<td>ASQA</td>
<td>Test</td>
<td>Hybrid</td>
<td>LLM Relevance</td>
<td>0.5747</td>
<td>0.8206</td>
<td>0.8668</td>
<td>0.9012</td>
<td>0.9227</td>
<td>0.9345</td>
<td>0.9356</td>
<td>0.9356</td>
</tr>
</tbody></table>
<h1 id="6-原因分析"><a href="#6-原因分析" class="headerlink" title="6 原因分析"></a>6 原因分析</h1><h2 id="6-1-Embedding-重排"><a href="#6-1-Embedding-重排" class="headerlink" title="6.1 Embedding 重排"></a>6.1 Embedding 重排</h2><ol>
<li>语义相似的文档不一定包含答案。</li>
<li>Embedding 层未针对检索任务优化。</li>
<li>均值池化会丢失关键位置信息，噪声信息会稀释关键句的语义表示，降低相似度计算的准确性。</li>
</ol>
<h2 id="6-2-Attend-Embedding-重排"><a href="#6-2-Attend-Embedding-重排" class="headerlink" title="6.2 Attend Embedding 重排"></a>6.2 Attend Embedding 重排</h2><ol>
<li>注意力机制本质是用于建模 token 间依赖关系，而非判断文档是否包含答案。</li>
<li>没有经过训练的注意力头的注意力分布并不具备检索导向性。</li>
<li>注意力机制对输入顺序敏感，文档的排列顺序可能影响注意力分布。</li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E7%A0%94%E7%A9%B6%E5%AE%9E%E8%B7%B5/" class="category-chain-item">研究实践</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/RAG/" class="print-no-link">#RAG</a>
      
        <a href="/tags/LLM/" class="print-no-link">#LLM</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>【趣味研究】Embedding Rerank</div>
      <div>http://xuan-van.github.io/67e5abea4c9d/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>文晋</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年6月15日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="NC - 非商业性使用">
                    <i class="iconfont icon-cc-nc"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - 相同方式共享">
                    <i class="iconfont icon-cc-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/5306a0f67226/" title="【时间序列预测】基于深度学习的多变量时间序列预测家庭电力消耗">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">【时间序列预测】基于深度学习的多变量时间序列预测家庭电力消耗</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/ca4c72297a46/" title="【论文复现】ReDeEP">
                        <span class="hidden-mobile">【论文复现】ReDeEP</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.utils.listenDOMLoaded(function() {
      Fluid.events.registerRefreshCallback(function() {
        if ('mermaid' in window) {
          mermaid.init();
        }
      });
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>




  
<script src="/background/background.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<!-- hexo injector body_end start --><script src="/background/background.js"></script><!-- hexo injector body_end end --></body>
</html>
