

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/background/%E5%9B%BE%E6%A0%87.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="文晋">
  <meta name="keywords" content="">
  
    <meta name="description" content=".kkegsybcnptk{}   模型结构：   参考项目：AkariAsai&#x2F;self-rag 1 安装环境配置： 12345cd selfragconda env create -f environment.ymlconda activate selfragconda install -c conda-forge faiss-gpupip install scipy #">
<meta property="og:type" content="article">
<meta property="og:title" content="【论文复现】SelfRAG">
<meta property="og:url" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91selfrag/index.html">
<meta property="og:site_name" content="文心晋意">
<meta property="og:description" content=".kkegsybcnptk{}   模型结构：   参考项目：AkariAsai&#x2F;self-rag 1 安装环境配置： 12345cd selfragconda env create -f environment.ymlconda activate selfragconda install -c conda-forge faiss-gpupip install scipy #">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91selfrag/1.png">
<meta property="og:image" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91selfrag/2.jpg">
<meta property="article:published_time" content="2024-12-11T04:00:00.000Z">
<meta property="article:modified_time" content="2025-03-28T06:51:26.359Z">
<meta property="article:author" content="文晋">
<meta property="article:tag" content="RAG">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91selfrag/1.png">
  
  
  
  <title>【论文复现】SelfRAG - 文心晋意</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/background/background.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"xuan-van.github.io","root":"/","version":"1.9.8","typing":{"enable":false,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":3},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body><!-- hexo injector body_begin start --><div id="web_bg"></div><!-- hexo injector body_begin end -->
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>文晋的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-image"></i>
                <span>图片</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/images/llama.svg" target="_self">
                    
                    <span>Llama 结构</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">【论文复现】SelfRAG</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-12-11 12:00" pubdate>
          2024年12月11日 中午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          4k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          34 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar category-bar" style="margin-right: -1rem">
    





<div class="category-list">
  
  
    
    
    
    <div class="category row nomargin-x">
      <a class="category-item 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="代码复现"
        id="heading-211acd8e7f189296b7caddd5c95b71af" role="tab" data-toggle="collapse" href="#collapse-211acd8e7f189296b7caddd5c95b71af"
        aria-expanded="true"
      >
        代码复现
        <span class="list-group-count">(5)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-211acd8e7f189296b7caddd5c95b71af"
           role="tabpanel" aria-labelledby="heading-211acd8e7f189296b7caddd5c95b71af">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E4%BB%A3%E7%A0%81%E6%8B%86%E8%A7%A3%E3%80%91trajectory-transformer/" title="【代码拆解】Trajectory Transformer"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【代码拆解】Trajectory Transformer</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0%E3%80%91%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0-llama3/" title="【模型复现】从零实现 Llama3"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【模型复现】从零实现 Llama3</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91hipporag-hipporag-2/" title="【论文复现】HippoRAG &amp; HippoRAG 2"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【论文复现】HippoRAG &amp; HippoRAG 2</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91instructrag/" title="【论文复现】InstructRAG"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【论文复现】InstructRAG</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91selfrag/" title="【论文复现】SelfRAG"
           class="list-group-item list-group-item-action
           active">
          <span class="category-post">【论文复现】SelfRAG</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
</div>


  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">【论文复现】SelfRAG</h1>
            
            
              <div class="markdown-body">
                
                <figure style="text-align: center;">
    <style>.kkegsybcnptk{}</style><img src="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91selfrag/1.png" srcset="/img/loading.gif" lazyload class="kkegsybcnptk">
</figure>

<p>模型结构：</p>
<img src="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91selfrag/2.jpg" srcset="/img/loading.gif" lazyload class="">

<p>参考项目：<a target="_blank" rel="noopener" href="https://github.com/AkariAsai/self-rag">AkariAsai&#x2F;self-rag</a></p>
<h1 id="1-安装"><a href="#1-安装" class="headerlink" title="1 安装"></a>1 安装</h1><p>环境配置：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> selfrag<br>conda <span class="hljs-built_in">env</span> create -f environment.yml<br>conda activate selfrag<br>conda install -c conda-forge faiss-gpu<br>pip install scipy <span class="hljs-comment"># LoRA 需要使用</span><br></code></pre></td></tr></table></figure>

<blockquote>
<p>问题：flash-attn 2.3.6 需要正确的 CUDA 才能安装。<br>解决方法：在 <a target="_blank" rel="noopener" href="https://github.com/Dao-AILab/flash-attention/releases">flash-attention&#x2F;releases</a> 中找到对应的 flash-attn 2.3.6 版本，先查看当前环境（Python、CUDA、PyTorch）版本，因此选择下载 <code>flash_attn-2.3.6+cu122torch2.1cxx11abiFALSE-cp38-cp38-linux_x86_64.whl</code>，然后在 <code>selfrag</code> 虚拟环境中安装 <code>pip install flash_attn-2.3.6+cu122torch2.1cxx11abiFALSE-cp38-cp38-linux_x86_64.whl</code>。</p>
</blockquote>
<p>下载模型：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">huggingface-cli download --resume-download selfrag/selfrag_llama2_7b --local-dir model/selfrag_llama2_7b<br>huggingface-cli download --resume-download meta-llama/Llama-2-7b-hf --local-dir ./model/llama2-7b-hf<br></code></pre></td></tr></table></figure>

<p>目录结构：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs nix">data<span class="hljs-symbol">/</span> <span class="hljs-comment"># 数据集</span><br>    enwiki_2020_intro_only<span class="hljs-symbol">/</span><br>    eval_data<span class="hljs-symbol">/</span><br>    selfrag_train_data<span class="hljs-symbol">/</span><br>    gpt4_reward_all_0813_train.json<br><br>model<span class="hljs-symbol">/</span> <span class="hljs-comment"># 训练好的模型，不保存下载的模型</span><br>    critic_llama2_7b<span class="hljs-symbol">/</span><br>    train_selfrag_7b<span class="hljs-symbol">/</span><br><br>rerpoduce<span class="hljs-symbol">/</span> <span class="hljs-comment"># 复现脚本</span><br>    evaluation<span class="hljs-symbol">/</span><br>        evaluate.sh<br>        run_long_form_static.py<br>        metrics.py<br>        run_short_form.py<br>        utils.py<br>    retriever<span class="hljs-symbol">/</span><br>        generate_embeddings.sh<br>        generate_passage_embeddings.py<br>        passage_retrieval.py<br>        run_retrieval.sh<br>        src<span class="hljs-symbol">/</span><br>    train_critic<span class="hljs-symbol">/</span><br>        llama_flash_attn_monkey_patch.py<br>        train_critic.sh<br>        train_special_tokens.py<br>    train_generator<span class="hljs-symbol">/</span><br>        finetune.py<br>        merge.py<br>        stage3_no_offloading_accelerate.conf<br>        train_generator.sh<br>    start.py<br>    start2.py<br>    start3.py<br><br>environment.yml <span class="hljs-comment"># 环境包</span><br>flash_attn-<span class="hljs-number">2.3</span>.<span class="hljs-number">6</span><span class="hljs-operator">+</span>cu122torch2.<span class="hljs-number">1</span>cxx11abiFALSE-cp38-cp38-linux_x86_64.whl <span class="hljs-comment"># 额外的 whl</span><br></code></pre></td></tr></table></figure>

<h1 id="2-快速开始"><a href="#2-快速开始" class="headerlink" title="2 快速开始"></a>2 快速开始</h1><p>对于推理，使用 <a target="_blank" rel="noopener" href="https://docs.vllm.ai/en/latest/">vllm</a> 可以显著加快推理速度。</p>
<h2 id="2-1-start-py"><a href="#2-1-start-py" class="headerlink" title="2.1 start.py"></a>2.1 start.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> vllm <span class="hljs-keyword">import</span> LLM, SamplingParams <span class="hljs-comment"># 使用 vllm 进行推理</span><br><br><span class="hljs-comment"># 加载预训练模型，数据类型为半精度浮点数（half）</span><br>model = LLM(<span class="hljs-string">&quot;../../model/selfrag_llama2_7b&quot;</span>, dtype=<span class="hljs-string">&quot;half&quot;</span>)<br><br><span class="hljs-comment"># 设置生成参数：温度为0.0（无随机性），top_p为1.0（不进行核采样），最大生成token数为100，不跳过特殊token</span><br>sampling_params = SamplingParams(temperature=<span class="hljs-number">0.0</span>, top_p=<span class="hljs-number">1.0</span>, max_tokens=<span class="hljs-number">100</span>, skip_special_tokens=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># 定义一个函数，用于格式化输入提示</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">format_prompt</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, paragraph=<span class="hljs-literal">None</span></span>):<br>  <span class="hljs-comment"># 构建基本的提示格式，包含指令和响应部分</span><br>  prompt = <span class="hljs-string">&quot;### Instruction:\n&#123;0&#125;\n\n### Response:\n&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">input</span>)<br>  <span class="hljs-comment"># 如果提供了段落信息，将其添加到提示中</span><br>  <span class="hljs-keyword">if</span> paragraph <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>    prompt += <span class="hljs-string">&quot;[Retrieval]&lt;paragraph&gt;&#123;0&#125;&lt;/paragraph&gt;&quot;</span>.<span class="hljs-built_in">format</span>(paragraph)<br>  <span class="hljs-keyword">return</span> prompt<br><br><span class="hljs-comment"># 定义两个查询示例</span><br>query_1 = <span class="hljs-string">&quot;Leave odd one out: twitter, instagram, whatsapp.&quot;</span><br>query_2 = <span class="hljs-string">&quot;Can you tell me the difference between llamas and alpacas?&quot;</span><br>queries = [query_1, query_2]<br><br><span class="hljs-comment"># 对于不需要检索的查询，生成模型预测</span><br>preds = model.generate([format_prompt(query) <span class="hljs-keyword">for</span> query <span class="hljs-keyword">in</span> queries], sampling_params)<br><br><span class="hljs-comment"># 打印每个查询的模型预测结果</span><br><span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds:<br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Model prediction: &#123;0&#125;&quot;</span>.<span class="hljs-built_in">format</span>(pred.outputs[<span class="hljs-number">0</span>].text))<br></code></pre></td></tr></table></figure>

<p><code>cd reproduce; python start.py</code> 结果：</p>
<pre><code class="hljs">Model prediction: Twitter, Instagram, and WhatsApp are all social media platforms.[No Retrieval]However, WhatsApp is a messaging app, while Twitter and Instagram are both primarily used for sharing photos and videos.[No Retrieval]Therefore, WhatsApp is the odd one out in this group.[Utility:5]&lt;/s&gt;
Model prediction: Sure![Retrieval]&lt;paragraph&gt;

* Alpaca (left) and llama (right) in the Andes of southern Peru.

Alpacas and llamas are both domesticated species of South American camelids.[Continue to Use Evidence]Alpacas are a much smaller than llamas, with a shoulder height of 3 to 4 feet.[Continue to Use Evidence]They are also bred specifically for their fiber, which is used to make all sorts of textiles and clothing.
</code></pre>
<p>当 Self-RAG 不需要检索时，它会在第一个查询中开始生成不需要检索的响应。另一方面，Self-RAG 为第二个问题输出 <code>[Retrieval]</code> 令牌，因为这个问题需要更细粒度的事实基础。</p>
<h2 id="2-2-start2-py"><a href="#2-2-start2-py" class="headerlink" title="2.2 start2.py"></a>2.2 start2.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> vllm <span class="hljs-keyword">import</span> LLM, SamplingParams<br><br><span class="hljs-comment"># 加载预训练模型，数据类型为半精度浮点数（half）</span><br>model = LLM(<span class="hljs-string">&quot;../../model/selfrag_llama2_7b&quot;</span>, dtype=<span class="hljs-string">&quot;half&quot;</span>)<br><br><span class="hljs-comment"># 设置生成参数：温度为0.0（无随机性），top_p为1.0（不进行核采样），最大生成token数为100，不跳过特殊token</span><br>sampling_params = SamplingParams(temperature=<span class="hljs-number">0.0</span>, top_p=<span class="hljs-number">1.0</span>, max_tokens=<span class="hljs-number">100</span>, skip_special_tokens=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># 定义一个函数，用于格式化输入提示</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">format_prompt</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, paragraph=<span class="hljs-literal">None</span></span>):<br>  <span class="hljs-comment"># 构建基本的提示格式，包含指令和响应部分</span><br>  prompt = <span class="hljs-string">&quot;### Instruction:\n&#123;0&#125;\n\n### Response:\n&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">input</span>)<br>  <span class="hljs-comment"># 如果提供了段落信息，将其添加到提示中</span><br>  <span class="hljs-keyword">if</span> paragraph <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>    prompt += <span class="hljs-string">&quot;[Retrieval]&lt;paragraph&gt;&#123;0&#125;&lt;/paragraph&gt;&quot;</span>.<span class="hljs-built_in">format</span>(paragraph)<br>  <span class="hljs-keyword">return</span> prompt<br><br>prompt = format_prompt(<span class="hljs-string">&quot;Can you tell me the difference between llamas and alpacas?&quot;</span>, <span class="hljs-string">&quot;The alpaca (Lama pacos) is a species of South American camelid mammal. It is similar to, and often confused with, the llama. Alpacas are considerably smaller than llamas, and unlike llamas, they were not bred to be working animals, but were bred specifically for their fiber.&quot;</span>)<br>preds = model.generate([prompt], sampling_params)<br><span class="hljs-built_in">print</span>([pred.outputs[<span class="hljs-number">0</span>].text <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]) <span class="hljs-comment"># 打印每个查询的模型预测结果</span><br></code></pre></td></tr></table></figure>

<p><code>cd reproduce; python start2.py</code> 结果：</p>
<pre><code class="hljs">[&#39;[Relevant]Alpacas are considerably smaller than llamas.[Fully supported][Utility:5]&lt;/s&gt;&#39;]
</code></pre>
<p>Self-RAG 可以在生成时随时检索和插入段落，并且只要它们被上下文标记特殊词元 <code>&lt;paragraph&gt;</code>、<code>&lt;/paragraph&gt;</code> 包围，就可以识别它们。Self-RAG 找到相关的插入文档，并生成完全有证据支持的答案。</p>
<h2 id="2-3-使用-Online-Retrieval-模型运行评估"><a href="#2-3-使用-Online-Retrieval-模型运行评估" class="headerlink" title="2.3 使用 Online Retrieval 模型运行评估"></a>2.3 使用 Online Retrieval 模型运行评估</h2><p>从 <a target="_blank" rel="noopener" href="https://drive.google.com/uc?id=1IYNAkwawfCDiBL27BlBqGssxFQH9vOux%27%E3%80%81">google drive</a> 下载维基百科的子集 <code>enwiki_2020_intro_only.zip</code>（包括维基百科文章的介绍段落），保存在 <code>data</code> 文件夹下。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> data<br>unzip enwiki_2020_intro_only.zip<br><span class="hljs-built_in">rm</span> enwiki_2020_intro_only.zip<br><span class="hljs-built_in">cd</span> ../reproduce<br>python start3.py<br></code></pre></td></tr></table></figure>
<br/>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br>sys.path.append(<span class="hljs-string">&#x27;reproduce父目录绝对路径/reproduce/retriever&#x27;</span>) <span class="hljs-comment"># 模块导入</span><br><br><span class="hljs-keyword">from</span> vllm <span class="hljs-keyword">import</span> LLM, SamplingParams  <span class="hljs-comment"># 导入LLM模型和采样参数设置</span><br><span class="hljs-keyword">from</span> passage_retrieval <span class="hljs-keyword">import</span> Retriever  <span class="hljs-comment"># 导入用于文档检索的Retriever类</span><br><br><span class="hljs-comment"># 初始化检索器，并设置其参数</span><br>retriever = Retriever(&#123;&#125;)<br>retriever.setup_retriever_demo(<br>    <span class="hljs-string">&quot;facebook/contriever-msmarco&quot;</span>,  <span class="hljs-comment"># 使用的模型</span><br>    <span class="hljs-string">&quot;data/enwiki_2020_intro_only/enwiki_2020_dec_intro_only.jsonl&quot;</span>,  <span class="hljs-comment"># 检索数据集</span><br>    <span class="hljs-string">&quot;data/enwiki_2020_intro_only/enwiki_dec_2020_contriever_intro/*&quot;</span>,  <span class="hljs-comment"># 索引文件路径</span><br>    n_docs=<span class="hljs-number">5</span>,  <span class="hljs-comment"># 检索文档数量</span><br>    save_or_load_index=<span class="hljs-literal">False</span>  <span class="hljs-comment"># 是否保存或加载索引</span><br>)<br><br><span class="hljs-comment"># 加载预训练模型，数据类型为半精度浮点数（half）</span><br>model = LLM(<span class="hljs-string">&quot;../../model/selfrag_llama2_7b&quot;</span>, dtype=<span class="hljs-string">&quot;half&quot;</span>)<br><br><span class="hljs-comment"># 设置生成参数：温度为0.0（无随机性），top_p为1.0（不进行核采样），最大生成token数为100，不跳过特殊token</span><br>sampling_params = SamplingParams(temperature=<span class="hljs-number">0.0</span>, top_p=<span class="hljs-number">1.0</span>, max_tokens=<span class="hljs-number">100</span>, skip_special_tokens=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># 定义一个函数，用于格式化输入提示</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">format_prompt</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, paragraph=<span class="hljs-literal">None</span></span>):<br>  <span class="hljs-comment"># 构建基本的提示格式，包含指令和响应部分</span><br>  prompt = <span class="hljs-string">&quot;### Instruction:\n&#123;0&#125;\n\n### Response:\n&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">input</span>)<br>  <span class="hljs-comment"># 如果提供了段落信息，将其添加到提示中</span><br>  <span class="hljs-keyword">if</span> paragraph <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>    prompt += <span class="hljs-string">&quot;[Retrieval]&lt;paragraph&gt;&#123;0&#125;&lt;/paragraph&gt;&quot;</span>.<span class="hljs-built_in">format</span>(paragraph)<br>  <span class="hljs-keyword">return</span> prompt<br><br><span class="hljs-comment"># 定义查询问题</span><br>query_3 = <span class="hljs-string">&quot;When does overfitting occur?&quot;</span><br><span class="hljs-comment"># 使用检索器搜索相关文档</span><br>retrieved_documents = retriever.search_document_demo(query_3, <span class="hljs-number">5</span>)<br><span class="hljs-comment"># 为每个检索到的文档创建格式化的提示</span><br>prompts = [format_prompt(query_3, doc[<span class="hljs-string">&quot;title&quot;</span>] +<span class="hljs-string">&quot;\n&quot;</span>+ doc[<span class="hljs-string">&quot;text&quot;</span>]) <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> retrieved_documents]<br><span class="hljs-comment"># 使用模型生成预测结果</span><br>preds = model.generate(prompts, sampling_params)<br><span class="hljs-comment"># 检索最相关的文档</span><br>top_doc = retriever.search_document_demo(query_3, <span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]<br><span class="hljs-comment"># 打印参考文档和模型预测结果</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Reference: &#123;0&#125;\nModel prediction: &#123;1&#125;&quot;</span>.<span class="hljs-built_in">format</span>(top_doc[<span class="hljs-string">&quot;title&quot;</span>] + <span class="hljs-string">&quot;\n&quot;</span> + top_doc[<span class="hljs-string">&quot;text&quot;</span>], preds[<span class="hljs-number">0</span>].outputs[<span class="hljs-number">0</span>].text))<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">Reference: Overfitting
  In statistics, overfitting is &quot;the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably&quot;. An overfitted model is a statistical model that contains more parameters than can be justified by the data. The essence of overfitting is to have unknowingly extracted some of the residual variation (i.e., the noise) as if that variation represented underlying model structure. Underfitting occurs when a statistical model cannot adequately capture the underlying structure of the data. An under-fitted model is a model where some parameters or terms that would appear in a correctly specified model are 
Model prediction: [Relevant]Overfitting occurs when a statistical model has too many parameters relative to the amount of data available.[Fully supported][Continue to Use Evidence]This can lead to the model performing well on the training data but not on new, unseen data.[Utility:5]&lt;/s&gt;
</code></pre>
<h1 id="3-检索器设置"><a href="#3-检索器设置" class="headerlink" title="3 检索器设置"></a>3 检索器设置</h1><p>默认情况下，使用 <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/contriever">Contriever</a> 作为检索组件。</p>
<h2 id="3-1-下载数据"><a href="#3-1-下载数据" class="headerlink" title="3.1 下载数据"></a>3.1 下载数据</h2><p>下载 DPR 中使用的预处理过的段落数据：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> data<br>wget https://dl.fbaipublicfiles.com/dpr/wikipedia_split/psgs_w100.tsv.gz<br>gunzip psgs_w100.tsv.gz<br></code></pre></td></tr></table></figure>

<p>下载生成的段落，使用 <a target="_blank" rel="noopener" href="https://huggingface.co/facebook/contriever-msmarco">Contriever-MSMARCO</a>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> data<br>wget https://dl.fbaipublicfiles.com/contriever/embeddings/contriever-msmarco/wikipedia_embeddings.tar<br>tar -xf wikipedia_embeddings.tar<br><span class="hljs-built_in">rm</span> wikipedia_embeddings.tar<br></code></pre></td></tr></table></figure>

<blockquote>
<p>在下载之前可以使用 <code>wget --spider 下载地址</code> 来查看文件大小等情况。</p>
</blockquote>
<h2 id="3-2-运行检索器"><a href="#3-2-运行检索器" class="headerlink" title="3.2 运行检索器"></a>3.2 运行检索器</h2><p>通过以下命令来运行文章检索，见附录 7.1：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> reproduce/retriever<br>bash run_retrieval.sh<br></code></pre></td></tr></table></figure>
<p>输入文件应为 <code>json</code> 或 <code>jsonl</code>，每个实例必须包含 <code>question</code> 或 <code>instruction</code>，它们将在检索期间用作查询。</p>
<h2 id="3-3-为自己的数据生成-embeddings"><a href="#3-3-为自己的数据生成-embeddings" class="headerlink" title="3.3 为自己的数据生成 embeddings"></a>3.3 为自己的数据生成 embeddings</h2><p>通过以下命令为自己的数据生成 embeddings，见附录 7.2：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> reproduce/retriever<br>bash generate_embeddings.sh<br></code></pre></td></tr></table></figure>

<h1 id="4-训练"><a href="#4-训练" class="headerlink" title="4 训练"></a>4 训练</h1><p>Self-RAG 训练两个模型 Critic 和 Generator，这两个模型都使用反射词元扩展词元词汇表，并使用标准的下一个词元预测目标进行训练。</p>
<h2 id="4-1-收集反射词元"><a href="#4-1-收集反射词元" class="headerlink" title="4.1 收集反射词元"></a>4.1 收集反射词元</h2><p>使用 GPT4 生成 Critic 数据，在 <code>data_creation/critic</code> 上可以找到为每种特殊令牌类型调用 GPT-4 的脚本。<a target="_blank" rel="noopener" href="https://drive.google.com/file/d/1IN1XcIOYtRIGWITJ4LKRgfITT-uUwk_W/view?usp=share_link">训练结果</a>为：<code>gpt4_reward_all_0813_train.json</code>。</p>
<h2 id="4-2-Critic-训练"><a href="#4-2-Critic-训练" class="headerlink" title="4.2 Critic 训练"></a>4.2 Critic 训练</h2><p>用新的特殊词元训练 Critic， 对 Llama2-7B 进行微调，见附录 7.3：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> reproduce/train_critic<br>sbatch train_critic.sh<br></code></pre></td></tr></table></figure>

<h2 id="4-3-创建-Generator-数据"><a href="#4-3-创建-Generator-数据" class="headerlink" title="4.3 创建 Generator 数据"></a>4.3 创建 Generator 数据</h2><p>使用 Critic 和 Retriever 生成 Generator 训练数据，训练结果为：<code>huggingface-cli download --repo-type dataset --resume-download selfrag/selfrag_train_data --local-dir ./data/selfrag_train_data</code></p>
<h2 id="4-4-Generator-训练"><a href="#4-4-Generator-训练" class="headerlink" title="4.4 Generator 训练"></a>4.4 Generator 训练</h2><p>使用新的特殊词元训练 Generator，用 <a target="_blank" rel="noopener" href="https://www.deepspeed.ai/">DeepSpeed</a> 来提高训练效率。设置训练数据路径后，通过运行附录 7.4 的脚本来进行训练。  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> reproduce/train_generator<br>sbatch train_generator.sh<br></code></pre></td></tr></table></figure>

<p>注意不同的 GPU 架构可能无法使用 <code>bf16</code>，需要改为 <code>fp16</code>，因此需要修改 <code>stage3_no_offloading_accelerate.conf</code>，将</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;bf16&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;enabled&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;auto&quot;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>
<p>改为</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;fp16&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;enabled&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;true&quot;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>

<p>由于使用了 LoRA 技术，因此需要 <code>python merge.py</code> 来合并模型权重：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> shutil<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer<br><span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> PeftModel<br><br>base_model_path = <span class="hljs-string">&quot;../model/llama2-7b-hf&quot;</span>  <span class="hljs-comment"># 基础模型路径</span><br>lora_model_path = <span class="hljs-string">&quot;model/train_selfrag_7b&quot;</span>  <span class="hljs-comment"># LoRA 微调后的模型路径</span><br>output_dir = <span class="hljs-string">&quot;model/reproduce_selfrag_7b&quot;</span>  <span class="hljs-comment"># 合并后的模型输出路径</span><br><br>base_model = AutoModelForCausalLM.from_pretrained(base_model_path) <span class="hljs-comment"># 加载基础模型</span><br>lora_tokenizer = AutoTokenizer.from_pretrained(lora_model_path) <span class="hljs-comment"># 加载 LoRA 分词器</span><br>base_model.resize_token_embeddings(<span class="hljs-built_in">len</span>(lora_tokenizer)) <span class="hljs-comment"># 扩展模型的词汇表</span><br>lora_model = PeftModel.from_pretrained(base_model, lora_model_path) <span class="hljs-comment"># 加载 LoRA 适配器</span><br>model = lora_model.merge_and_unload() <span class="hljs-comment"># 合并模型</span><br><br>model.save_pretrained(output_dir, safe_serialization=<span class="hljs-literal">False</span>) <span class="hljs-comment"># 保存合并后的模型</span><br>lora_tokenizer.save_pretrained(output_dir) <span class="hljs-comment"># 保存扩展后的分词器</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Model merging and saving completed successfully!&quot;</span>)<br></code></pre></td></tr></table></figure>

<h1 id="5-推理"><a href="#5-推理" class="headerlink" title="5 推理"></a>5 推理</h1><p>对于任务评估，下载数据集 <a target="_blank" rel="noopener" href="https://drive.google.com/file/d/1TLKhWjez63H4uBtgCxyoyJsZi-IMgnDb/view?usp=share_link">eval_data.zip</a>，每个文件都已经附带了检索到的文档，因此，如果不想在推理中运行检索器，可以简单地在所有 <code>contexts</code> 中加载检索到的文件。使用附录 7.5 中的命令来评估相应的数据集。</p>
<h2 id="5-1-短格式"><a href="#5-1-短格式" class="headerlink" title="5.1 短格式"></a>5.1 短格式</h2><p>通常只为简短的生成任务检索一次，因此提供了一个易于运行的评估脚本，该脚本利用了 Contriever 离线检索的预先给定的文档。<code>--world_size</code> 可使用多个 GPU 进行推理。<code>--mode</code> 有三种参数（两个 QA 数据集会用到）：</p>
<ul>
<li><code>adaptive_retrieval</code>：检索给定的阈值或 Self-RAG 预测。</li>
<li><code>no_retrieval</code>：在推理时禁用检索。</li>
<li><code>always_retrieve</code>：总是检索。</li>
</ul>
<h2 id="5-2-长格式"><a href="#5-2-长格式" class="headerlink" title="5.2 长格式"></a>5.2 长格式</h2><p>对于长篇 QA，可以使用检索模型或<strong>预先给定的段落</strong>运行评估。DPR &#x2F; Contriever 与整个英文维基百科嵌入需要 100 GB RAM，因此使用一小组初始检索文档。关键参数：</p>
<ul>
<li><code>w_rel</code>（默认 1.0）：控制符杠搜索过程中对 <code>isRel</code>（对检索到的段落是否相关的批评标记）标记概率的强调。</li>
<li><code>w_sup</code>（默认 1.0）：控制在符系搜索过程中对 <code>isSup</code>（对文档是否支持生成）标记概率的强调。</li>
<li><code>w_use</code>（默认 0.5）：控制 beam 搜索期间对 <code>isUse</code>（对整体质量的批评标记）标记概率的强调。</li>
<li><code>threshold</code>（默认 0.2）：此阈值控制自适应检索的频率。</li>
<li><code>max_depth</code>（默认 6）：这对应于论文中的 <code>T</code>，它定义了最大搜索深度。</li>
<li><code>beam_width</code>（默认 2）：这控制了分段级光束搜索中光束的大小。</li>
</ul>
<h1 id="6-常见问题"><a href="#6-常见问题" class="headerlink" title="6 常见问题"></a>6 常见问题</h1><h2 id="6-1-CUDA-out-of-memory"><a href="#6-1-CUDA-out-of-memory" class="headerlink" title="6.1 CUDA out of memory"></a>6.1 CUDA out of memory</h2><ol>
<li>LoRA 技术。注意需要合并 LoRA 额外的参数。需要额外 <code>pip install scipy</code></li>
<li>增加梯度累积步数 <code>--gradient_accumulation_steps</code>。</li>
<li>清理缓存，在训练循环中适当的地方调用 <code>torch.cuda.empty_cache()</code> 来清理未使用的缓存，但是会<strong>增加训练时间</strong>。</li>
<li>使用混合精度训练，设置 <code>--fp16</code>（V100）或<code>--bf16</code>（A100） 参数为 <code>true</code>，<strong>可能反而导致内存不足</strong>。</li>
<li>调整 PyTorch 内存分配器，设置 <code>export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128</code> 来避免内存碎片化。</li>
<li>将权重加载到 CPU 上，<code>device_map=&#39;cpu&#39;</code>。</li>
</ol>
<h2 id="6-2-加速训练"><a href="#6-2-加速训练" class="headerlink" title="6.2 加速训练"></a>6.2 加速训练</h2><ol>
<li>DeepSpeed：<ul>
<li>配置 <code>df_config.json</code>：</li>
</ul>
 <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    训练批量大小 train_batch_size = train_micro_batch_size_per_gpu * n_gpus * gradient_accumulation_steps<br>    <span class="hljs-attr">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> 每块 GPU 的微批次大小<br>    <span class="hljs-attr">&quot;gradient_accumulation_steps&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">8</span><span class="hljs-punctuation">,</span> 梯度累积步数<br>    <span class="hljs-attr">&quot;zero_optimization&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> ZeRO 优化器配置<br>        <span class="hljs-attr">&quot;stage&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span> 启用 ZeRO Stage <span class="hljs-number">2</span> 优化，模型参数和优化器状态被分片到 CPU 或其他设备<br>        <span class="hljs-attr">&quot;offload_optimizer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> 优化器状态的卸载配置：不启用<br>            <span class="hljs-attr">&quot;device&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;none&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;offload_param&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> 模型参数的卸载配置：不启用<br>            <span class="hljs-attr">&quot;device&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;none&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;optimizer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> 优化器配置<br>        <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;AdamW&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;用于训练深度学习模型</span><br><span class="hljs-string">        &quot;</span>params<span class="hljs-string">&quot;: &#123;</span><br><span class="hljs-string">            &quot;</span>lr<span class="hljs-string">&quot;: &quot;</span>auto<span class="hljs-string">&quot;, 学习率</span><br><span class="hljs-string">            &quot;</span>weight_decay<span class="hljs-string">&quot;: &quot;</span>auto<span class="hljs-string">&quot; 权重衰减，用于 L2 正则化</span><br><span class="hljs-string">        &#125;</span><br><span class="hljs-string">    &#125;,</span><br><span class="hljs-string">    &quot;</span>scheduler<span class="hljs-string">&quot;: &#123; 学习率调度器配置</span><br><span class="hljs-string">        &quot;</span>type<span class="hljs-string">&quot;: &quot;</span>WarmupLR<span class="hljs-string">&quot;, 用于稳定训练初期</span><br><span class="hljs-string">        &quot;</span>params<span class="hljs-string">&quot;: &#123;</span><br><span class="hljs-string">            &quot;</span>warmup_num_steps<span class="hljs-string">&quot;: &quot;</span>auto<span class="hljs-string">&quot; Warmup 步数</span><br><span class="hljs-string">        &#125;</span><br><span class="hljs-string">    &#125;,</span><br><span class="hljs-string">    &quot;</span>fp16<span class="hljs-string">&quot;: &#123; 启用混合精度训练</span><br><span class="hljs-string">        &quot;</span>enabled<span class="hljs-string">&quot;: &quot;</span>auto<span class="hljs-string">&quot;</span><br><span class="hljs-string">    &#125;</span><br><span class="hljs-string">&#125;</span><br></code></pre></td></tr></table></figure></li>
<li><code>--fsdp &quot;full_shard auto_wrap&quot;</code>，<strong>无法与 DeepSpeed 同时使用</strong>。</li>
</ol>
<h2 id="6-3-训练-Critic-出错"><a href="#6-3-训练-Critic-出错" class="headerlink" title="6.3 训练 Critic 出错"></a>6.3 训练 Critic 出错</h2><h3 id="错误情况"><a href="#错误情况" class="headerlink" title="错误情况"></a>错误情况</h3><p>在执行 <code>train_special_tokens.py</code> 脚本时，<code>SupervisedDataset</code> 类的初始化过程中出现了 <code>KeyError</code>。此错误是由于尝试从 <code>PROMPT_DICT</code> 字典中访问不存在的键 <code>&quot;prompt_no_input_paragraph&quot;</code> 引起的。</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>向 <code>PROMPT_DICT</code> 字典中添加 <code>&quot;prompt_no_input_paragraph&quot;</code> 和 <code>&quot;prompt_no_input_separated&quot;</code> 两个键：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">PROMPT_DICT = &#123;<br>    <span class="hljs-string">&quot;prompt_input&quot;</span>: (<br>        <span class="hljs-string">&quot;### Instruction:\n&#123;instruction&#125;\n\n### Input:\n&#123;input&#125;\n\n### Response:&quot;</span><br>    ),<br>    <span class="hljs-string">&quot;prompt_no_input&quot;</span>: (<br>        <span class="hljs-string">&quot;### Instruction:\n&#123;instruction&#125;\n\n### Response:&quot;</span><br>    ),<br>    <span class="hljs-string">&quot;prompt_no_input_paragraph&quot;</span>: (<br>        <span class="hljs-string">&quot;### Instruction:\n&#123;instruction&#125;\n\n### Context:\n&#123;context&#125;\n\n### Response:&quot;</span><br>    ),<br>    <span class="hljs-string">&quot;prompt_no_input_separated&quot;</span>: (<br>        <span class="hljs-string">&quot;### Instruction:\n&#123;instruction&#125;\n\n### Separated Context:\n&#123;context&#125;\n\n### Response:&quot;</span><br>    ),<br>&#125;<br></code></pre></td></tr></table></figure>

<h2 id="6-4-评估出错"><a href="#6-4-评估出错" class="headerlink" title="6.4 评估出错"></a>6.4 评估出错</h2><p><code>run_short_form.py</code> 的 <code>call_model_rerank_w_scores_batch</code> 函数中多出一个参数 <code>max_depth</code>，需要删除。</p>
<h2 id="6-5-其他"><a href="#6-5-其他" class="headerlink" title="6.5 其他"></a>6.5 其他</h2><ol>
<li>注意使用 bash 执行脚本时，输入通常需要 <code>--</code> 参数来换行，<code>\</code> 后不能有空格。</li>
<li>文件路径处理，用于导入数据和模型：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br>os.chdir(<span class="hljs-string">&#x27;selfrag父目录绝对路径/selfrag&#x27;</span>)<br></code></pre></td></tr></table></figure>
<ol start="3">
<li>模块路径处理，用于导入自定义的库：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br>sys.path.append(<span class="hljs-string">&#x27;reproduce父目录绝对路径/reproduce/retriever&#x27;</span>)<br></code></pre></td></tr></table></figure>

<h1 id="7-附录"><a href="#7-附录" class="headerlink" title="7 附录"></a>7 附录</h1><h2 id="7-1-run-retrieval-sh"><a href="#7-1-run-retrieval-sh" class="headerlink" title="7.1 run_retrieval.sh"></a>7.1 run_retrieval.sh</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">python passage_retrieval.py \<br>    --model_name_or_path facebook/contriever-msmarco \ <span class="hljs-comment"># 指定要使用的模型</span><br>    --passages ../../data/psgs_w100.tsv \ <span class="hljs-comment"># 指定要使用的文档集合</span><br>    --passages_embeddings <span class="hljs-string">&quot;wikipedia_embeddings/*&quot;</span> \ <span class="hljs-comment"># 指定预先计算的文档嵌入文件路径</span><br>    --data YOUR_INPUT_FILE  \ <span class="hljs-comment"># 指定输入数据文件的路径</span><br>    --output_dir YOUR_OUTPUT_FILE \ <span class="hljs-comment"># 指定输出目录</span><br>    --n_docs 20 <span class="hljs-comment"># 指定要检索的文档数量</span><br></code></pre></td></tr></table></figure>

<h2 id="7-2-generate-embeddings-sh"><a href="#7-2-generate-embeddings-sh" class="headerlink" title="7.2 generate_embeddings.sh"></a>7.2 generate_embeddings.sh</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> &#123;0..1&#125;; <span class="hljs-keyword">do</span> <span class="hljs-comment"># 循环遍历0到1的数字</span><br>  <span class="hljs-built_in">export</span> CUDA_VISIBLE_DEVICES=<span class="hljs-variable">$&#123;i&#125;</span> <span class="hljs-comment"># 设置 CUDA_VISIBLE_DEVICES 环境变量为当前循环的数字</span><br>  python generate_passage_embeddings.py \ <span class="hljs-comment"># 运行 generate_passage_embeddings.py 脚本，生成段落嵌入</span><br>    --model_name_or_path facebook/contriever-msmarco \  <span class="hljs-comment"># 指定使用的模型</span><br>    --output_dir YOUR_OUTPUT_DIR \  <span class="hljs-comment"># 指定输出目录</span><br>    --passages YOUR_PASSAGE_DATA \  <span class="hljs-comment"># 指定段落数据文件</span><br>    --shard_id <span class="hljs-variable">$&#123;i&#125;</span> \  <span class="hljs-comment"># 指定当前分片的ID</span><br>    --num_shards 4 \  <span class="hljs-comment"># 指定总分片数</span><br>    &gt; ./log/nohup.my_embeddings.<span class="hljs-variable">$&#123;i&#125;</span> 2&gt;&amp;1 &amp;  <span class="hljs-comment"># 将输出重定向到日志文件，并在后台运行</span><br></code></pre></td></tr></table></figure>

<h2 id="7-3-train-critic-sh"><a href="#7-3-train-critic-sh" class="headerlink" title="7.3 train_critic.sh"></a>7.3 train_critic.sh</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs bash">torchrun --nproc_per_node=2 \  <span class="hljs-comment"># 使用torchrun命令运行脚本，每个节点使用2个进程</span><br>  --master_port=2568 train_special_tokens.py \  <span class="hljs-comment"># 设置主节点端口为2568，运行train_special_tokens.py脚本</span><br>  --model_name_or_path ../../../model/llama2-7b-hf \  <span class="hljs-comment"># 指定模型路径</span><br>  --data_path ../../data/gpt4_reward_all_0813_train.json \  <span class="hljs-comment"># 指定数据路径</span><br>  --output_dir ../../model/critic_llama2_7b \  <span class="hljs-comment"># 指定输出目录</span><br>  --num_train_epochs 3  \  <span class="hljs-comment"># 设置训练轮数为 3</span><br>  --per_device_train_batch_size 1 --per_device_eval_batch_size 1 \  <span class="hljs-comment"># 设置每个设备的训练和评估批次大小为 1</span><br>  --gradient_accumulation_steps 8 \  <span class="hljs-comment"># 设置梯度累积步数为 8</span><br>  --evaluation_strategy <span class="hljs-string">&quot;no&quot;</span> \  <span class="hljs-comment"># 设置评估策略为不评估</span><br>  --save_strategy <span class="hljs-string">&quot;steps&quot;</span> \  <span class="hljs-comment"># 设置保存策略为按步数保存</span><br>  --save_steps 300 \  <span class="hljs-comment"># 设置每 300 步保存一次</span><br>  --save_total_limit 1 \  <span class="hljs-comment"># 设置保存的总数限制为 1</span><br>  --learning_rate 2e-5 \  <span class="hljs-comment"># 设置学习率为 2e-5</span><br>  --weight_decay 0. \  <span class="hljs-comment"># 设置权重衰减为 0</span><br>  --warmup_ratio 0.01 \  <span class="hljs-comment"># 设置预热比例为 0.01</span><br>  --lr_scheduler_type <span class="hljs-string">&quot;cosine&quot;</span> \  <span class="hljs-comment"># 设置学习率调度器类型为 cosine</span><br>  --logging_steps 10 \  <span class="hljs-comment"># 设置每 10 步记录一次日志</span><br>  --lora_rank 8 \  <span class="hljs-comment"># 设置 LoRA 秩为 8</span><br>  --lora_alpha 16 \  <span class="hljs-comment"># 设置 LoRA alpha 为 16</span><br>  --lora_dropout 0.1  <span class="hljs-comment"># 设置 LoRA dropout 为 0.1</span><br></code></pre></td></tr></table></figure>

<h2 id="7-4-train-generator-sh"><a href="#7-4-train-generator-sh" class="headerlink" title="7.4 train_generator.sh"></a>7.4 train_generator.sh</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> CUDA_VISIBLE_DEVICES=0,1<br><br>MODEL_SIZE=7B<br>NUM_GPUS=2<br>BATCH_SIZE_PER_GPU=1<br>TOTAL_BATCH_SIZE=128<br>GRADIENT_ACC_STEPS=$((<span class="hljs-variable">$TOTAL_BATCH_SIZE</span>/<span class="hljs-variable">$NUM_GPUS</span>/<span class="hljs-variable">$BATCH_SIZE_PER_GPU</span>))<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Training llama model <span class="hljs-variable">$&#123;MODEL_SIZE&#125;</span> using <span class="hljs-variable">$NUM_GPUS</span> GPUs, <span class="hljs-variable">$BATCH_SIZE_PER_GPU</span> batch size per GPU, <span class="hljs-variable">$GRADIENT_ACC_STEPS</span> gradient accumulation steps&quot;</span><br><br>CUDA_VISIBLE_DEVICES=0,1 <span class="hljs-comment"># 设置哪些GPU对当前进程可见，这里指定了0号和1号GPU。</span><br><br>accelerate launch \ <span class="hljs-comment"># 使用Hugging Face的accelerate库来启动分布式训练。</span><br>    --num_machines 1 \ <span class="hljs-comment"># 指定使用的机器数量，这里为1台机器。</span><br>    --num_processes 2 \ <span class="hljs-comment"># 指定进程数，通常等于GPU的数量。</span><br>    --use_deepspeed \ <span class="hljs-comment"># 启用DeepSpeed库来加速训练。</span><br>    --deepspeed_config_file stage3_no_offloading_accelerate.conf \ <span class="hljs-comment"># 指定DeepSpeed配置文件。</span><br>    finetune.py \ <span class="hljs-comment"># 指定要执行的Python脚本，这里是finetune.py。</span><br>    --model_name_or_path ../../../model/llama2-7b-hf \ <span class="hljs-comment"># 指定模型的名称或路径，这里使用相对路径指定模型位置。</span><br>    --use_flash_attn \ <span class="hljs-comment"># 使用Flash Attention，这是一种高效的注意力机制实现。</span><br>    --tokenizer_name ../../../model/llama2-7b-hf \ <span class="hljs-comment"># 指定分词器的名称或路径。</span><br>    --use_slow_tokenizer \ <span class="hljs-comment"># 使用较慢的分词器实现。</span><br>    --train_file ../../data/selfrag_train_data/train.jsonl \ <span class="hljs-comment"># 指定训练数据文件的位置。</span><br>    --max_seq_length 2048 \ <span class="hljs-comment"># 设置最大序列长度。</span><br>    --preprocessing_num_workers 16 \ <span class="hljs-comment"># 设置预处理工作线程数。</span><br>    --per_device_train_batch_size 1 \ <span class="hljs-comment"># 每个设备上的批次大小。</span><br>    --gradient_accumulation_steps 128 \ <span class="hljs-comment"># 梯度累积步数。</span><br>    --learning_rate 2e-5 \ <span class="hljs-comment"># 设置学习率。</span><br>    --lr_scheduler_type linear \ <span class="hljs-comment"># 学习率调度器类型，这里使用线性调度器。</span><br>    --warmup_ratio 0.03 \ <span class="hljs-comment"># 预热比例，用于学习率预热。</span><br>    --weight_decay 0. \ <span class="hljs-comment"># 设置权重衰减，这里为0，表示不使用权重衰减。</span><br>    --num_train_epochs 3 \ <span class="hljs-comment"># 设置训练的轮数（epoch）。</span><br>    --output_dir ../../model/train_selfrag_7b/ \ <span class="hljs-comment"># 设置输出目录。</span><br>    --with_tracking \ <span class="hljs-comment"># 启用跟踪，可能是指使用某种跟踪工具。</span><br>    --report_to tensorboard \ <span class="hljs-comment"># 指定报告工具，这里使用TensorBoard。</span><br>    --logging_steps 1000 \ <span class="hljs-comment"># 设置日志记录步数，每1000步记录一次。</span><br>    --use_special_tokens \ <span class="hljs-comment"># 使用特殊标记。</span><br>    --use_lora \ <span class="hljs-comment"># 使用LoRA（Low-Rank Adaptation）技术。</span><br>    --lora_rank 8 \ <span class="hljs-comment"># 设置LoRA的秩。</span><br>    --lora_alpha 16 \ <span class="hljs-comment"># 设置LoRA的缩放因子。</span><br>    --lora_dropout 0.1 <span class="hljs-comment"># 设置LoRA的dropout率。</span><br></code></pre></td></tr></table></figure>

<h2 id="7-5-evaluate-sh"><a href="#7-5-evaluate-sh" class="headerlink" title="7.5 evaluate.sh"></a>7.5 evaluate.sh</h2><h3 id="PopQA"><a href="#PopQA" class="headerlink" title="PopQA"></a>PopQA</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">python run_short_form.py \<br>--model_name ../../model/selfrag_llama2_7b \<br>--input_file ../../data/eval_data/popqa_longtail_w_gs.jsonl \<br>--mode adaptive_retrieval \<br>--max_new_tokens 100 \<br>--threshold 0.2 \<br>--output_file result/popqa.json \<br>--metric match --ndocs 10 --use_groundness --use_utility --use_seqscore \<br>--dtype half<br></code></pre></td></tr></table></figure>

<h3 id="TriviaQA"><a href="#TriviaQA" class="headerlink" title="TriviaQA"></a>TriviaQA</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">python run_short_form.py \<br>--model_name ../../model/selfrag_llama2_7b \<br>--input_file ../../data/eval_data/triviaqa_test_w_gs.jsonl \<br>--mode adaptive_retrieval \<br>--max_new_tokens 100 \<br>--threshold 0.2 \<br>--output_file result/triviaqa.json \<br>--metric match --ndocs 10 --use_groundness --use_utility --use_seqscore \<br>--dtype half<br></code></pre></td></tr></table></figure>

<h3 id="ARC-Challenge"><a href="#ARC-Challenge" class="headerlink" title="ARC-Challenge"></a>ARC-Challenge</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">python run_short_form.py \<br>  --model_name ../../model/selfrag_llama2_7b \<br>  --input_file ../../data/eval_data/arc_challenge_processed.jsonl \<br>  --max_new_tokens 50 --threshold 0.2 \<br>  --output_file result/arc_challenge.json \<br>  --metric match --ndocs 5 --use_groundness --use_utility --use_seqscore \<br>  --task arc_c<br></code></pre></td></tr></table></figure>

<h3 id="PubHealth"><a href="#PubHealth" class="headerlink" title="PubHealth"></a>PubHealth</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">python run_short_form.py \<br>  --model_name ../../model/selfrag_llama2_7b \<br>  --input_file ../../data/eval_data/health_claims_processed.jsonl \<br>  --max_new_tokens 50 \<br>  --threshold 0.2 --output_file result/health.json \<br>  --metric match --ndocs 5 \<br>  --use_groundness --use_utility --use_seqscore \<br>  --task fever<br></code></pre></td></tr></table></figure>

<h3 id="ASQA"><a href="#ASQA" class="headerlink" title="ASQA"></a>ASQA</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">python run_long_form_static.py \<br>  --model_name ../../model/selfrag_llama2_7b \<br>  --ndocs 5 --max_new_tokens 300 --threshold 0.2 \<br>  --use_grounding --use_utility --use_seqscore \<br>  --task asqa --input_file ../../data/eval_data/asqa_eval_gtr_top100.json \<br>  --output_file result/asqa.json --max_depth 7 --mode always_retrieve \<br></code></pre></td></tr></table></figure>

<h3 id="FactScore"><a href="#FactScore" class="headerlink" title="FactScore"></a>FactScore</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">python run_long_form_static.py \<br>  --model_name ../../model/selfrag_llama2_7b \<br>  --ndocs 5 --max_new_tokens 300 --threshold 0.2 \<br>  --use_grounding --use_utility --use_seqscore \<br>  --task factscore --input_file ../../data/eval_data/factscore_unlabeled_alpaca_13b_retrieval.jsonl \<br>  --output_file factscore.json --max_depth 7 \<br></code></pre></td></tr></table></figure>
                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/" class="category-chain-item">代码复现</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/RAG/" class="print-no-link">#RAG</a>
      
        <a href="/tags/LLM/" class="print-no-link">#LLM</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>【论文复现】SelfRAG</div>
      <div>http://xuan-van.github.io/代码复现/【论文复现】selfrag/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>文晋</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年12月11日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="NC - 非商业性使用">
                    <i class="iconfont icon-cc-nc"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - 相同方式共享">
                    <i class="iconfont icon-cc-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91instructrag/" title="【论文复现】InstructRAG">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">【论文复现】InstructRAG</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8/%E3%80%90git-%E5%85%A5%E9%97%A8%E3%80%91%E5%8A%A8%E6%89%8B%E5%AD%A6%E4%B9%A0-git/" title="【Git 入门】动手学习 Git">
                        <span class="hidden-mobile">【Git 入门】动手学习 Git</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.utils.listenDOMLoaded(function() {
      Fluid.events.registerRefreshCallback(function() {
        if ('mermaid' in window) {
          mermaid.init();
        }
      });
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>




  
<script src="/background/background.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<!-- hexo injector body_end start --><script src="/background/background.js"></script><!-- hexo injector body_end end --></body>
</html>
