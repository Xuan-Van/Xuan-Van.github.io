

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/background/%E5%9B%BE%E6%A0%87.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="文晋">
  <meta name="keywords" content="">
  
    <meta name="description" content=".tnlkkqxqehit{}   模型结构：   参考项目：weizhepei&#x2F;InstructRAG 模型和数据集：meng-lab&#x2F;InstructRAG 1 安装1.1 虚拟环境1234567conda create -n instrag python&#x3D;3.10 -yconda activate instragpip install numpy&#x3D;&#x3D;1.26.4">
<meta property="og:type" content="article">
<meta property="og:title" content="【论文复现】InstructRAG">
<meta property="og:url" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91instructrag/index.html">
<meta property="og:site_name" content="文心晋意">
<meta property="og:description" content=".tnlkkqxqehit{}   模型结构：   参考项目：weizhepei&#x2F;InstructRAG 模型和数据集：meng-lab&#x2F;InstructRAG 1 安装1.1 虚拟环境1234567conda create -n instrag python&#x3D;3.10 -yconda activate instragpip install numpy&#x3D;&#x3D;1.26.4">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91instructrag/1.png">
<meta property="og:image" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91instructrag/2.jpg">
<meta property="article:published_time" content="2025-02-26T04:00:00.000Z">
<meta property="article:modified_time" content="2025-04-11T02:13:43.234Z">
<meta property="article:author" content="文晋">
<meta property="article:tag" content="RAG">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91instructrag/1.png">
  
  
  
  <title>【论文复现】InstructRAG - 文心晋意</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/background/background.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"xuan-van.github.io","root":"/","version":"1.9.8","typing":{"enable":false,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":3},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body><!-- hexo injector body_begin start --><div id="web_bg"></div><!-- hexo injector body_begin end -->
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>文晋的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-image"></i>
                <span>图片</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/images/llama.svg" target="_self">
                    
                    <span>Llama 结构</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">【论文复现】InstructRAG</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-02-26 12:00" pubdate>
          2025年2月26日 中午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          8.3k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          70 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar category-bar" style="margin-right: -1rem">
    





<div class="category-list">
  
  
    
    
    
    <div class="category row nomargin-x">
      <a class="category-item 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="代码复现"
        id="heading-211acd8e7f189296b7caddd5c95b71af" role="tab" data-toggle="collapse" href="#collapse-211acd8e7f189296b7caddd5c95b71af"
        aria-expanded="true"
      >
        代码复现
        <span class="list-group-count">(5)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-211acd8e7f189296b7caddd5c95b71af"
           role="tabpanel" aria-labelledby="heading-211acd8e7f189296b7caddd5c95b71af">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E4%BB%A3%E7%A0%81%E6%8B%86%E8%A7%A3%E3%80%91trajectory-transformer/" title="【代码拆解】Trajectory Transformer"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【代码拆解】Trajectory Transformer</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0%E3%80%91%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0-llama3/" title="【模型复现】从零实现 Llama3"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【模型复现】从零实现 Llama3</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91hipporag-hipporag2/" title="【论文复现】HippoRAG &amp; HippoRAG2"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【论文复现】HippoRAG &amp; HippoRAG2</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91instructrag/" title="【论文复现】InstructRAG"
           class="list-group-item list-group-item-action
           active">
          <span class="category-post">【论文复现】InstructRAG</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91selfrag/" title="【论文复现】SelfRAG"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【论文复现】SelfRAG</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
</div>


  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">【论文复现】InstructRAG</h1>
            
            
              <div class="markdown-body">
                
                <figure style="text-align: center;">
    <style>.tnlkkqxqehit{}</style><img src="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91instructrag/1.png" srcset="/img/loading.gif" lazyload class="tnlkkqxqehit">
</figure>

<p>模型结构：</p>
<img src="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91instructrag/2.jpg" srcset="/img/loading.gif" lazyload class="">

<p>参考项目：<a target="_blank" rel="noopener" href="https://github.com/weizhepei/InstructRAG">weizhepei&#x2F;InstructRAG</a></p>
<p>模型和数据集：<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/meng-lab/InstructRAG">meng-lab&#x2F;InstructRAG</a></p>
<h1 id="1-安装"><a href="#1-安装" class="headerlink" title="1 安装"></a>1 安装</h1><h2 id="1-1-虚拟环境"><a href="#1-1-虚拟环境" class="headerlink" title="1.1 虚拟环境"></a>1.1 虚拟环境</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda create -n instrag python=3.10 -y<br>conda activate instrag<br>pip install numpy==1.26.4 vllm==0.4.1 accelerate ipykernel<br>python -m ipykernel install --user --name instrag<br>jupyter kernelspec list<br>pip install flash-attn==2.5.6 --no-build-isolation<br>pip install peft <span class="hljs-comment"># LoRA 微调需要</span><br></code></pre></td></tr></table></figure>

<h2 id="1-2-项目结构"><a href="#1-2-项目结构" class="headerlink" title="1.2 项目结构"></a>1.2 项目结构</h2><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs nix">dataset<span class="hljs-symbol">/</span> <span class="hljs-comment"># 保存每个问答数据集的样例、训练集、测试集</span><br>eval_results<span class="hljs-symbol">/</span> <span class="hljs-comment"># 保存测试集的答案和评估结果</span><br>records<span class="hljs-symbol">/</span> <span class="hljs-comment"># 保存日志</span><br>saved_checkpoints<span class="hljs-symbol">/</span> <span class="hljs-comment"># 保存 LoRA 微调的模型文件</span><br>saved_models<span class="hljs-symbol">/</span> <span class="hljs-comment"># 保存完整的监督微调后的模型</span><br>src<span class="hljs-symbol">/</span> <span class="hljs-comment"># 保存项目脚本</span><br>finetune.ipynb <span class="hljs-comment"># 拆解 finetune.py</span><br>inference.ipynb <span class="hljs-comment"># 拆解 inference.py</span><br></code></pre></td></tr></table></figure>

<h2 id="1-3-LLM"><a href="#1-3-LLM" class="headerlink" title="1.3 LLM"></a>1.3 LLM</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">huggingface-cli download --token Your_token meta-llama/Meta-Llama-3-8B-Instruct --local-dir model/Llama-3-8B-Instruct<br></code></pre></td></tr></table></figure>

<h2 id="1-4-数据集"><a href="#1-4-数据集" class="headerlink" title="1.4 数据集"></a>1.4 数据集</h2><h3 id="1-4-1-原始数据集"><a href="#1-4-1-原始数据集" class="headerlink" title="1.4.1 原始数据集"></a>1.4.1 原始数据集</h3><p>下载原始数据集：<code>huggingface-cli download --token Your_token --repo-type dataset meng-lab/InstructRAG --local-dir dataset/origin</code></p>
<ol>
<li>ASQA：</li>
</ol>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> str list<span class="hljs-punctuation">,</span> # 只有 <span class="hljs-number">1</span> 个答案<br>    <span class="hljs-attr">&quot;qa_pairs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> str list<span class="hljs-punctuation">,</span> # 有多个答案<br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        ... # 有多个问答对<br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>

<ol start="2">
<li>2WikiMultiHopQA &amp; NaturalQuestions：</li>
</ol>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> str list<span class="hljs-punctuation">,</span> # 只有 <span class="hljs-number">1</span> 个答案<br>    <span class="hljs-attr">&quot;qa_pairs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>

<ol start="3">
<li>PopQA &amp; TriviaQA：</li>
</ol>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> str list<span class="hljs-punctuation">,</span> # 有多个答案<br>    <span class="hljs-attr">&quot;qa_pairs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>

<h3 id="1-4-2-生成理由的数据集"><a href="#1-4-2-生成理由的数据集" class="headerlink" title="1.4.2 生成理由的数据集"></a>1.4.2 生成理由的数据集</h3><p>下载生成理由的数据集：<a target="_blank" rel="noopener" href="https://drive.google.com/file/d/1MVkdc4g9_D4REtaBFKeJ9gMun4qzdQtO/view?usp=share_link">google drive</a></p>
<ol>
<li>ASQA：</li>
</ol>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> str list<span class="hljs-punctuation">,</span> # 只有 <span class="hljs-number">1</span> 个答案<br>    <span class="hljs-attr">&quot;qa_pairs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> str list<span class="hljs-punctuation">,</span> # 有多个答案<br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        ... # 有多个问答对<br>    <span class="hljs-punctuation">]</span><br>    <span class="hljs-attr">&quot;rationale&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # test.json 没有<br>    <span class="hljs-attr">&quot;ctxs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;score&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;has_answer&quot;</span><span class="hljs-punctuation">:</span> str # 只有 test.json 有<br>        <span class="hljs-punctuation">&#125;</span><br>        ... # 多个上下文<br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>

<ol start="2">
<li>2WikiMultiHopQA &amp; NaturalQuestions：</li>
</ol>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> str list<span class="hljs-punctuation">,</span> # 只有 <span class="hljs-number">1</span> 个答案<br>    <span class="hljs-attr">&quot;qa_pairs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;rationale&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # test.json 没有<br>    <span class="hljs-attr">&quot;ctxs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;score&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;has_answer&quot;</span><span class="hljs-punctuation">:</span> bool<br>        <span class="hljs-punctuation">&#125;</span><br>        ... # 多个上下文<br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>

<ol start="3">
<li>PopQA &amp; TrivialQA：</li>
</ol>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> str list<span class="hljs-punctuation">,</span> # 有多个答案<br>    <span class="hljs-attr">&quot;qa_pairs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;rationale&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # test.json 没有<br>    <span class="hljs-attr">&quot;ctxs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;score&quot;</span><span class="hljs-punctuation">:</span> str<br>        <span class="hljs-punctuation">&#125;</span><br>        ... # 多个上下文<br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>

<h1 id="2-整体流程"><a href="#2-整体流程" class="headerlink" title="2 整体流程"></a>2 整体流程</h1><h2 id="2-1-使用自定义查询进行检索"><a href="#2-1-使用自定义查询进行检索" class="headerlink" title="2.1 使用自定义查询进行检索"></a>2.1 使用自定义查询进行检索</h2><p>使用带有预构建检索语料库（例如维基百科）索引的 <a target="_blank" rel="noopener" href="https://github.com/castorini/pyserini">Pyserini</a>。</p>
<ol>
<li>稀疏检索（BM25）：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pyserini.search.lucene <span class="hljs-keyword">import</span> LuceneSearcher<br><br><span class="hljs-comment"># 使用 Wikipedia 转储 作为检索源</span><br>searcher = LuceneSearcher.from_prebuilt_index(<span class="hljs-string">&#x27;wikipedia-dpr&#x27;</span>) <br><span class="hljs-comment"># 检索与给定查询相关的文档</span><br>hits = searcher.search(<span class="hljs-string">&#x27;who got the first nobel prize in physics&#x27;</span>)<br><span class="hljs-comment"># 显示检索到的文档和相关性分数</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;doc: <span class="hljs-subst">&#123;searcher.doc(hits[<span class="hljs-number">0</span>].docid).raw()&#125;</span>\nscore: <span class="hljs-subst">&#123;hits[<span class="hljs-number">0</span>].score&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>

<ol start="2">
<li>密集检索（DPR）：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pyserini.search.faiss <span class="hljs-keyword">import</span> FaissSearcher, DprQueryEncoder<br><br><span class="hljs-comment"># 加载查询编码器</span><br>encoder = DprQueryEncoder(<span class="hljs-string">&quot;facebook/dpr-question_encoder-single-nq-base&quot;</span>)<br><span class="hljs-comment"># 使用 Wikipedia 转储 作为检索源</span><br>searcher = FaissSearcher.from_prebuilt_index(<span class="hljs-string">&#x27;wikipedia-dpr-100w.dpr-single-nq&#x27;</span>, encoder)<br><span class="hljs-comment"># 检索与给定查询相关的文档</span><br>hits = searcher.search(<span class="hljs-string">&#x27;who got the first nobel prize in physics&#x27;</span>)<br><span class="hljs-comment"># 显示检索到的文档和相关性分数</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;doc: <span class="hljs-subst">&#123;searcher.doc(hits[<span class="hljs-number">0</span>].docid).raw()&#125;</span>\nscore: <span class="hljs-subst">&#123;hits[<span class="hljs-number">0</span>].score&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>

<h2 id="2-2-生成理由"><a href="#2-2-生成理由" class="headerlink" title="2.2 生成理由"></a>2.2 生成理由</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">DATASET=PopQA  <span class="hljs-comment"># [PopQA, TriviaQA, NaturalQuestions, 2WikiMultiHopQA, ASQA]</span><br><br>CUDA_VISIBLE_DEVICES=0 python src/inference.py \<br>  --dataset_name <span class="hljs-variable">$DATASET</span> \<br>  --model_name_or_path meta-llama/Meta-Llama-3-8B-Instruct \<br>  --n_docs 5 \<br>  --output_dir dataset/<span class="hljs-variable">$&#123;DATASET&#125;</span>\<br>  --do_rationale_generation \<br></code></pre></td></tr></table></figure>

<h2 id="2-3-监督微调"><a href="#2-3-监督微调" class="headerlink" title="2.3 监督微调"></a>2.3 监督微调</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs bash">DATASET=PopQA <span class="hljs-comment"># [PopQA, TriviaQA, NaturalQuestions, 2WikiMultiHopQA, ASQA]</span><br>PER_DEVICE_BATCH_SIZE=1<br>NUM_DEVICE=4<br>TOTAL_BATCH_SIZE=128<br>GRADIENT_ACC_STEPS=$((<span class="hljs-variable">$TOTAL_BATCH_SIZE</span>/<span class="hljs-variable">$NUM_DEVICE</span>/<span class="hljs-variable">$PER_DEVICE_BATCH_SIZE</span>))<br><br>CUDA_VISIBLE_DEVICES=<span class="hljs-string">&quot;0,1,2,3&quot;</span> torchrun --nproc_per_node=<span class="hljs-variable">$NUM_DEVICE</span> src/finetune.py \<br>  --model_name_or_path ../model/Llama-3-8B-Instruct \<br>  --dataset_name <span class="hljs-variable">$DATASET</span> \<br>  --output_dir saved_checkpoints/InstructRAG-FT/<span class="hljs-variable">$&#123;DATASET&#125;</span> \<br>  --per_device_train_batch_size <span class="hljs-variable">$PER_DEVICE_BATCH_SIZE</span> \<br>  --gradient_accumulation_steps <span class="hljs-variable">$GRADIENT_ACC_STEPS</span> \<br>  --num_train_epochs 2 \<br>  --n_docs 5 \<br>  --learning_rate 2.5e-5 \<br>  --lr_scheduler_type <span class="hljs-string">&quot;cosine&quot;</span> \<br>  --bf16 False \<br>  --tf32 False \<br>  --logging_steps 1 \<br>  --weight_decay 0.0 \<br>  --warmup_ratio 0.03 \<br>  --seed 42 \<br>  --model_max_length 4096 \<br>  --ddp_timeout 1800 \<br>  --fsdp <span class="hljs-string">&quot;full_shard auto_wrap&quot;</span> \<br>  --fsdp_transformer_layer_cls_to_wrap <span class="hljs-string">&quot;LlamaDecoderLayer&quot;</span> \<br>  --lora_enable \<br>  --lora_r 16 \<br>  --lora_alpha 32 \<br>  --lora_dropout 0.05<br></code></pre></td></tr></table></figure>

<h2 id="2-4-合并-LoRA"><a href="#2-4-合并-LoRA" class="headerlink" title="2.4 合并 LoRA"></a>2.4 合并 LoRA</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">DATASET=PopQA <span class="hljs-comment"># [PopQA, TriviaQA, NaturalQuestions, 2WikiMultiHopQA, ASQA]</span><br><span class="hljs-built_in">mkdir</span> -p saved_models/InstructRAG-FT/<span class="hljs-variable">$DATASET</span><br><br>python src/merge.py --base_model_path ../model/Llama-3-8B-Instruct --adapter_path saved_checkpoints/InstructRAG-FT/<span class="hljs-variable">$DATASET</span> --output_path saved_models/InstructRAG-FT/<span class="hljs-variable">$DATASET</span><br></code></pre></td></tr></table></figure>

<p><code>merge.py</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer<br><span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> PeftModel<br><span class="hljs-keyword">import</span> argparse<br><br>parser = argparse.ArgumentParser()<br>parser.add_argument(<span class="hljs-string">&quot;--base_model_path&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;原始模型路径&quot;</span>)<br>parser.add_argument(<span class="hljs-string">&quot;--adapter_path&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;适配器文件夹路径&quot;</span>)<br>parser.add_argument(<span class="hljs-string">&quot;--output_path&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;合并后的模型保存路径&quot;</span>)<br>args = parser.parse_args()<br><br>base_model = AutoModelForCausalLM.from_pretrained(args.base_model_path) <span class="hljs-comment"># 加载基础模型</span><br>lora_model = PeftModel.from_pretrained(base_model, args.adapter_path) <span class="hljs-comment"># 加载 LoRA 适配器</span><br>merged_model = lora_model.merge_and_unload() <span class="hljs-comment"># 合并模型</span><br><br><span class="hljs-comment"># 加载微调后的Tokenizer（包含任何新特殊标记）</span><br>tokenizer = AutoTokenizer.from_pretrained(args.adapter_path)<br><br><span class="hljs-comment"># 保存合并后的模型和Tokenizer</span><br>merged_model.save_pretrained(args.output_path)<br>tokenizer.save_pretrained(args.output_path)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;合并后的模型已保存到：<span class="hljs-subst">&#123;args.output_path&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

<h2 id="2-5-推理和评估"><a href="#2-5-推理和评估" class="headerlink" title="2.5 推理和评估"></a>2.5 推理和评估</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">DATASET=PopQA <span class="hljs-comment"># [PopQA, TriviaQA, NaturalQuestions, 2WikiMultiHopQA, ASQA]</span><br>MODEL=InstructRAG-FT <span class="hljs-comment"># [InstructRAG-FT, InstructRAG-ICL]</span><br><br>CUDA_VISIBLE_DEVICES=0 python src/inference.py \<br>  --dataset_name <span class="hljs-variable">$DATASET</span> \<br>  --rag_model <span class="hljs-variable">$MODEL</span> \<br>  --n_docs 5 \<br>  --output_dir eval_results/<span class="hljs-variable">$&#123;MODEL&#125;</span>/<span class="hljs-variable">$&#123;DATASET&#125;</span> \<br>  --load_local_model<br></code></pre></td></tr></table></figure>

<h1 id="3-脚本分析"><a href="#3-脚本分析" class="headerlink" title="3 脚本分析"></a>3 脚本分析</h1><p>下面将以 <code>ASQA</code> 数据集的 <code>demo.json</code> 为例，拆解 <code>finetune.py</code> 和 <code>inference.py</code>，介绍整个项目的运行逻辑和数据流向。拆解过程中将 <code>log_utils.py</code> 换成了 <code>print</code>，便于查看当前状态。</p>
<h2 id="3-1-finetune-py：监督微调"><a href="#3-1-finetune-py：监督微调" class="headerlink" title="3.1 finetune.py：监督微调"></a>3.1 finetune.py：监督微调</h2><ol>
<li>导入必要的包：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> transformers<br><span class="hljs-keyword">import</span> types<br><span class="hljs-keyword">import</span> dataclasses<br><span class="hljs-keyword">import</span> io<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> copy<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Literal</span><br><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> partial<br><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass, field<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer, AutoModelForCausalLM<br><span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> LoraConfig, TaskType, get_peft_model<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Dict</span>, <span class="hljs-type">Sequence</span>, <span class="hljs-type">Union</span><br></code></pre></td></tr></table></figure>

<ol start="2">
<li>定义模型参数，添加了 LoRA 微调功能：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ModelArguments</span>:<br>    model_name_or_path: <span class="hljs-built_in">str</span> = field(  <span class="hljs-comment"># 模型名称或路径</span><br>        default=<span class="hljs-literal">None</span>,<br>        metadata=&#123;<span class="hljs-string">&quot;help&quot;</span>: <span class="hljs-string">&quot;Name to a huggingface native pretrained model or path to a model on disk.&quot;</span>&#125;<br>    )<br>    lora_enable: <span class="hljs-built_in">bool</span> = field(  <span class="hljs-comment"># 是否启用 LoRA 进行微调</span><br>        default=<span class="hljs-literal">False</span>,<br>        metadata=&#123;<span class="hljs-string">&quot;help&quot;</span>: <span class="hljs-string">&quot;Whether to enable LoRA for fine-tuning.&quot;</span>&#125;<br>    )<br>    lora_r: <span class="hljs-built_in">int</span> = field(  <span class="hljs-comment"># LoRA 的注意力维度</span><br>        default=<span class="hljs-number">16</span>,<br>        metadata=&#123;<span class="hljs-string">&quot;help&quot;</span>: <span class="hljs-string">&quot;LoRA attention dimension.&quot;</span>&#125;<br>    )<br>    lora_alpha: <span class="hljs-built_in">int</span> = field(  <span class="hljs-comment"># LoRA 的 alpha 缩放因子</span><br>        default=<span class="hljs-number">32</span>,<br>        metadata=&#123;<span class="hljs-string">&quot;help&quot;</span>: <span class="hljs-string">&quot;LoRA alpha scaling.&quot;</span>&#125;<br>    )<br>    lora_dropout: <span class="hljs-built_in">float</span> = field(  <span class="hljs-comment"># LoRA 的 dropout 概率</span><br>        default=<span class="hljs-number">0.05</span>,<br>        metadata=&#123;<span class="hljs-string">&quot;help&quot;</span>: <span class="hljs-string">&quot;LoRA dropout probability.&quot;</span>&#125;<br>    )<br>    <br>model_args = ModelArguments(model_name_or_path=<span class="hljs-string">&quot;../model/Llama-3-8B-Instruct&quot;</span>, lora_enable=<span class="hljs-literal">True</span>, lora_r=<span class="hljs-number">16</span>, lora_alpha=<span class="hljs-number">32</span>, lora_dropout=<span class="hljs-number">0.05</span>)<br></code></pre></td></tr></table></figure>

<ol start="3">
<li>定义数据参数：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DataArguments</span>:<br>    dataset_name: <span class="hljs-built_in">str</span> = field(  <span class="hljs-comment"># 数据集名称</span><br>        default=<span class="hljs-literal">None</span>,<br>        metadata=&#123;<br>            <span class="hljs-string">&quot;help&quot;</span>: <span class="hljs-string">&quot;Name of the dataset to load.&quot;</span><br>        &#125;<br>    )<br><br>    prompt_dict_path: <span class="hljs-built_in">str</span> = field(  <span class="hljs-comment"># 提示词字典路径</span><br>        default=<span class="hljs-string">&quot;src/rag.json&quot;</span>,<br>        metadata=&#123;<br>            <span class="hljs-string">&quot;help&quot;</span>: <span class="hljs-string">&quot;Path to the dictionary for the prompt to format examples&quot;</span><br>        &#125;<br>    )<br><br>    n_docs: <span class="hljs-built_in">int</span> = field(  <span class="hljs-comment"># 每个示例检索的文档数量</span><br>        default=<span class="hljs-number">5</span>,<br>        metadata=&#123;<br>            <span class="hljs-string">&quot;help&quot;</span>: <span class="hljs-string">&quot;Number of documents retrieved for each example.&quot;</span><br>        &#125;<br>    )<br><br>data_args = DataArguments(dataset_name=<span class="hljs-string">&quot;ASQA&quot;</span>)<br></code></pre></td></tr></table></figure>

<ol start="4">
<li>定义训练参数：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TrainingArguments</span>(transformers.TrainingArguments):<br>    cache_dir: <span class="hljs-built_in">str</span> = field(default=<span class="hljs-literal">None</span>)  <span class="hljs-comment"># 缓存目录</span><br>    optim: <span class="hljs-built_in">str</span> = field(default=<span class="hljs-string">&quot;adamw_torch&quot;</span>)  <span class="hljs-comment"># 优化器</span><br>    model_max_length: <span class="hljs-built_in">int</span> = field(  <span class="hljs-comment"># 模型的最大序列长度</span><br>        default=<span class="hljs-number">4096</span>,<br>        metadata=&#123;<br>            <span class="hljs-string">&quot;help&quot;</span>: <span class="hljs-string">&quot;Maximum sequence length. Sequences will be right padded to this length (and possibly truncated).&quot;</span><br>            <span class="hljs-string">&quot;Enforcing a consistent max length ensures memory usage is constant and predictable.&quot;</span><br>        &#125;<br>    )<br><br>    padding: <span class="hljs-type">Literal</span>[<span class="hljs-string">&quot;max_length&quot;</span>, <span class="hljs-string">&quot;longest&quot;</span>] = field(  <span class="hljs-comment"># 填充策略</span><br>        default=<span class="hljs-string">&quot;longest&quot;</span>,<br>        metadata=&#123;<br>            <span class="hljs-string">&quot;help&quot;</span>: <span class="hljs-string">&quot;Padding strategy. If &#x27;max_length&#x27;, pads to `model_max_length` always; this might lead to some &quot;</span><br>            <span class="hljs-string">&quot;redundant compute. If &#x27;longest&#x27;, pads to the longest sequence in the batch, capped by `model_max_length`.&quot;</span><br>        &#125;<br>    )<br><br>    resume_from_checkpoint: <span class="hljs-built_in">bool</span> = field(  <span class="hljs-comment"># 是否从检查点恢复</span><br>        default=<span class="hljs-literal">False</span>,<br>        metadata=&#123;<span class="hljs-string">&quot;help&quot;</span>: <span class="hljs-string">&quot;If True, loads from last check point.&quot;</span>&#125;<br>    )<br><br>    use_fast_tokenizer: <span class="hljs-built_in">bool</span> = field(  <span class="hljs-comment"># 是否使用快速分词器</span><br>        default=<span class="hljs-literal">False</span>,<br>        metadata=&#123;<br>            <span class="hljs-string">&quot;help&quot;</span>: <span class="hljs-string">&quot;Use fast tokenizer if True. &quot;</span><br>            <span class="hljs-string">&quot;Fast LLaMA tokenizer forces protobuf downgrade to 3.20.3. &quot;</span><br>            <span class="hljs-string">&quot;Use fast tokenizer only if you can live with that.&quot;</span><br>        &#125;<br>    )<br>    <br>PER_DEVICE_BATCH_SIZE=<span class="hljs-number">1</span> <span class="hljs-comment"># 设置每个设备的批次大小为1</span><br>NUM_DEVICE=<span class="hljs-number">4</span> <span class="hljs-comment"># 设置使用的设备数量为4</span><br>TOTAL_BATCH_SIZE=<span class="hljs-number">128</span> <span class="hljs-comment"># 设置总批次大小为128</span><br>GRADIENT_ACC_STEPS=((TOTAL_BATCH_SIZE//NUM_DEVICE//PER_DEVICE_BATCH_SIZE)) <span class="hljs-comment"># 梯度累积步数</span><br>training_args = TrainingArguments(<br>    output_dir=<span class="hljs-string">&quot;./&quot;</span>, <span class="hljs-comment"># 输出目录</span><br>    per_device_train_batch_size=PER_DEVICE_BATCH_SIZE, <br>    gradient_accumulation_steps=GRADIENT_ACC_STEPS, <br>    num_train_epochs=<span class="hljs-number">2</span>, <span class="hljs-comment"># 训练总轮数</span><br>    learning_rate=<span class="hljs-number">2.5e-5</span>, <span class="hljs-comment"># 学习率</span><br>    lr_scheduler_type=<span class="hljs-string">&quot;cosine&quot;</span>, <span class="hljs-comment"># 学习率调度器</span><br>    bf16=<span class="hljs-literal">False</span>, <span class="hljs-comment"># 不启用bfloat16精度</span><br>    tf32=<span class="hljs-literal">False</span>, <span class="hljs-comment"># 不启用TensorFloat-32精度</span><br>    logging_steps=<span class="hljs-number">1</span>, <span class="hljs-comment"># 每1步记录一次日志</span><br>    weight_decay=<span class="hljs-number">0.0</span>, <span class="hljs-comment"># 权重衰减</span><br>    warmup_ratio=<span class="hljs-number">0.03</span>, <span class="hljs-comment"># 预热步数占总训练步数的3%</span><br>    seed=<span class="hljs-number">42</span>, <span class="hljs-comment"># 随机种子设为42</span><br>    model_max_length=<span class="hljs-number">4096</span>, <span class="hljs-comment"># 模型最大输入长度</span><br>    ddp_timeout=<span class="hljs-number">1800</span>, <span class="hljs-comment"># DDP（分布式数据并行）超时时间设为1800秒</span><br>    fsdp=<span class="hljs-string">&quot;full_shard auto_wrap&quot;</span>, <span class="hljs-comment"># 使用完全分片数据并行（FSDP）策略，自动包装指定层</span><br>    fsdp_transformer_layer_cls_to_wrap=<span class="hljs-string">&quot;LlamaDecoderLayer&quot;</span> <span class="hljs-comment"># 指定要包装的Transformer层为LlamaDecoderLayer</span><br>)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">TrainingArguments(output_dir=&#39;/&#39;, overwrite_output_dir=False, do_train=False, do_eval=False, do_predict=False, eval_strategy=&lt;IntervalStrategy.NO: &#39;no&#39;&gt;, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=32, eval_accumulation_steps=None, eval_delay=0, torch_empty_cache_steps=None, learning_rate=2.5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=2, max_steps=-1, lr_scheduler_type=&lt;SchedulerType.COSINE: &#39;cosine&#39;&gt;, lr_scheduler_kwargs=&#123;&#125;, warmup_ratio=0.03, warmup_steps=0, log_level=&#39;passive&#39;, log_level_replica=&#39;warning&#39;, log_on_each_node=True, logging_dir=&#39;/runs/Apr10_12-14-05_89a604750497&#39;, logging_strategy=&lt;IntervalStrategy.STEPS: &#39;steps&#39;&gt;, logging_first_step=False, logging_steps=1, logging_nan_inf_filter=True, save_strategy=&lt;SaveStrategy.STEPS: &#39;steps&#39;&gt;, save_steps=500, save_total_limit=None, save_safetensors=True, save_on_each_node=False, save_only_model=False, restore_callback_states_from_checkpoint=False, no_cuda=False, use_cpu=False, use_mps_device=False, seed=42, data_seed=None, jit_mode_eval=False, use_ipex=False, bf16=False, fp16=False, fp16_opt_level=&#39;O1&#39;, half_precision_backend=&#39;auto&#39;, bf16_full_eval=False, fp16_full_eval=False, tf32=False, local_rank=0, ddp_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=None, dataloader_num_workers=0, dataloader_prefetch_factor=None, past_index=-1, run_name=&#39;/&#39;, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, fsdp=[&lt;FSDPOption.FULL_SHARD: &#39;full_shard&#39;&gt;, &lt;FSDPOption.AUTO_WRAP: &#39;auto_wrap&#39;&gt;], fsdp_min_num_params=0, fsdp_config=&#123;&#39;min_num_params&#39;: 0, &#39;transformer_layer_cls_to_wrap&#39;: [&#39;LlamaDecoderLayer&#39;], &#39;xla&#39;: False, &#39;xla_fsdp_v2&#39;: False, &#39;xla_fsdp_grad_ckpt&#39;: False&#125;, fsdp_transformer_layer_cls_to_wrap=&#39;LlamaDecoderLayer&#39;, accelerator_config=AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None, use_configured_state=False), deepspeed=None, label_smoothing_factor=0.0, optim=&lt;OptimizerNames.ADAMW_TORCH: &#39;adamw_torch&#39;&gt;, optim_args=None, adafactor=False, group_by_length=False, length_column_name=&#39;length&#39;, report_to=[], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, ddp_broadcast_buffers=None, dataloader_pin_memory=True, dataloader_persistent_workers=False, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=False, hub_model_id=None, hub_strategy=&lt;HubStrategy.EVERY_SAVE: &#39;every_save&#39;&gt;, hub_token=None, hub_private_repo=None, hub_always_push=False, gradient_checkpointing=False, gradient_checkpointing_kwargs=None, include_inputs_for_metrics=False, include_for_metrics=[], eval_do_concat_batches=True, fp16_backend=&#39;auto&#39;, evaluation_strategy=None, push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters=&#39;&#39;, auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope=&#39;last&#39;, ddp_timeout=1800, torch_compile=False, torch_compile_backend=None, torch_compile_mode=None, dispatch_batches=None, split_batches=None, include_tokens_per_second=False, include_num_input_tokens_seen=False, neftune_noise_alpha=None, optim_target_modules=None, batch_eval_metrics=False, eval_on_start=False, use_liger_kernel=False, eval_use_gather_object=False, average_tokens_across_devices=False, cache_dir=None, model_max_length=4096, padding=&#39;longest&#39;, use_fast_tokenizer=False)
</code></pre>
<ol start="5">
<li>加载 <code>common_utils.py</code> 中的函数：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 分布式环境中对象创建可能非常消耗内存，这个类在奇数和偶数rank上交错创建对象，避免所有对象同时创建，假设local_rank == -1表示不使用分布式训练</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">staggered_object_creation</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, local_rank: <span class="hljs-built_in">int</span>, world_size: <span class="hljs-built_in">int</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.local_rank = local_rank  <span class="hljs-comment"># 当前rank</span><br>        <span class="hljs-variable language_">self</span>.world_size = world_size  <span class="hljs-comment"># 总rank数</span><br><br>    <span class="hljs-comment"># 进入上下文时偶数rank等待</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__enter__</span>(<span class="hljs-params">self, *args, **kwargs</span>):<br>        <span class="hljs-keyword">del</span> args, kwargs<br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.world_size &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> <span class="hljs-variable language_">self</span>.local_rank % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>:<br>            dist.barrier()  <span class="hljs-comment"># 分布式屏障</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span><br><br>    <span class="hljs-comment"># 退出上下文时奇数rank先完成，然后所有rank同步</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__exit__</span>(<span class="hljs-params">self, *args, **kwargs</span>):<br>        <span class="hljs-keyword">del</span> args, kwargs<br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.world_size &gt; <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.local_rank % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>:<br>                dist.barrier()<br>            dist.barrier()  <span class="hljs-comment"># 最终安全屏障</span><br><br>    <span class="hljs-comment"># 装饰器用法</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, func</span>):<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">decorator</span>(<span class="hljs-params">*args, **kwargs</span>):<br>            <span class="hljs-keyword">with</span> <span class="hljs-variable language_">self</span>:<br>                <span class="hljs-keyword">return</span> func(*args, **kwargs)<br>        <span class="hljs-keyword">return</span> decorator<br><br><span class="hljs-comment"># 修改模型的zero_grad方法以节省内存    </span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">let_model_save_mem_when_zero_grad</span>(<span class="hljs-params">model: torch.nn.Module</span>):<br>    <span class="hljs-comment"># 将所有模型参数的梯度设置为零或None    </span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">new_zero_grad</span>(<span class="hljs-params">self, set_to_none: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span></span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">getattr</span>(<span class="hljs-variable language_">self</span>, <span class="hljs-string">&quot;_is_replica&quot;</span>, <span class="hljs-literal">False</span>):<br>            warnings.warn(<br>                <span class="hljs-string">&quot;Calling .zero_grad() from a module created with nn.DataParallel() has no effect. &quot;</span><br>                <span class="hljs-string">&quot;The parameters are copied (in a differentiable manner) from the original module. &quot;</span><br>                <span class="hljs-string">&quot;This means they are not leaf nodes in autograd and so don&#x27;t accumulate gradients. &quot;</span><br>                <span class="hljs-string">&quot;If you need gradients in your forward method, consider using autograd.grad instead.&quot;</span><br>            )<br><br>        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.parameters():<br>            <span class="hljs-keyword">if</span> p.grad <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                <span class="hljs-keyword">if</span> set_to_none:  <span class="hljs-comment"># 设置为None更节省内存</span><br>                    p.grad = <span class="hljs-literal">None</span><br>                <span class="hljs-keyword">else</span>:<br>                    <span class="hljs-keyword">if</span> p.grad.grad_fn <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                        p.grad.detach_()<br>                    <span class="hljs-keyword">else</span>:<br>                        p.grad.requires_grad_(<span class="hljs-literal">False</span>)<br>                    p.grad.zero_()<br><br>    <span class="hljs-comment"># 动态修改模型的zero_grad方法</span><br>    model.zero_grad = types.MethodType(new_zero_grad, model)<br>    <span class="hljs-keyword">return</span> model<br><br><span class="hljs-comment"># 确保文件对象是可读的IO基类</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_make_r_io_base</span>(<span class="hljs-params">f, mode: <span class="hljs-built_in">str</span></span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(f, io.IOBase):<br>        f = <span class="hljs-built_in">open</span>(f, mode=mode)<br>    <span class="hljs-keyword">return</span> f<br><br><span class="hljs-comment"># 加载JSON文件到字典</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">jload</span>(<span class="hljs-params">f, mode=<span class="hljs-string">&quot;r&quot;</span></span>):<br>    f = _make_r_io_base(f, mode)  <span class="hljs-comment"># 确保文件可读</span><br>    jdict = json.load(f)  <span class="hljs-comment"># 加载JSON</span><br>    f.close()<br>    <span class="hljs-keyword">return</span> jdict<br><br><span class="hljs-comment"># 收集状态字典并保存到磁盘</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">safe_save_model_for_hf_trainer</span>(<span class="hljs-params"></span><br><span class="hljs-params">    trainer: transformers.Trainer, output_dir: <span class="hljs-built_in">str</span>, give_rw_access=<span class="hljs-literal">True</span>, rank0_only=<span class="hljs-literal">True</span></span><br><span class="hljs-params"></span>):<br>    now = time.perf_counter()  <span class="hljs-comment"># 记录开始时间</span><br><br>    <span class="hljs-comment"># 处理FSDP (完全分片数据并行) 情况</span><br>    <span class="hljs-keyword">if</span> trainer.is_fsdp_enabled:<br>        <span class="hljs-comment"># 配置完全状态字典，可选的offload到CPU和rank0_only</span><br>        cfg = FullStateDictConfig(offload_to_cpu=<span class="hljs-literal">True</span>, rank0_only=rank0_only)<br>        <span class="hljs-keyword">with</span> FSDP.state_dict_type(trainer.model, StateDictType.FULL_STATE_DICT, cfg):<br>            state_dict = trainer.model.state_dict()<br>            <span class="hljs-keyword">if</span> trainer.args.should_save:  <span class="hljs-comment"># 只有应该保存的rank才保存</span><br>                trainer._save(output_dir, state_dict=state_dict)  <span class="hljs-comment"># 保存模型</span><br><br>    <span class="hljs-comment"># 处理DeepSpeed情况</span><br>    <span class="hljs-keyword">elif</span> trainer.is_deepspeed_enabled:<br>        <span class="hljs-keyword">if</span> trainer.args.should_save:<br>            trainer._save(output_dir)  <span class="hljs-comment"># DeepSpeed有自己的保存逻辑</span><br><br>    <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># 非FSDP和非DeepSpeed情况</span><br>        state_dict = trainer.model.state_dict()<br>        <span class="hljs-keyword">if</span> trainer.args.should_save:<br>            cpu_state_dict = &#123;key: value.cpu() <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> state_dict.items()&#125;  <span class="hljs-comment"># 转移到CPU</span><br>            <span class="hljs-keyword">del</span> state_dict  <span class="hljs-comment"># 删除原状态字典节省内存</span><br>            trainer._save(output_dir, state_dict=cpu_state_dict)  <span class="hljs-comment"># 保存CPU上的状态字典</span><br><br>    <span class="hljs-keyword">if</span> trainer.args.should_save:<br>        <span class="hljs-keyword">if</span> give_rw_access:  <span class="hljs-comment"># 可选设置目录读写权限</span><br>            <span class="hljs-keyword">try</span>:<br>                os.system(<span class="hljs-string">f&quot;chmod -R a+xwr <span class="hljs-subst">&#123;output_dir&#125;</span>&quot;</span>)<br>            <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Failed to give read-write access to <span class="hljs-subst">&#123;output_dir&#125;</span>: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Saving model took <span class="hljs-subst">&#123;time.perf_counter() - now:<span class="hljs-number">.2</span>f&#125;</span> seconds.&quot;</span>)  <span class="hljs-comment"># 记录保存耗时</span><br></code></pre></td></tr></table></figure>

<ol start="6">
<li>创建上下文管理器：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">ctx_mgr = staggered_object_creation(<br>    local_rank=training_args.local_rank, world_size=training_args.world_size<br>)<br></code></pre></td></tr></table></figure>

<ol start="7">
<li>使用上下文管理器：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> ctx_mgr:<br>    <span class="hljs-comment"># 定义模型的参数</span><br>    model_kwargs = <span class="hljs-built_in">dict</span>(<br>        <span class="hljs-comment">### V100 不能使用 flash_attention</span><br>        <span class="hljs-comment"># attn_implementation=&quot;flash_attention_2&quot;,</span><br>        <span class="hljs-comment">###</span><br>        config=transformers.AutoConfig.from_pretrained(model_args.model_name_or_path),  <span class="hljs-comment"># 从预训练模型加载配置</span><br>        cache_dir=training_args.cache_dir,  <span class="hljs-comment"># 缓存目录</span><br>        low_cpu_mem_usage=<span class="hljs-literal">True</span>,  <span class="hljs-comment"># 低 CPU 内存使用</span><br>        device_map=&#123;<span class="hljs-string">&quot;&quot;</span>: training_args.device.index&#125;,  <span class="hljs-comment"># 设备映射</span><br>    )<br><br>    <span class="hljs-comment"># 加载预训练模型</span><br>    model = AutoModelForCausalLM.from_pretrained(model_args.model_name_or_path, **model_kwargs)<br>    <span class="hljs-comment"># 调用函数优化模型在零梯度时的内存使用</span><br>    let_model_save_mem_when_zero_grad(model)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">Loading checkpoint shards: 100%|██████████| 4/4 [00:36&lt;00:00,  9.21s/it]
</code></pre>
<ol start="8">
<li>加载 tokenizer，设置填充策略：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">tokenizer = transformers.AutoTokenizer.from_pretrained(<br>    model_args.model_name_or_path,<br>    cache_dir=training_args.cache_dir,<br>    model_max_length=training_args.model_max_length,<br>    padding_side=<span class="hljs-string">&quot;right&quot;</span>,<br>    truncation_side=<span class="hljs-string">&quot;left&quot;</span>,<br>    use_fast=training_args.use_fast_tokenizer,<br>)<br><br>tokenizer.padding = training_args.padding<br><span class="hljs-comment"># 如果分词器没有 pad_token，则将其设置为 eos_token</span><br><span class="hljs-keyword">if</span> tokenizer.pad_token <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>    tokenizer.pad_token = tokenizer.eos_token<br></code></pre></td></tr></table></figure>

<ol start="9">
<li>使用 LoRA：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> model_args.lora_enable:<br>    <span class="hljs-comment"># 创建 LoRA 配置</span><br>    lora_config = LoraConfig(<br>        r=model_args.lora_r,<br>        lora_alpha=model_args.lora_alpha,<br>        lora_dropout=model_args.lora_dropout,<br>        target_modules=[<span class="hljs-string">&quot;q_proj&quot;</span>, <span class="hljs-string">&quot;v_proj&quot;</span>],  <span class="hljs-comment"># 目标模块</span><br>        task_type=TaskType.CAUSAL_LM,  <span class="hljs-comment"># 任务类型为因果语言模型</span><br>    )<br>    <span class="hljs-comment"># 获取 LoRA 模型</span><br>    model = get_peft_model(model, lora_config)<br>    <span class="hljs-comment"># 打印可训练参数</span><br>    model.print_trainable_parameters()<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">trainable params: 6,815,744 || all params: 8,037,076,992 || trainable%: 0.0848
</code></pre>
<ol start="10">
<li>加载 <code>data_utils.py</code> 中的函数：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br></pre></td><td class="code"><pre><code class="hljs python">IGNORE_INDEX = -<span class="hljs-number">100</span> <span class="hljs-comment"># 定义忽略索引，用于标记不需要计算损失的token</span><br><br><span class="hljs-comment"># 监督微调数据集类，继承自PyTorch的Dataset</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SFTDataset</span>(torch.utils.data.Dataset):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        data_list: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">dict</span>],</span><br><span class="hljs-params">        prompt_dict: <span class="hljs-built_in">dict</span>,</span><br><span class="hljs-params">        tokenizer: transformers.PreTrainedTokenizer,</span><br><span class="hljs-params">        n_docs: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-built_in">super</span>(SFTDataset, <span class="hljs-variable language_">self</span>).__init__()<br><br>        <span class="hljs-comment"># 预处理数据，生成RAG格式的输入</span><br>        sft_data = preprocess_for_rag(data_list=data_list, prompt_dict=prompt_dict, tokenizer=tokenizer, n_docs=n_docs)<br><br>        <span class="hljs-variable language_">self</span>.input_ids = sft_data[<span class="hljs-string">&quot;input_ids&quot;</span>]  <span class="hljs-comment"># 输入ID</span><br>        <span class="hljs-variable language_">self</span>.labels = sft_data[<span class="hljs-string">&quot;labels&quot;</span>] <span class="hljs-comment"># 标签</span><br><br>        <span class="hljs-variable language_">self</span>.metadata = sft_data[<span class="hljs-string">&quot;metadata&quot;</span>] <span class="hljs-comment"># 元数据</span><br>        <span class="hljs-variable language_">self</span>.tokenization_metadata = sft_data[<span class="hljs-string">&quot;tokenization_metadata&quot;</span>] <span class="hljs-comment"># 分词元数据</span><br><br>    <span class="hljs-comment"># 返回数据集大小</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.input_ids)<br><br>    <span class="hljs-comment"># 获取单个样本</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, i</span>) -&gt; <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, torch.Tensor]:<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">dict</span>(input_ids=<span class="hljs-variable language_">self</span>.input_ids[i], labels=<span class="hljs-variable language_">self</span>.labels[i])<br><br><span class="hljs-comment"># 用于SFT数据集的数据整理器</span><br><span class="hljs-meta">@dataclasses.dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DataCollatorForSFTDataset</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    tokenizer: transformers.PreTrainedTokenizer <span class="hljs-comment"># 分词器</span><br><br>    <span class="hljs-comment"># 对输入ID和标签进行填充，使其长度一致</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, instances: <span class="hljs-type">Sequence</span>[<span class="hljs-type">Dict</span>]</span>) -&gt; <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, torch.Tensor]:<br><br>        input_ids, labels = <span class="hljs-built_in">tuple</span>([instance[key] <span class="hljs-keyword">for</span> instance <span class="hljs-keyword">in</span> instances] <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> (<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>))<br>        input_ids = torch.nn.utils.rnn.pad_sequence(<br>            input_ids, batch_first=<span class="hljs-literal">True</span>, padding_value=<span class="hljs-variable language_">self</span>.tokenizer.pad_token_id<br>        )<br>        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=<span class="hljs-literal">True</span>, padding_value=IGNORE_INDEX)<br>        attention_mask = input_ids.ne(<span class="hljs-variable language_">self</span>.tokenizer.pad_token_id).long() <span class="hljs-comment"># 生成注意力掩码</span><br>        <br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">dict</span>(<br>            input_ids=input_ids,<br>            labels=labels,<br>            attention_mask=attention_mask,<br>        )<br><br><span class="hljs-comment"># 创建监督学习数据</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_supervised_data</span>(<span class="hljs-params"></span><br><span class="hljs-params">    tokenizer: transformers.PreTrainedTokenizer,</span><br><span class="hljs-params">    data_args,</span><br><span class="hljs-params"></span>):<br>    <br>    prompt_dict = jload(data_args.prompt_dict_path) <span class="hljs-comment"># 加载提示模板</span><br><br>    data_path = os.path.join(<span class="hljs-string">&#x27;dataset&#x27;</span>, data_args.dataset_name, <span class="hljs-string">&#x27;demo.json&#x27;</span>) <span class="hljs-comment"># 数据路径由 train.json 改为了 demo.json，只有一组数据</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Loading training set from: <span class="hljs-subst">&#123;data_path&#125;</span>&quot;</span>)<br>    data_list = jload(data_path) <span class="hljs-comment"># 加载训练数据</span><br><br>    <span class="hljs-comment"># 创建SFT数据集</span><br>    train_dataset = SFTDataset(<br>        data_list=data_list,<br>        prompt_dict=prompt_dict,<br>        tokenizer=tokenizer,<br>        n_docs=data_args.n_docs,<br>    )<br><br>    data_collator = DataCollatorForSFTDataset(tokenizer=tokenizer) <span class="hljs-comment"># 创建数据整理器</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">dict</span>(train_dataset=train_dataset, data_collator=data_collator) <span class="hljs-comment"># 返回数据集和数据整理器</span><br><br><span class="hljs-comment"># 规范化问题：确保问题以问号结尾且开头格式正确</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalize_question</span>(<span class="hljs-params">question</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> question.endswith(<span class="hljs-string">&quot;?&quot;</span>):<br>        question = question + <span class="hljs-string">&quot;?&quot;</span><br>    <span class="hljs-keyword">if</span> question.startswith(<span class="hljs-string">&quot;.&quot;</span>): <span class="hljs-comment"># 检查是否以 &quot;.&quot; 开头</span><br>        question = question.lstrip(<span class="hljs-string">&quot;. &quot;</span>) <span class="hljs-comment"># 移除开头的 &quot;.&quot; 和空格</span><br><br>    <span class="hljs-keyword">return</span> question[<span class="hljs-number">0</span>].lower() + question[<span class="hljs-number">1</span>:]  <span class="hljs-comment"># 首字母小写</span><br><br><span class="hljs-comment"># 构建上下文文档：保证文档得分升序排列</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_contexts</span>(<span class="hljs-params">example, n_docs</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(example[<span class="hljs-string">&quot;ctxs&quot;</span>]) &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> example[<span class="hljs-string">&quot;ctxs&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;score&quot;</span>] &gt; example[<span class="hljs-string">&quot;ctxs&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;score&quot;</span>]: <span class="hljs-comment"># 如果第一个文档分数更高，则反转列表</span><br>        ctxs_list = example[<span class="hljs-string">&quot;ctxs&quot;</span>][:n_docs][::-<span class="hljs-number">1</span>]  <br>    <span class="hljs-keyword">else</span>: <span class="hljs-comment"># 否则直接取前n_docs个文档</span><br>        ctxs_list = example[<span class="hljs-string">&quot;ctxs&quot;</span>][:n_docs]  <br><br>    <span class="hljs-comment"># 格式化文档文本</span><br>    docs_text = <span class="hljs-string">&quot;\n\n&quot;</span>.join([<span class="hljs-string">f&quot;Document <span class="hljs-subst">&#123;idx+<span class="hljs-number">1</span>&#125;</span> (Title: <span class="hljs-subst">&#123;ctx[<span class="hljs-string">&#x27;title&#x27;</span>]&#125;</span>): <span class="hljs-subst">&#123;ctx[<span class="hljs-string">&#x27;text&#x27;</span>]&#125;</span>&quot;</span> <span class="hljs-keyword">for</span> idx, ctx <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(ctxs_list)])<br>    doc_prompt = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;docs_text&#125;</span>\n\n&quot;</span><br>    <br>    <span class="hljs-keyword">return</span> doc_prompt<br>    <br><span class="hljs-comment"># 预处理数据，生成RAG格式的输入</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_for_rag</span>(<span class="hljs-params"></span><br><span class="hljs-params">    data_list: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">dict</span>],</span><br><span class="hljs-params">    prompt_dict: <span class="hljs-built_in">dict</span>,</span><br><span class="hljs-params">    tokenizer: transformers.PreTrainedTokenizer,</span><br><span class="hljs-params">    n_docs: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">    verbose=<span class="hljs-literal">True</span>,</span><br><span class="hljs-params"></span>) -&gt; <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Union</span>[torch.Tensor, <span class="hljs-type">Sequence</span>[torch.Tensor]]]:<br><br>    sources = [] <span class="hljs-comment"># 源文本</span><br>    targets = [] <span class="hljs-comment"># 目标文本</span><br><br>    assistant_prefix = prompt_dict[<span class="hljs-string">&#x27;assistant_prefix&#x27;</span>]  <span class="hljs-comment"># 助手前缀</span><br>    assist_prefix_len = <span class="hljs-built_in">len</span>(tokenizer.encode(assistant_prefix, add_special_tokens=<span class="hljs-literal">False</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)[<span class="hljs-number">0</span>])  <span class="hljs-comment"># 前缀长度</span><br><br>    user_prefix = prompt_dict[<span class="hljs-string">&#x27;user_prefix&#x27;</span>]  <span class="hljs-comment"># 用户前缀</span><br>    user_prefix_id = tokenizer.encode(user_prefix, add_special_tokens=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 用户前缀ID</span><br>    user_prefix_len = <span class="hljs-built_in">len</span>(user_prefix_id)  <span class="hljs-comment"># 用户前缀长度</span><br><br>    <span class="hljs-keyword">for</span> sample <span class="hljs-keyword">in</span> data_list:<br>        query_prompt = prompt_dict[<span class="hljs-string">&#x27;query_prompt&#x27;</span>] + normalize_question(sample[<span class="hljs-string">&#x27;question&#x27;</span>])  <span class="hljs-comment"># 查询提示</span><br>        doc_prompt = build_contexts(sample, n_docs=n_docs)  <span class="hljs-comment"># 文档提示</span><br>        sources.append(doc_prompt + query_prompt)  <span class="hljs-comment"># 组合源文本</span><br>    <br>        target_prompt = assistant_prefix + sample[<span class="hljs-string">&#x27;rationale&#x27;</span>] + tokenizer.eos_token  <span class="hljs-comment"># 目标文本</span><br>        targets.append(target_prompt)<br><br>    examples = [s + t <span class="hljs-keyword">for</span> s, t <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(sources, targets)]  <span class="hljs-comment"># 组合源和目标</span><br>    examples_tokenized = _tokenize_fn(examples, tokenizer, max_len_offset = [user_prefix_len] * <span class="hljs-built_in">len</span>(examples), add_special_tokens=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 分词</span><br><br>    input_ids = [torch.cat([user_prefix_id, ctx]) <span class="hljs-keyword">for</span> ctx <span class="hljs-keyword">in</span> examples_tokenized[<span class="hljs-string">&quot;input_ids&quot;</span>]]  <span class="hljs-comment"># 组合输入ID</span><br>    targets_tokenized = _tokenize_fn(targets, tokenizer, add_special_tokens=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 目标分词</span><br><br>    labels = copy.deepcopy(input_ids)  <span class="hljs-comment"># 深拷贝输入ID作为标签</span><br><br>    <span class="hljs-keyword">for</span> idx, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(labels):<br>        target_len = <span class="hljs-built_in">len</span>(targets_tokenized[<span class="hljs-string">&quot;input_ids&quot;</span>][idx])  <span class="hljs-comment"># 目标长度</span><br>            <br>        <span class="hljs-keyword">if</span> idx == <span class="hljs-number">0</span>:<br>            logger.warning(<span class="hljs-string">f&#x27;\n===DEBUG Input:\n<span class="hljs-subst">&#123;json.dumps(tokenizer.decode(label))&#125;</span>===&#x27;</span>)  <span class="hljs-comment"># 调试输入</span><br>            logger.warning(<span class="hljs-string">f&#x27;\n===DEBUG Target:\n<span class="hljs-subst">&#123;label[-(target_len - assist_prefix_len):]&#125;</span> ==&gt; <span class="hljs-subst">&#123;json.dumps(tokenizer.decode(label[-(target_len - assist_prefix_len):]))&#125;</span>===&#x27;</span>)  <span class="hljs-comment"># 调试目标</span><br><br>        <span class="hljs-keyword">assert</span> torch.<span class="hljs-built_in">all</span>(labels[idx][-(target_len-assist_prefix_len):].eq(targets_tokenized[<span class="hljs-string">&quot;input_ids&quot;</span>][idx][assist_prefix_len:]))  <span class="hljs-comment"># 验证目标一致</span><br><br>        label[:-(target_len - assist_prefix_len)] = IGNORE_INDEX  <span class="hljs-comment"># 忽略不需要计算损失的部分</span><br><br>    packaged_data = <span class="hljs-built_in">dict</span>(<br>        input_ids=input_ids,<br>        labels=labels,<br>        metadata=<span class="hljs-built_in">dict</span>(),<br>        tokenization_metadata=examples_tokenized[<span class="hljs-string">&quot;tokenization_metadata&quot;</span>],<br>    )<br><br>    <span class="hljs-keyword">if</span> verbose:<br>        logger.warning(<span class="hljs-string">f&quot;Tokenization metadata:\n<span class="hljs-subst">&#123;json.dumps(packaged_data[<span class="hljs-string">&#x27;tokenization_metadata&#x27;</span>])&#125;</span>&quot;</span>)  <span class="hljs-comment"># 输出分词元数据</span><br><br>    <span class="hljs-keyword">return</span> packaged_data<br><br><span class="hljs-comment"># 分词函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_tokenize_text</span>(<span class="hljs-params">x, tokenizer, padding, add_special_tokens</span>):<br>    tokenized = tokenizer(<br>        text=x,<br>        return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,<br>        padding=padding,<br>        max_length=tokenizer.model_max_length,<br>        truncation=<span class="hljs-literal">True</span>,<br>        add_special_tokens=add_special_tokens,<br>    )<br>    <span class="hljs-keyword">return</span> tokenized<br><br><span class="hljs-comment"># 带偏移的分词函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_tokenize_text_with_offset</span>(<span class="hljs-params">x, tokenizer, padding, add_special_tokens</span>):<br>    tokenized = tokenizer(<br>        text=x[<span class="hljs-number">0</span>],<br>        return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,<br>        padding=padding,<br>        max_length=tokenizer.model_max_length - x[<span class="hljs-number">1</span>],  <span class="hljs-comment"># 考虑偏移</span><br>        truncation=<span class="hljs-literal">True</span>,<br>        add_special_tokens=add_special_tokens,<br>    )<br>    <span class="hljs-keyword">return</span> tokenized<br><br><span class="hljs-comment"># 分词函数，处理字符串列表</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_tokenize_fn</span>(<span class="hljs-params">strings: <span class="hljs-type">Sequence</span>[<span class="hljs-built_in">str</span>], tokenizer: transformers.PreTrainedTokenizer, max_len_offset=<span class="hljs-literal">None</span>, add_special_tokens=<span class="hljs-literal">True</span></span>) -&gt; <span class="hljs-built_in">dict</span>:<br>    padding = <span class="hljs-built_in">getattr</span>(tokenizer, <span class="hljs-string">&quot;padding&quot;</span>, <span class="hljs-string">&quot;longest&quot;</span>)  <span class="hljs-comment"># 获取填充方式</span><br>    <span class="hljs-keyword">if</span> max_len_offset <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        tokenized_list = <span class="hljs-built_in">list</span>(<br>            <span class="hljs-built_in">map</span>(<br>                partial(_tokenize_text_with_offset, tokenizer=tokenizer, padding=padding, add_special_tokens=add_special_tokens),<br>                <span class="hljs-built_in">zip</span>(strings, max_len_offset),  <span class="hljs-comment"># 组合字符串和偏移</span><br>            )<br>        )<br>    <span class="hljs-keyword">else</span>:<br>        tokenized_list = <span class="hljs-built_in">list</span>(<br>            <span class="hljs-built_in">map</span>(<br>                partial(_tokenize_text, tokenizer=tokenizer, padding=padding, add_special_tokens=add_special_tokens),<br>                strings,<br>            )<br>        )<br><br>    input_ids = labels = [tokenized.input_ids[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> tokenized <span class="hljs-keyword">in</span> tokenized_list]  <span class="hljs-comment"># 输入ID和标签</span><br>    input_ids_lens = labels_lens = [<br>        tokenized.input_ids.ne(tokenizer.pad_token_id).<span class="hljs-built_in">sum</span>().item() <span class="hljs-keyword">for</span> tokenized <span class="hljs-keyword">in</span> tokenized_list  <span class="hljs-comment"># 计算非填充长度</span><br>    ]<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">dict</span>(<br>        input_ids=input_ids,<br>        labels=labels,<br>        input_ids_lens=input_ids_lens,<br>        labels_lens=labels_lens,<br>        tokenization_metadata=<span class="hljs-built_in">dict</span>(  <span class="hljs-comment"># 分词元数据</span><br>            num_examples=<span class="hljs-built_in">len</span>(tokenized_list),<br>            input_ids_avg_len=np.mean(input_ids_lens),<br>            input_ids_max_len=<span class="hljs-built_in">max</span>(input_ids_lens),<br>            input_ids_min_len=<span class="hljs-built_in">min</span>(input_ids_lens),<br>            labels_avg_len=np.mean(labels_lens),<br>            labels_max_len=<span class="hljs-built_in">max</span>(labels_lens),<br>            labels_min_len=<span class="hljs-built_in">min</span>(labels_lens),<br>            model_max_length=tokenizer.model_max_length,<br>        ),<br>    )<br></code></pre></td></tr></table></figure>

<ol start="11">
<li>创建数据模块：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">data_module: <span class="hljs-built_in">dict</span> = make_supervised_data(<br>    tokenizer=tokenizer,<br>    data_args=data_args,<br>)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">Loading training set from: dataset/ASQA/demos.json

===DEBUG Input:
&quot;&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\nDocument 1 (Title: Nathan&#39;s Hot Dog Eating Contest): competitive eating by downing 50 hot dogs\u2014smashing the previous record of 25.5. The Japanese eater introduced advanced eating and training techniques that shattered previous competitive eating world records. The rise in popularity of the event coincided with the surge in popularity of the worldwide competitive eating circuit. On July 4, 2011, Sonya Thomas became the champion of the first Nathan&#39;s Hot Dog Eating Contest for Women. Previously, women and men had competed against each other, except for one all-female Memorial Day competition held in 1975. Eating 40 hot dogs in 10 minutes, Thomas earned the inaugural Pepto-Bismol-sponsored pink belt and\n\nDocument 2 (Title: Nathan&#39;s Hot Dog Eating Contest): Island most years since about 1972, usually in conjunction with Independence Day. Nathan&#39;s promoter Mortimer Matz claimed that on July 4, 1916, four immigrants held a hot dog eating contest at Nathan&#39;s Famous stand on Coney Island to settle an argument about who was the most patriotic. He also made the spurious claim that the contest has been held each year since then except 1941 (\&quot;as a protest to the war in Europe\&quot;) and 1971 (as a protest to political unrest in the U.S.). A man by the name of Jim Mullen is said to have won the first contest,\n\nDocument 3 (Title: Nathan&#39;s Hot Dog Eating Contest): called to the stage individually during introductions. In 2013, six-time defending champion Joey Chestnut was escorted to the stage in a sedan chair. The competition draws many spectators and worldwide press coverage. In 2007, an estimated 50,000 came out to witness the event. In 2004 a three-story-high \&quot;Hot Dog Eating Wall of Fame\&quot; was erected at the site of the annual contest. The wall lists past winners, and has a digital clock which counts down the minutes until the next contest. Despite substantial damage suffered at Nathan&#39;s due to Hurricane Sandy in October 2012, the location was repaired, reopened, and\n\nDocument 4 (Title: Nathan&#39;s Hot Dog Eating Contest): Nathan&#39;s Hot Dog Eating Contest The Nathan&#39;s Hot Dog Eating Contest is an annual American hot dog competitive eating competition. It is held each year on Independence Day at Nathan&#39;s Famous Corporation&#39;s original, and best-known restaurant at the corner of Surf and Stillwell Avenues in Coney Island, a neighborhood of Brooklyn, New York City. The contest has gained public attention in recent years due to the stardom of Takeru Kobayashi and Joey Chestnut. The defending men&#39;s champion is Joey Chestnut, who ate 74 hot dogs in the 2018 contest. The defending women&#39;s champion is Miki Sudo, who ate 37 hot\n\nDocument 5 (Title: Sonya Thomas): at the time. The only eaters besides Kobayashi to defeat Thomas between the 2004 and 2005 Nathan&#39;s contests were Bill \&quot;El Wingador\&quot; Simmons in the controversial 2005 Wing Bowl, and Dale Boone, who won a contest eating overheated baked beans after he doused the beans in water to cool them down. On July 4, 2011, Thomas became the first champion of Nathan&#39;s Hot Dog Eating Contest for Women. Eating 40 hot dogs in 10 minutes, Thomas earned the inaugural Pink Belt and won $10,000. Thomas had won 1st place in the National Buffalo Wing Festival US chicken wing eating championship\n\nBased on your knowledge and the provided information, answer the question:\n&#123;question&#125;who won nathan&#39;s hot dog eating contest?&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n\nThe documents that are useful to answer the question \&quot;Who won Nathan&#39;s hot dog eating contest?\&quot; are:\n\n* Document 1: Nathan&#39;s Hot Dog Eating Contest\n* Document 5: Sonya Thomas\n\nDocument 1 provides information about the history of the contest, including the fact that Sonya Thomas became the champion of the first Nathan&#39;s Hot Dog Eating Contest for Women in 2011.\n\nDocument 5 provides more information about Sonya Thomas, including her achievements in competitive eating, including winning the Nathan&#39;s Hot Dog Eating Contest for Women in 2011.\n\nBased on these documents, we can conclude that Sonya Thomas won the Nathan&#39;s Hot Dog Eating Contest for Women in 2011.\n\nHowever, the provided answer mentions the champions of the 2021 edition, which is not mentioned in the provided documents. Therefore, we cannot determine the winners of the contest for years after 2011 based on the provided information.\n\nIn conclusion, the answer to the question \&quot;Who won Nathan&#39;s hot dog eating contest?\&quot; is Sonya Thomas, who won the Nathan&#39;s Hot Dog Eating Contest for Women in 2011.&lt;|eot_id|&gt;&quot;===

===DEBUG Target:
tensor([   791,   9477,    430,    527,   5505,    311,   4320,    279,   3488,
       330,  15546,   2834,  37837,    596,   4106,   5679,  12459,  14130,
      7673,    527,   1473,      9,  12051,    220,     16,     25,  37837,
       596,   8166,  14588,  60638,  47633,    198,      9,  12051,    220,
        20,     25,  21533,     64,  11355,    271,   7676,    220,     16,
      5825,   2038,    922,    279,   3925,    315,    279,  14130,     11,
      2737,    279,   2144,    430,  21533,     64,  11355,   6244,    279,
     18824,    315,    279,   1176,  37837,    596,   8166,  14588,  60638,
     47633,    369,  11215,    304,    220,    679,     16,    382,   7676,
       220,     20,   5825,    810,   2038,    922,  21533,     64,  11355,
        11,   2737,   1077,  33997,    304,  15022,  12459,     11,   2737,
     11230,    279,  37837,    596,   8166,  14588,  60638,  47633,    369,
     11215,    304,    220,    679,     16,    382,  29815,    389,   1521,
      9477,     11,    584,    649,  32194,    430,  21533,     64,  11355,
      2834,    279,  37837,    596,   8166,  14588,  60638,  47633,    369,
     11215,    304,    220,    679,     16,    382,  11458,     11,    279,
      3984,   4320,  34945,    279,  34838,    315,    279,    220,   2366,
        16,  14002,     11,    902,    374,    539,   9932,    304,    279,
      3984,   9477,     13,  15636,     11,    584,   4250,   8417,    279,
     26526,    315,    279,  14130,    369,   1667,   1306,    220,    679,
        16,   3196,    389,    279,   3984,   2038,    382,    644,  17102,
        11,    279,   4320,    311,    279,   3488,    330,  15546,   2834,
     37837,    596,   4106,   5679,  12459,  14130,   7673,    374,  21533,
        64,  11355,     11,    889,   2834,    279,  37837,    596,   8166,
     14588,  60638,  47633,    369,  11215,    304,    220,    679,     16,
        13, 128009]) ==&gt; &quot;The documents that are useful to answer the question \&quot;Who won Nathan&#39;s hot dog eating contest?\&quot; are:\n\n* Document 1: Nathan&#39;s Hot Dog Eating Contest\n* Document 5: Sonya Thomas\n\nDocument 1 provides information about the history of the contest, including the fact that Sonya Thomas became the champion of the first Nathan&#39;s Hot Dog Eating Contest for Women in 2011.\n\nDocument 5 provides more information about Sonya Thomas, including her achievements in competitive eating, including winning the Nathan&#39;s Hot Dog Eating Contest for Women in 2011.\n\nBased on these documents, we can conclude that Sonya Thomas won the Nathan&#39;s Hot Dog Eating Contest for Women in 2011.\n\nHowever, the provided answer mentions the champions of the 2021 edition, which is not mentioned in the provided documents. Therefore, we cannot determine the winners of the contest for years after 2011 based on the provided information.\n\nIn conclusion, the answer to the question \&quot;Who won Nathan&#39;s hot dog eating contest?\&quot; is Sonya Thomas, who won the Nathan&#39;s Hot Dog Eating Contest for Women in 2011.&lt;|eot_id|&gt;&quot;===
Tokenization metadata:
&#123;&quot;num_examples&quot;: 2, &quot;input_ids_avg_len&quot;: 1099.5, &quot;input_ids_max_len&quot;: 1216, &quot;input_ids_min_len&quot;: 983, &quot;labels_avg_len&quot;: 1099.5, &quot;labels_max_len&quot;: 1216, &quot;labels_min_len&quot;: 983, &quot;model_max_length&quot;: 4096&#125;
</code></pre>
<ol start="12">
<li>创建训练器：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">trainer = Trainer(<br>    model=model,<br>    tokenizer=tokenizer,<br>    args=training_args,<br>    **data_module,<br>)<br></code></pre></td></tr></table></figure>

<ol start="13">
<li>开始训练：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">trainer.train(resume_from_checkpoint=training_args.resume_from_checkpoint)<br><span class="hljs-comment"># 训练完成后记录日志</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;hooray! training finished successfully!\nNow on to model saving -- With mixed precision, FSDP will upcast in the model preparation step, and FSDP will then save checkpoints in the upcasted precision. See: https://huggingface.co/docs/accelerate/en/concept_guides/fsdp_and_deepspeed&quot;</span>)<br>trainer.save_state() <span class="hljs-comment"># 保存训练状态</span><br>safe_save_model_for_hf_trainer(trainer=trainer, output_dir=training_args.output_dir) <span class="hljs-comment"># 安全地保存模型</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;hooray again! model saving worked.&quot;</span>)<br></code></pre></td></tr></table></figure>

<h2 id="3-2-inference-py：推理与评估"><a href="#3-2-inference-py：推理与评估" class="headerlink" title="3.2 inference.py：推理与评估"></a>3.2 inference.py：推理与评估</h2><ol>
<li>导入必要的包：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> io<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> transformers<br><span class="hljs-keyword">import</span> copy<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> functools<br><span class="hljs-keyword">import</span> string<br><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> vllm <span class="hljs-keyword">import</span> LLM, SamplingParams<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Union</span><br></code></pre></td></tr></table></figure>

<ol start="2">
<li>加载 <code>common_utils.py</code> 中的函数：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python">makedirs = functools.partial(os.makedirs, exist_ok=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 确保文件对象是可读的IO基类</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_make_r_io_base</span>(<span class="hljs-params">f, mode: <span class="hljs-built_in">str</span></span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(f, io.IOBase):<br>        f = <span class="hljs-built_in">open</span>(f, mode=mode)<br>    <span class="hljs-keyword">return</span> f<br><br><span class="hljs-comment"># 确保文件对象是可写的IO基类，必要时创建目录</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_make_w_io_base</span>(<span class="hljs-params">f, mode: <span class="hljs-built_in">str</span></span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(f, io.IOBase):<br>        f_dirname = os.path.dirname(f)<br>        <span class="hljs-keyword">if</span> f_dirname != <span class="hljs-string">&quot;&quot;</span>:<br>            makedirs(f_dirname)  <span class="hljs-comment"># 创建父目录</span><br>        f = <span class="hljs-built_in">open</span>(f, mode=mode)<br>    <span class="hljs-keyword">return</span> f<br><br><span class="hljs-comment"># 加载JSON文件到字典</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">jload</span>(<span class="hljs-params">f, mode=<span class="hljs-string">&quot;r&quot;</span></span>):<br>    f = _make_r_io_base(f, mode)  <span class="hljs-comment"># 确保文件可读</span><br>    jdict = json.load(f)  <span class="hljs-comment"># 加载JSON</span><br>    f.close()<br>    <span class="hljs-keyword">return</span> jdict<br><br><span class="hljs-comment"># 将对象以JSON格式写入文件</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">jdump</span>(<span class="hljs-params">obj: <span class="hljs-type">Union</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">dict</span>, <span class="hljs-built_in">list</span>], f, mode=<span class="hljs-string">&quot;w&quot;</span>, indent=<span class="hljs-number">4</span>, default=<span class="hljs-built_in">str</span></span>):<br>    f = _make_w_io_base(f, mode)  <span class="hljs-comment"># 确保文件可写</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(obj, (<span class="hljs-built_in">dict</span>, <span class="hljs-built_in">list</span>)):<br>        json.dump(obj, f, indent=indent, default=default)<br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(obj, <span class="hljs-built_in">str</span>):<br>        f.write(obj)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f&quot;Unexpected type: <span class="hljs-subst">&#123;<span class="hljs-built_in">type</span>(obj)&#125;</span>&quot;</span>)<br>    f.close()<br></code></pre></td></tr></table></figure>

<ol start="3">
<li>模拟 parser 的命令行解析，只拆解 FT 模型，ICL 逻辑类似：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Args</span>:<br>    <span class="hljs-keyword">pass</span><br><br>args = Args()<br><br>args.dataset_name = <span class="hljs-string">&quot;ASQA&quot;</span> <span class="hljs-comment"># 数据集名称</span><br>args.rag_model = <span class="hljs-string">&quot;InstructRAG-FT&quot;</span> <span class="hljs-comment"># RAG模型类型</span><br>args.model_name_or_path = <span class="hljs-string">&quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;</span> <span class="hljs-comment"># 模型名称或路径</span><br>args.load_local_model = <span class="hljs-literal">True</span> <span class="hljs-comment"># 是否加载本地模型</span><br>args.do_rationale_generation = <span class="hljs-literal">False</span> <span class="hljs-comment"># 是否生成理由</span><br>args.n_docs = <span class="hljs-number">5</span> <span class="hljs-comment"># 检索文档数量</span><br>args.output_dir = <span class="hljs-string">&quot;./&quot;</span> <span class="hljs-comment"># 输出目录</span><br>args.cache_dir = <span class="hljs-literal">None</span>  <span class="hljs-comment"># 模型缓存目录</span><br>args.prompt_dict_path = <span class="hljs-string">&quot;src/rag.json&quot;</span> <span class="hljs-comment"># 提示词模板路径</span><br>args.temperature = <span class="hljs-number">0</span> <span class="hljs-comment"># 采样温度</span><br>args.max_tokens = <span class="hljs-number">4096</span> <span class="hljs-comment"># 最大token数</span><br>args.seed = <span class="hljs-number">42</span> <span class="hljs-comment"># 随机种子</span><br>args.max_instances =sys.maxsize <span class="hljs-comment"># 最大实例数</span><br></code></pre></td></tr></table></figure>

<ol start="4">
<li><code>do_rationale_generation</code> 与 <code>eval_model</code> 这两个函数的逻辑是一致的，只不过前者用于生成训练数据的理由，后者用于生成测试数据的答案，因此只拆解 <code>eval_model</code>：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 数据路径由 test.json 改成了 demo.json，只有一组数据</span><br>data_path = <span class="hljs-string">f&#x27;dataset/<span class="hljs-subst">&#123;args.dataset_name&#125;</span>/demo.json&#x27;</span><br><br>test_data = jload(data_path)[:args.max_instances]<br><span class="hljs-built_in">print</span>(json.dumps(test_data, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure>
<br/>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Who won nathan&#x27;s hot dog eating contest?&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-string">&quot;The Nathan&#x27;s Hot Dog Eating Contest is an annual American hot dog eating competition held on Independence Day at Nathan&#x27;s Famous Corporation&#x27;s original restaurant at the corner of Surf and Stillwell Avenues in Coney Island, a neighborhood of Brooklyn, New York City. The current men&#x27;s and women&#x27;s competitions champions are Joey Chestnut and Michelle Lesco, who crowned themselves in the 2021 edition. Previously, Miki Sudo had won the women&#x27;s competition every year from 2014-2020, with Chestnut doing so in the men&#x27;s variant in 2017 and 2016 and Matt Stonie in 2015.&quot;</span><br>        <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;qa_pairs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Who won the men&#x27;s competition of Nathan&#x27;s Hot Dog Eating Contest in 2017?&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">&quot;Joey Chestnut&quot;</span><br>                <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Who won the women&#x27;s competition of Nathan&#x27;s Hot Dog Eating Contest in 2017?&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">&quot;Miki Sudo&quot;</span><br>                <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Who won the men&#x27;s competition of Nathan&#x27;s Hot Dog Eating Contest in 2016?&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">&quot;Joey Chestnut&quot;</span><br>                <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Who won the women&#x27;s competition of Nathan&#x27;s Hot Dog Eating Contest in 2016?&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">&quot;Miki Sudo&quot;</span><br>                <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Who won the men&#x27;s competition of Nathan&#x27;s Hot Dog Eating Contest in 2015?&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">&quot;Matt Stonie&quot;</span><br>                <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Who won the women&#x27;s competition of Nathan&#x27;s Hot Dog Eating Contest in 2015?&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">&quot;Miki Sudo&quot;</span><br>                <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;rationale&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;The documents that are useful to answer the question \&quot;Who won Nathan&#x27;s hot dog eating contest?\&quot; are:\n\n* Document 1: Nathan&#x27;s Hot Dog Eating Contest\n* Document 5: Sonya Thomas\n\nDocument 1 provides information about the history of the contest, including the fact that Sonya Thomas became the champion of the first Nathan&#x27;s Hot Dog Eating Contest for Women in 2011.\n\nDocument 5 provides more information about Sonya Thomas, including her achievements in competitive eating, including winning the Nathan&#x27;s Hot Dog Eating Contest for Women in 2011.\n\nBased on these documents, we can conclude that Sonya Thomas won the Nathan&#x27;s Hot Dog Eating Contest for Women in 2011.\n\nHowever, the provided answer mentions the champions of the 2021 edition, which is not mentioned in the provided documents. Therefore, we cannot determine the winners of the contest for years after 2011 based on the provided information.\n\nIn conclusion, the answer to the question \&quot;Who won Nathan&#x27;s hot dog eating contest?\&quot; is Sonya Thomas, who won the Nathan&#x27;s Hot Dog Eating Contest for Women in 2011.&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;ctxs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;3360010&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Nathan&#x27;s Hot Dog Eating Contest&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;competitive eating by downing 50 hot dogs—smashing the previous record of 25.5. The Japanese eater introduced advanced eating and training techniques that shattered previous competitive eating world records. The rise in popularity of the event coincided with the surge in popularity of the worldwide competitive eating circuit. On July 4, 2011, Sonya Thomas became the champion of the first Nathan&#x27;s Hot Dog Eating Contest for Women. Previously, women and men had competed against each other, except for one all-female Memorial Day competition held in 1975. Eating 40 hot dogs in 10 minutes, Thomas earned the inaugural Pepto-Bismol-sponsored pink belt and&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.7802734375</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;3360007&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Nathan&#x27;s Hot Dog Eating Contest&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Island most years since about 1972, usually in conjunction with Independence Day. Nathan&#x27;s promoter Mortimer Matz claimed that on July 4, 1916, four immigrants held a hot dog eating contest at Nathan&#x27;s Famous stand on Coney Island to settle an argument about who was the most patriotic. He also made the spurious claim that the contest has been held each year since then except 1941 (\&quot;as a protest to the war in Europe\&quot;) and 1971 (as a protest to political unrest in the U.S.). A man by the name of Jim Mullen is said to have won the first contest,&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.7802734375</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;3360012&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Nathan&#x27;s Hot Dog Eating Contest&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;called to the stage individually during introductions. In 2013, six-time defending champion Joey Chestnut was escorted to the stage in a sedan chair. The competition draws many spectators and worldwide press coverage. In 2007, an estimated 50,000 came out to witness the event. In 2004 a three-story-high \&quot;Hot Dog Eating Wall of Fame\&quot; was erected at the site of the annual contest. The wall lists past winners, and has a digital clock which counts down the minutes until the next contest. Despite substantial damage suffered at Nathan&#x27;s due to Hurricane Sandy in October 2012, the location was repaired, reopened, and&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.7958984375</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;3360002&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Nathan&#x27;s Hot Dog Eating Contest&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Nathan&#x27;s Hot Dog Eating Contest The Nathan&#x27;s Hot Dog Eating Contest is an annual American hot dog competitive eating competition. It is held each year on Independence Day at Nathan&#x27;s Famous Corporation&#x27;s original, and best-known restaurant at the corner of Surf and Stillwell Avenues in Coney Island, a neighborhood of Brooklyn, New York City. The contest has gained public attention in recent years due to the stardom of Takeru Kobayashi and Joey Chestnut. The defending men&#x27;s champion is Joey Chestnut, who ate 74 hot dogs in the 2018 contest. The defending women&#x27;s champion is Miki Sudo, who ate 37 hot&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.7978515625</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;3425375&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Sonya Thomas&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;at the time. The only eaters besides Kobayashi to defeat Thomas between the 2004 and 2005 Nathan&#x27;s contests were Bill \&quot;El Wingador\&quot; Simmons in the controversial 2005 Wing Bowl, and Dale Boone, who won a contest eating overheated baked beans after he doused the beans in water to cool them down. On July 4, 2011, Thomas became the first champion of Nathan&#x27;s Hot Dog Eating Contest for Women. Eating 40 hot dogs in 10 minutes, Thomas earned the inaugural Pink Belt and won $10,000. Thomas had won 1st place in the National Buffalo Wing Festival US chicken wing eating championship&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.8037109375</span><br>            <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">]</span><br></code></pre></td></tr></table></figure>

<ol start="5">
<li>加载 LLM 和 tokenizer：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> args.rag_model == <span class="hljs-string">&#x27;InstructRAG-FT&#x27;</span>:<br>    demos = []<br>    <span class="hljs-keyword">if</span> args.load_local_model: <span class="hljs-comment"># 本地</span><br>        llm = LLM(model=<span class="hljs-string">f&#x27;saved_models/InstructRAG-FT/<span class="hljs-subst">&#123;args.dataset_name&#125;</span>&#x27;</span>, max_model_len=args.max_tokens)<br>    <span class="hljs-keyword">else</span>: <span class="hljs-comment"># 联网</span><br>        llm = LLM(model=<span class="hljs-string">f&#x27;meng-lab/<span class="hljs-subst">&#123;args.dataset_name&#125;</span>-InstructRAG-FT&#x27;</span>, download_dir=args.cache_dir, max_model_len=args.max_tokens)<br>        <br><span class="hljs-keyword">elif</span> args.rag_model == <span class="hljs-string">&#x27;InstructRAG-ICL&#x27;</span>:<br>    demos = jload(<span class="hljs-string">f&#x27;dataset/<span class="hljs-subst">&#123;args.dataset_name&#125;</span>/demos.json&#x27;</span>)<br>    llm = LLM(model=<span class="hljs-string">&#x27;meta-llama/Meta-Llama-3-8B-Instruct&#x27;</span>, download_dir=args.cache_dir, max_model_len=args.max_tokens)<br>    <br>tokenizer = llm.get_tokenizer()<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">INFO 04-10 11:21:45 llm_engine.py:98] Initializing an LLM engine (v0.4.1) with config: model=&#39;saved_models/InstructRAG-FT/ASQA&#39;, speculative_config=None, tokenizer=&#39;saved_models/InstructRAG-FT/ASQA&#39;, skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend=&#39;outlines&#39;), seed=0)
INFO 04-10 11:21:45 utils.py:608] Found nccl from library /public/home/jfqu/.config/vllm/nccl/cu12/libnccl.so.2.18.1
INFO 04-10 11:21:48 selector.py:65] Cannot use FlashAttention backend for Volta and Turing GPUs.
INFO 04-10 11:21:48 selector.py:33] Using XFormers backend.
INFO 04-10 11:22:38 model_runner.py:173] Loading model weights took 14.9595 GB
INFO 04-10 11:22:40 gpu_executor.py:119] # GPU blocks: 5774, # CPU blocks: 2048
INFO 04-10 11:22:42 model_runner.py:976] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set &#39;enforce_eager=True&#39; or use &#39;--enforce-eager&#39; in the CLI.
INFO 04-10 11:22:42 model_runner.py:980] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 04-10 11:22:51 model_runner.py:1057] Graph capturing finished in 9 secs.
</code></pre>
<ol start="6">
<li>加载提示词：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt_dict = jload(args.prompt_dict_path)<br><span class="hljs-built_in">print</span>(json.dumps(prompt_dict, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure>
<br/>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;user_prefix&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\n&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;assistant_prefix&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n\n&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;query_prompt&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Based on your knowledge and the provided information, answer the question:\n&#123;question&#125;&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;demo_task_instruction&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Your task is to analyze the provided documents and answer the given question. Please generate a brief explanation of how the contents of these documents lead to your answer. If the provided information is not helpful to answer the question, you only need to respond based on your own knowledge, without referring to the documents.\n\nBelow are some examples of how to answer the question:\n\n&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;demo_prefix&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Read the following documents relevant to the given question: &#123;question&#125;\n\n&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;demo_postfix&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;###\n\nNow it is your turn to analyze the following documents and answer the given question.\n\n&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;rationale_generation_instruction&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Please identify documents that are useful to answer the given question: &#x27;&#123;question&#125;&#x27;, and explain how the contents lead to the answer: &#123;answers&#125;.\n\nIf none of the documents is aligned with the answer, in that case, you have to explain the answer only based on your own knowledge, without referring to the provided information.\n\n&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;rationale_generation_postfix_ASQA&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Note that the question may be ambiguous and have multiple correct answers. Make sure your response includes all correct answers and provides clear reasoning details followed by a concise conclusion.&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;rationale_generation_postfix_PopQA&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Note that the question mainly asks about the object entity that holds a certain relationship with the given subject entity. There may be multiple correct answers. Make sure your response includes all correct answers and provides clear reasoning details followed by a concise conclusion.&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;rationale_generation_postfix_TriviaQA&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Note that the question may be compositional and require intermediate analysis to deduce the final answer. Make sure your response is grounded and provides clear reasoning details followed by a concise conclusion.&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;rationale_generation_postfix_NaturalQuestions&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Note that the question may be compositional and require intermediate analysis to deduce the final answer. Make sure your response is grounded and provides clear reasoning details followed by a concise conclusion.&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;rationale_generation_postfix_2WikiMultiHopQA&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Note that the question may be compositional and require intermediate analysis to deduce the final answer. Make sure your response is grounded and provides clear reasoning details followed by a concise conclusion.&quot;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>

<ol start="7">
<li>加载 <code>data_utils.py</code> 中的函数：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 规范化问题：确保问题以问号结尾且开头格式正确</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalize_question</span>(<span class="hljs-params">question</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> question.endswith(<span class="hljs-string">&quot;?&quot;</span>):<br>        question = question + <span class="hljs-string">&quot;?&quot;</span><br>    <span class="hljs-keyword">if</span> question.startswith(<span class="hljs-string">&quot;.&quot;</span>): <span class="hljs-comment"># 检查是否以 &quot;.&quot; 开头</span><br>        question = question.lstrip(<span class="hljs-string">&quot;. &quot;</span>) <span class="hljs-comment"># 移除开头的 &quot;.&quot; 和空格</span><br><br>    <span class="hljs-keyword">return</span> question[<span class="hljs-number">0</span>].lower() + question[<span class="hljs-number">1</span>:]  <span class="hljs-comment"># 首字母小写</span><br><br><span class="hljs-comment"># 构建上下文文档：保证文档得分升序排列</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_contexts</span>(<span class="hljs-params">example, n_docs</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(example[<span class="hljs-string">&quot;ctxs&quot;</span>]) &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> example[<span class="hljs-string">&quot;ctxs&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;score&quot;</span>] &gt; example[<span class="hljs-string">&quot;ctxs&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;score&quot;</span>]: <span class="hljs-comment"># 如果第一个文档分数更高，则反转列表</span><br>        ctxs_list = example[<span class="hljs-string">&quot;ctxs&quot;</span>][:n_docs][::-<span class="hljs-number">1</span>]  <br>    <span class="hljs-keyword">else</span>: <span class="hljs-comment"># 否则直接取前n_docs个文档</span><br>        ctxs_list = example[<span class="hljs-string">&quot;ctxs&quot;</span>][:n_docs]  <br><br>    <span class="hljs-comment"># 格式化文档文本</span><br>    docs_text = <span class="hljs-string">&quot;\n\n&quot;</span>.join([<span class="hljs-string">f&quot;Document <span class="hljs-subst">&#123;idx+<span class="hljs-number">1</span>&#125;</span> (Title: <span class="hljs-subst">&#123;ctx[<span class="hljs-string">&#x27;title&#x27;</span>]&#125;</span>): <span class="hljs-subst">&#123;ctx[<span class="hljs-string">&#x27;text&#x27;</span>]&#125;</span>&quot;</span> <span class="hljs-keyword">for</span> idx, ctx <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(ctxs_list)])<br>    doc_prompt = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;docs_text&#125;</span>\n\n&quot;</span><br>    <br>    <span class="hljs-keyword">return</span> doc_prompt<br><br><span class="hljs-comment"># 格式化提示文本</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">format_prompt</span>(<span class="hljs-params"></span><br><span class="hljs-params">        dataset_name: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">        example: <span class="hljs-built_in">dict</span>, </span><br><span class="hljs-params">        n_docs: <span class="hljs-built_in">int</span>,</span><br><span class="hljs-params">        prompt_dict: <span class="hljs-built_in">dict</span>,</span><br><span class="hljs-params">        tokenizer: transformers.PreTrainedTokenizer,</span><br><span class="hljs-params">        do_rationale_generation: <span class="hljs-built_in">bool</span>,</span><br><span class="hljs-params">        demos: <span class="hljs-built_in">list</span> = [],</span><br><span class="hljs-params">        </span>) -&gt; <span class="hljs-built_in">str</span>:<br>    example[<span class="hljs-string">&#x27;question&#x27;</span>] = normalize_question(example[<span class="hljs-string">&#x27;question&#x27;</span>])  <span class="hljs-comment"># 规范化问题</span><br>    max_length = tokenizer.model_max_length  <span class="hljs-comment"># 最大长度</span><br><br>    query_prompt = prompt_dict[<span class="hljs-string">&#x27;query_prompt&#x27;</span>].format_map(example)  <span class="hljs-comment"># 查询提示</span><br>    target_prefix = <span class="hljs-string">&quot;&quot;</span>  <span class="hljs-comment"># 目标前缀</span><br><br>    doc_prompt = build_contexts(example, n_docs=n_docs)  <span class="hljs-comment"># 构建文档上下文</span><br>    prefix = prompt_dict[<span class="hljs-string">&#x27;user_prefix&#x27;</span>]  <span class="hljs-comment"># 用户前缀</span><br><br>    <span class="hljs-keyword">if</span> do_rationale_generation: <span class="hljs-comment"># 生成理由</span><br>        query_prompt = <span class="hljs-string">&#x27;&#x27;</span><br>        prefix += prompt_dict[<span class="hljs-string">&#x27;demo_prefix&#x27;</span>].format_map(example)  <span class="hljs-comment"># 添加演示前缀</span><br>        target_prefix += prompt_dict[<span class="hljs-string">&#x27;rationale_generation_instruction&#x27;</span>].format_map(example) + prompt_dict[<span class="hljs-string">&#x27;rationale_generation_postfix_&#x27;</span> + dataset_name]  <span class="hljs-comment"># 添加推理生成指令</span><br><br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(demos) &gt; <span class="hljs-number">0</span>: <span class="hljs-comment"># ICL</span><br>        prefix += prompt_dict[<span class="hljs-string">&#x27;demo_task_instruction&#x27;</span>]  <span class="hljs-comment"># 添加演示任务指令</span><br><br>        <span class="hljs-keyword">for</span> idx, demo <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(demos):<br>            demo_question = normalize_question(demo[<span class="hljs-string">&#x27;question&#x27;</span>])  <span class="hljs-comment"># 规范化演示问题</span><br>            demo_rationale = demo[<span class="hljs-string">&#x27;rationale&#x27;</span>]  <span class="hljs-comment"># 演示推理</span><br>            prefix += <span class="hljs-string">f&quot;###\n\nExample <span class="hljs-subst">&#123;idx+<span class="hljs-number">1</span>&#125;</span>\n\nQuestion: <span class="hljs-subst">&#123;demo_question&#125;</span>\n\nAnswer: <span class="hljs-subst">&#123;demo_rationale&#125;</span>\n\n&quot;</span>  <span class="hljs-comment"># 添加演示示例</span><br><br>        prefix += prompt_dict[<span class="hljs-string">&#x27;demo_postfix&#x27;</span>]  <span class="hljs-comment"># 添加演示后缀</span><br><br>    prefix_tokenized_id = tokenizer(prefix, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, add_special_tokens=<span class="hljs-literal">True</span>).input_ids  <span class="hljs-comment"># 分词前缀</span><br>    prefix_len = <span class="hljs-built_in">len</span>(prefix_tokenized_id)  <span class="hljs-comment"># 前缀长度</span><br><br>    target_prefix += prompt_dict[<span class="hljs-string">&#x27;assistant_prefix&#x27;</span>]  <span class="hljs-comment"># 添加助手前缀</span><br><br>    input_ids = tokenizer(doc_prompt + query_prompt + target_prefix, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, add_special_tokens=<span class="hljs-literal">False</span>).input_ids  <span class="hljs-comment"># 分词输入</span><br><br>    <span class="hljs-keyword">if</span> input_ids.shape[-<span class="hljs-number">1</span>] &gt; max_length - prefix_len:<br>        input_ids = input_ids[..., -(max_length - prefix_len):]  <span class="hljs-comment"># 截断超长部分</span><br>    input_ids = torch.cat([prefix_tokenized_id, input_ids], axis=-<span class="hljs-number">1</span>)  <span class="hljs-comment"># 组合前缀和输入</span><br>    <br>    formatted_prompt = tokenizer.decode(input_ids[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 解码为文本</span><br>    <span class="hljs-keyword">return</span> formatted_prompt<br><br><span class="hljs-comment"># 批量格式化提示文本</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">format_prompt_with_data_list</span>(<span class="hljs-params"></span><br><span class="hljs-params">    data_list: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">dict</span>],</span><br><span class="hljs-params">    dataset_name: <span class="hljs-built_in">str</span>,</span><br><span class="hljs-params">    prompt_dict: <span class="hljs-built_in">dict</span>,</span><br><span class="hljs-params">    tokenizer: transformers.PreTrainedTokenizer,</span><br><span class="hljs-params">    n_docs: <span class="hljs-built_in">int</span> = <span class="hljs-number">5</span>,</span><br><span class="hljs-params">    demos: <span class="hljs-built_in">list</span> = [],</span><br><span class="hljs-params">    do_rationale_generation: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params"></span>):<br>    data = copy.deepcopy(data_list) <span class="hljs-comment"># 递归复制所有嵌套对象</span><br>    formatted_data = [format_prompt(dataset_name, example, n_docs, prompt_dict, tokenizer, do_rationale_generation, demos) <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> tqdm(data)]  <span class="hljs-comment"># 使用进度条</span><br><br>    <span class="hljs-keyword">return</span> formatted_data<br></code></pre></td></tr></table></figure>

<ol start="8">
<li>得到模型输入：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">prompts = format_prompt_with_data_list(<br>    data_list=test_data,<br>    dataset_name=args.dataset_name,<br>    prompt_dict=prompt_dict,<br>    tokenizer=tokenizer,<br>    n_docs=args.n_docs,<br>    demos=demos,<br>)<br><span class="hljs-built_in">print</span>(json.dumps(prompts, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">100%|██████████| 1/1 [00:00&lt;00:00, 153.02it/s]
[
&quot;&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\nDocument 1 (Title: Nathan&#39;s Hot Dog Eating Contest): competitive eating by downing 50 hot dogs—smashing the previous record of 25.5. The Japanese eater introduced advanced eating and training techniques that shattered previous competitive eating world records. The rise in popularity of the event coincided with the surge in popularity of the worldwide competitive eating circuit. On July 4, 2011, Sonya Thomas became the champion of the first Nathan&#39;s Hot Dog Eating Contest for Women. Previously, women and men had competed against each other, except for one all-female Memorial Day competition held in 1975. Eating 40 hot dogs in 10 minutes, Thomas earned the inaugural Pepto-Bismol-sponsored pink belt and\n\nDocument 2 (Title: Nathan&#39;s Hot Dog Eating Contest): Island most years since about 1972, usually in conjunction with Independence Day. Nathan&#39;s promoter Mortimer Matz claimed that on July 4, 1916, four immigrants held a hot dog eating contest at Nathan&#39;s Famous stand on Coney Island to settle an argument about who was the most patriotic. He also made the spurious claim that the contest has been held each year since then except 1941 (\&quot;as a protest to the war in Europe\&quot;) and 1971 (as a protest to political unrest in the U.S.). A man by the name of Jim Mullen is said to have won the first contest,\n\nDocument 3 (Title: Nathan&#39;s Hot Dog Eating Contest): called to the stage individually during introductions. In 2013, six-time defending champion Joey Chestnut was escorted to the stage in a sedan chair. The competition draws many spectators and worldwide press coverage. In 2007, an estimated 50,000 came out to witness the event. In 2004 a three-story-high \&quot;Hot Dog Eating Wall of Fame\&quot; was erected at the site of the annual contest. The wall lists past winners, and has a digital clock which counts down the minutes until the next contest. Despite substantial damage suffered at Nathan&#39;s due to Hurricane Sandy in October 2012, the location was repaired, reopened, and\n\nDocument 4 (Title: Nathan&#39;s Hot Dog Eating Contest): Nathan&#39;s Hot Dog Eating Contest The Nathan&#39;s Hot Dog Eating Contest is an annual American hot dog competitive eating competition. It is held each year on Independence Day at Nathan&#39;s Famous Corporation&#39;s original, and best-known restaurant at the corner of Surf and Stillwell Avenues in Coney Island, a neighborhood of Brooklyn, New York City. The contest has gained public attention in recent years due to the stardom of Takeru Kobayashi and Joey Chestnut. The defending men&#39;s champion is Joey Chestnut, who ate 74 hot dogs in the 2018 contest. The defending women&#39;s champion is Miki Sudo, who ate 37 hot\n\nDocument 5 (Title: Sonya Thomas): at the time. The only eaters besides Kobayashi to defeat Thomas between the 2004 and 2005 Nathan&#39;s contests were Bill \&quot;El Wingador\&quot; Simmons in the controversial 2005 Wing Bowl, and Dale Boone, who won a contest eating overheated baked beans after he doused the beans in water to cool them down. On July 4, 2011, Thomas became the first champion of Nathan&#39;s Hot Dog Eating Contest for Women. Eating 40 hot dogs in 10 minutes, Thomas earned the inaugural Pink Belt and won $10,000. Thomas had won 1st place in the National Buffalo Wing Festival US chicken wing eating championship\n\nBased on your knowledge and the provided information, answer the question:\nwho won nathan&#39;s hot dog eating contest?&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n\n&quot;
]
</code></pre>
<ol start="9">
<li>得到采样参数：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">sampling_params = SamplingParams(temperature=args.temperature,<br>                                 max_tokens=args.max_tokens,<br>                                 seed=args.seed,<br>                                 stop_token_ids=[tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(<span class="hljs-string">&quot;&lt;|eot_id|&gt;&quot;</span>)])<br>sampling_params<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0, top_p=1.0, top_k=-1, min_p=0.0, seed=42, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[128009, 128009], include_stop_str_in_output=False, ignore_eos=False, max_tokens=4096, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None)
</code></pre>
<ol start="10">
<li>模型推理，得到模型输出：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">outputs = llm.generate(prompts, sampling_params)<br>outputs[<span class="hljs-number">0</span>].outputs[<span class="hljs-number">0</span>].text<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">Processed prompts: 100%|██████████| 1/1 [00:07&lt;00:00,  7.43s/it]
&#39;The documents provided do not directly answer the question &quot;who won Nathan\&#39;s Hot Dog Eating Contest?&quot; However, they do provide information about the contest, its history, and past winners.\n\nFrom Document 1, we learn that Takeru Kobayashi set a new record by eating 50 hot dogs in 2006, and Sonya Thomas became the champion of the first Nathan\&#39;s Hot Dog Eating Contest for Women in 2011.\n\nFrom Document 4, we learn that the defending men\&#39;s champion is Joey Chestnut, who ate 74 hot dogs in the 2018 contest, and the defending women\&#39;s champion is Miki Sudo, who ate 37 hot dogs in the same contest.\n\nFrom Document 5, we learn that Sonya Thomas became the first champion of Nathan\&#39;s Hot Dog Eating Contest for Women in 2011, eating 40 hot dogs in 10 minutes.\n\nBased on this information, we can conclude that:\n\n* Takeru Kobayashi won the Nathan\&#39;s Hot Dog Eating Contest in 2006, eating 50 hot dogs.\n* Sonya Thomas won the Nathan\&#39;s Hot Dog Eating Contest for Women in 2011, eating 40 hot dogs.\n* Joey Chestnut is the defending men\&#39;s champion, having eaten 74 hot dogs in the 2018 contest.\n* Miki Sudo is the defending women\&#39;s champion, having eaten 37 hot dogs in the 2018 contest.\n\nTherefore, the answer to the question &quot;who won Nathan\&#39;s Hot Dog Eating Contest?&quot; is not a single answer, but rather a list of past winners, including Takeru Kobayashi, Sonya Thomas, Joey Chestnut, and Miki Sudo.&#39;
</code></pre>
<ol start="11">
<li>保存结果：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 保存输出结果</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">save_outputs</span>(<span class="hljs-params">outputs, test_data, output_file, n_docs</span>):<br>    output_data = []<br>    <span class="hljs-keyword">for</span> i, output <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(outputs):<br>        prompt = output.prompt  <span class="hljs-comment"># 获取模型输入</span><br>        generated_text = output.outputs[<span class="hljs-number">0</span>].text  <span class="hljs-comment"># 获取模型输出</span><br>        sample = test_data[i]  <span class="hljs-comment"># 获取对应的源数据</span><br>        <br>        <span class="hljs-comment"># 构建输出数据结构</span><br>        output_data.append(&#123;<br>            <span class="hljs-string">&quot;question&quot;</span>: sample[<span class="hljs-string">&quot;question&quot;</span>],  <span class="hljs-comment"># 问题</span><br>            <span class="hljs-string">&quot;answers&quot;</span>: sample[<span class="hljs-string">&quot;answers&quot;</span>],  <span class="hljs-comment"># 答案</span><br>            <span class="hljs-string">&quot;qa_pairs&quot;</span>: sample[<span class="hljs-string">&quot;qa_pairs&quot;</span>] <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;qa_pairs&quot;</span> <span class="hljs-keyword">in</span> sample <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>,  <span class="hljs-comment"># QA对</span><br>            <span class="hljs-string">&quot;rationale&quot;</span>: generated_text,  <span class="hljs-comment"># 生成的理由</span><br>            <span class="hljs-string">&quot;prompt&quot;</span>: prompt,  <span class="hljs-comment"># 模型输入</span><br>            <span class="hljs-string">&quot;ctxs&quot;</span>: sample[<span class="hljs-string">&quot;ctxs&quot;</span>][:n_docs][::-<span class="hljs-number">1</span>] <span class="hljs-keyword">if</span> (sample[<span class="hljs-string">&quot;ctxs&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;score&#x27;</span>] &gt; sample[<span class="hljs-string">&quot;ctxs&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&#x27;score&#x27;</span>]) <span class="hljs-keyword">else</span><br>            sample[<span class="hljs-string">&quot;ctxs&quot;</span>][:n_docs],  <span class="hljs-comment"># 上下文文档，根据分数升序</span><br>        &#125;)<br>       <br>    <span class="hljs-comment"># 将输出数据保存为JSON文件 </span><br>    jdump(output_data, output_file)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Outputs saved to <span class="hljs-subst">&#123;output_file&#125;</span>&quot;</span>)<br>    <br>    <span class="hljs-keyword">return</span> output_data<br><br>output_file = os.path.join(args.output_dir, <span class="hljs-string">&quot;result.json&quot;</span>)<br>eval_results = save_outputs(outputs, test_data, output_file, args.n_docs)<br><span class="hljs-built_in">print</span>(json.dumps(eval_results, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure>
<br/>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><code class="hljs json">Outputs saved to ./result.json<br><span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Who won nathan&#x27;s hot dog eating contest?&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-string">&quot;The Nathan&#x27;s Hot Dog Eating Contest is an annual American hot dog eating competition held on Independence Day at Nathan&#x27;s Famous Corporation&#x27;s original restaurant at the corner of Surf and Stillwell Avenues in Coney Island, a neighborhood of Brooklyn, New York City. The current men&#x27;s and women&#x27;s competitions champions are Joey Chestnut and Michelle Lesco, who crowned themselves in the 2021 edition. Previously, Miki Sudo had won the women&#x27;s competition every year from 2014-2020, with Chestnut doing so in the men&#x27;s variant in 2017 and 2016 and Matt Stonie in 2015.&quot;</span><br>        <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;qa_pairs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Who won the men&#x27;s competition of Nathan&#x27;s Hot Dog Eating Contest in 2017?&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">&quot;Joey Chestnut&quot;</span><br>                <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Who won the women&#x27;s competition of Nathan&#x27;s Hot Dog Eating Contest in 2017?&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">&quot;Miki Sudo&quot;</span><br>                <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Who won the men&#x27;s competition of Nathan&#x27;s Hot Dog Eating Contest in 2016?&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">&quot;Joey Chestnut&quot;</span><br>                <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Who won the women&#x27;s competition of Nathan&#x27;s Hot Dog Eating Contest in 2016?&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">&quot;Miki Sudo&quot;</span><br>                <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Who won the men&#x27;s competition of Nathan&#x27;s Hot Dog Eating Contest in 2015?&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">&quot;Matt Stonie&quot;</span><br>                <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Who won the women&#x27;s competition of Nathan&#x27;s Hot Dog Eating Contest in 2015?&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;answers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                    <span class="hljs-string">&quot;Miki Sudo&quot;</span><br>                <span class="hljs-punctuation">]</span><br>            <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;rationale&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;The documents provided do not directly answer the question \&quot;who won Nathan&#x27;s Hot Dog Eating Contest?\&quot; However, they do provide information about the contest, its history, and past winners.\n\nFrom Document 1, we learn that Takeru Kobayashi set a new record by eating 50 hot dogs in 2006, and Sonya Thomas became the champion of the first Nathan&#x27;s Hot Dog Eating Contest for Women in 2011.\n\nFrom Document 4, we learn that the defending men&#x27;s champion is Joey Chestnut, who ate 74 hot dogs in the 2018 contest, and the defending women&#x27;s champion is Miki Sudo, who ate 37 hot dogs in the same contest.\n\nFrom Document 5, we learn that Sonya Thomas became the first champion of Nathan&#x27;s Hot Dog Eating Contest for Women in 2011, eating 40 hot dogs in 10 minutes.\n\nBased on this information, we can conclude that:\n\n* Takeru Kobayashi won the Nathan&#x27;s Hot Dog Eating Contest in 2006, eating 50 hot dogs.\n* Sonya Thomas won the Nathan&#x27;s Hot Dog Eating Contest for Women in 2011, eating 40 hot dogs.\n* Joey Chestnut is the defending men&#x27;s champion, having eaten 74 hot dogs in the 2018 contest.\n* Miki Sudo is the defending women&#x27;s champion, having eaten 37 hot dogs in the 2018 contest.\n\nTherefore, the answer to the question \&quot;who won Nathan&#x27;s Hot Dog Eating Contest?\&quot; is not a single answer, but rather a list of past winners, including Takeru Kobayashi, Sonya Thomas, Joey Chestnut, and Miki Sudo.&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;prompt&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\nDocument 1 (Title: Nathan&#x27;s Hot Dog Eating Contest): competitive eating by downing 50 hot dogs—smashing the previous record of 25.5. The Japanese eater introduced advanced eating and training techniques that shattered previous competitive eating world records. The rise in popularity of the event coincided with the surge in popularity of the worldwide competitive eating circuit. On July 4, 2011, Sonya Thomas became the champion of the first Nathan&#x27;s Hot Dog Eating Contest for Women. Previously, women and men had competed against each other, except for one all-female Memorial Day competition held in 1975. Eating 40 hot dogs in 10 minutes, Thomas earned the inaugural Pepto-Bismol-sponsored pink belt and\n\nDocument 2 (Title: Nathan&#x27;s Hot Dog Eating Contest): Island most years since about 1972, usually in conjunction with Independence Day. Nathan&#x27;s promoter Mortimer Matz claimed that on July 4, 1916, four immigrants held a hot dog eating contest at Nathan&#x27;s Famous stand on Coney Island to settle an argument about who was the most patriotic. He also made the spurious claim that the contest has been held each year since then except 1941 (\&quot;as a protest to the war in Europe\&quot;) and 1971 (as a protest to political unrest in the U.S.). A man by the name of Jim Mullen is said to have won the first contest,\n\nDocument 3 (Title: Nathan&#x27;s Hot Dog Eating Contest): called to the stage individually during introductions. In 2013, six-time defending champion Joey Chestnut was escorted to the stage in a sedan chair. The competition draws many spectators and worldwide press coverage. In 2007, an estimated 50,000 came out to witness the event. In 2004 a three-story-high \&quot;Hot Dog Eating Wall of Fame\&quot; was erected at the site of the annual contest. The wall lists past winners, and has a digital clock which counts down the minutes until the next contest. Despite substantial damage suffered at Nathan&#x27;s due to Hurricane Sandy in October 2012, the location was repaired, reopened, and\n\nDocument 4 (Title: Nathan&#x27;s Hot Dog Eating Contest): Nathan&#x27;s Hot Dog Eating Contest The Nathan&#x27;s Hot Dog Eating Contest is an annual American hot dog competitive eating competition. It is held each year on Independence Day at Nathan&#x27;s Famous Corporation&#x27;s original, and best-known restaurant at the corner of Surf and Stillwell Avenues in Coney Island, a neighborhood of Brooklyn, New York City. The contest has gained public attention in recent years due to the stardom of Takeru Kobayashi and Joey Chestnut. The defending men&#x27;s champion is Joey Chestnut, who ate 74 hot dogs in the 2018 contest. The defending women&#x27;s champion is Miki Sudo, who ate 37 hot\n\nDocument 5 (Title: Sonya Thomas): at the time. The only eaters besides Kobayashi to defeat Thomas between the 2004 and 2005 Nathan&#x27;s contests were Bill \&quot;El Wingador\&quot; Simmons in the controversial 2005 Wing Bowl, and Dale Boone, who won a contest eating overheated baked beans after he doused the beans in water to cool them down. On July 4, 2011, Thomas became the first champion of Nathan&#x27;s Hot Dog Eating Contest for Women. Eating 40 hot dogs in 10 minutes, Thomas earned the inaugural Pink Belt and won $10,000. Thomas had won 1st place in the National Buffalo Wing Festival US chicken wing eating championship\n\nBased on your knowledge and the provided information, answer the question:\nwho won nathan&#x27;s hot dog eating contest?&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n\n&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;ctxs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;3360010&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Nathan&#x27;s Hot Dog Eating Contest&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;competitive eating by downing 50 hot dogs—smashing the previous record of 25.5. The Japanese eater introduced advanced eating and training techniques that shattered previous competitive eating world records. The rise in popularity of the event coincided with the surge in popularity of the worldwide competitive eating circuit. On July 4, 2011, Sonya Thomas became the champion of the first Nathan&#x27;s Hot Dog Eating Contest for Women. Previously, women and men had competed against each other, except for one all-female Memorial Day competition held in 1975. Eating 40 hot dogs in 10 minutes, Thomas earned the inaugural Pepto-Bismol-sponsored pink belt and&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.7802734375</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;3360007&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Nathan&#x27;s Hot Dog Eating Contest&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Island most years since about 1972, usually in conjunction with Independence Day. Nathan&#x27;s promoter Mortimer Matz claimed that on July 4, 1916, four immigrants held a hot dog eating contest at Nathan&#x27;s Famous stand on Coney Island to settle an argument about who was the most patriotic. He also made the spurious claim that the contest has been held each year since then except 1941 (\&quot;as a protest to the war in Europe\&quot;) and 1971 (as a protest to political unrest in the U.S.). A man by the name of Jim Mullen is said to have won the first contest,&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.7802734375</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;3360012&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Nathan&#x27;s Hot Dog Eating Contest&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;called to the stage individually during introductions. In 2013, six-time defending champion Joey Chestnut was escorted to the stage in a sedan chair. The competition draws many spectators and worldwide press coverage. In 2007, an estimated 50,000 came out to witness the event. In 2004 a three-story-high \&quot;Hot Dog Eating Wall of Fame\&quot; was erected at the site of the annual contest. The wall lists past winners, and has a digital clock which counts down the minutes until the next contest. Despite substantial damage suffered at Nathan&#x27;s due to Hurricane Sandy in October 2012, the location was repaired, reopened, and&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.7958984375</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;3360002&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Nathan&#x27;s Hot Dog Eating Contest&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Nathan&#x27;s Hot Dog Eating Contest The Nathan&#x27;s Hot Dog Eating Contest is an annual American hot dog competitive eating competition. It is held each year on Independence Day at Nathan&#x27;s Famous Corporation&#x27;s original, and best-known restaurant at the corner of Surf and Stillwell Avenues in Coney Island, a neighborhood of Brooklyn, New York City. The contest has gained public attention in recent years due to the stardom of Takeru Kobayashi and Joey Chestnut. The defending men&#x27;s champion is Joey Chestnut, who ate 74 hot dogs in the 2018 contest. The defending women&#x27;s champion is Miki Sudo, who ate 37 hot&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.7978515625</span><br>            <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">&#123;</span><br>                <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;3425375&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Sonya Thomas&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;at the time. The only eaters besides Kobayashi to defeat Thomas between the 2004 and 2005 Nathan&#x27;s contests were Bill \&quot;El Wingador\&quot; Simmons in the controversial 2005 Wing Bowl, and Dale Boone, who won a contest eating overheated baked beans after he doused the beans in water to cool them down. On July 4, 2011, Thomas became the first champion of Nathan&#x27;s Hot Dog Eating Contest for Women. Eating 40 hot dogs in 10 minutes, Thomas earned the inaugural Pink Belt and won $10,000. Thomas had won 1st place in the National Buffalo Wing Festival US chicken wing eating championship&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-attr">&quot;score&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.8037109375</span><br>            <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">]</span><br></code></pre></td></tr></table></figure>

<ol start="12">
<li>加载 <code>metrics.py</code> 中的函数：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 标准化答案文本</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalize_answer</span>(<span class="hljs-params">s</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">remove_articles</span>(<span class="hljs-params">text</span>): <span class="hljs-comment"># 移除冠词（a, an, the）</span><br>        <span class="hljs-keyword">return</span> re.sub(<span class="hljs-string">r&quot;\b(a|an|the)\b&quot;</span>, <span class="hljs-string">&quot; &quot;</span>, text)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">white_space_fix</span>(<span class="hljs-params">text</span>): <span class="hljs-comment"># 修复多余的空格，确保单词之间只有一个空格</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot; &quot;</span>.join(text.split())<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">remove_punc</span>(<span class="hljs-params">text</span>): <span class="hljs-comment"># 移除所有标点符号</span><br>        exclude = <span class="hljs-built_in">set</span>(string.punctuation)<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>.join(ch <span class="hljs-keyword">for</span> ch <span class="hljs-keyword">in</span> text <span class="hljs-keyword">if</span> ch <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> exclude)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">lower</span>(<span class="hljs-params">text</span>): <span class="hljs-comment"># 将文本转换为小写</span><br>        <span class="hljs-keyword">return</span> text.lower()<br><br>    <span class="hljs-comment"># 依次应用上述函数：小写化 -&gt; 移除标点 -&gt; 移除冠词 -&gt; 修复空格</span><br>    <span class="hljs-keyword">return</span> white_space_fix(remove_articles(remove_punc(lower(s))))<br><br><span class="hljs-comment"># 检查答案列表中是否有任一答案出现在给定的上下文中</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">exact_presence</span>(<span class="hljs-params">answers, context</span>):<br>    <span class="hljs-comment"># 标准化所有答案和上下文</span><br>    answers = [normalize_answer(ans) <span class="hljs-keyword">for</span> ans <span class="hljs-keyword">in</span> answers]<br>    context = normalize_answer(context)<br><br>    <span class="hljs-comment"># 遍历每个答案，检查是否在上下文中出现</span><br>    <span class="hljs-keyword">for</span> ans <span class="hljs-keyword">in</span> answers:<br>        <span class="hljs-keyword">if</span> ans <span class="hljs-keyword">in</span> context:<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span>  <span class="hljs-comment"># 所有答案均未出现</span><br><br><span class="hljs-comment"># 计算STR-EM指标（仅适用于ASQA数据集）</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_str_em</span>(<span class="hljs-params">data</span>):<br>    <span class="hljs-comment"># 检查数据是否包含qa_pairs字段</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;qa_pairs&#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> data[<span class="hljs-number">0</span>] <span class="hljs-keyword">or</span> data[<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;qa_pairs&#x27;</span>] <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br><br>    acc = []  <span class="hljs-comment"># 存储每个QA对的准确率</span><br>    hit = []  <span class="hljs-comment"># 存储是否完全命中（所有QA对均准确）</span><br><br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> data:<br>        loc_acc = []  <span class="hljs-comment"># 临时存储当前item中每个QA对的检查结果</span><br>        <span class="hljs-keyword">for</span> qa_pair <span class="hljs-keyword">in</span> item[<span class="hljs-string">&#x27;qa_pairs&#x27;</span>]:<br>            <span class="hljs-comment"># 检查当前QA对的答案是否出现在rationale中</span><br>            loc_acc.append(exact_presence(qa_pair[<span class="hljs-string">&#x27;answers&#x27;</span>], item[<span class="hljs-string">&quot;rationale&quot;</span>]))<br><br>        <span class="hljs-comment"># 计算当前item的准确率和是否完全命中</span><br>        acc.append(np.mean(loc_acc))<br>        hit.append(<span class="hljs-built_in">int</span>(np.mean(loc_acc) == <span class="hljs-number">1</span>))<br><br>    <span class="hljs-comment"># 返回平均准确率和完全命中率（转换为百分比）</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">100</span> * np.mean(acc), <span class="hljs-number">100</span> * np.mean(hit)<br><br><span class="hljs-comment"># 计算并保存评估指标</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_metrics</span>(<span class="hljs-params">data, save_dir=<span class="hljs-literal">None</span>, is_asqa=<span class="hljs-literal">False</span></span>):<br>    idx = <span class="hljs-number">0</span><br>    num_accurate = <span class="hljs-number">0</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Evaluating results...&#x27;</span>)<br>    <span class="hljs-keyword">if</span> is_asqa:<br>        <span class="hljs-comment"># 如果是ASQA数据集，计算STR-EM指标</span><br>        rationale_str_em, _ = compute_str_em(data)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># 否则遍历数据，检查每个答案是否出现在rationale中</span><br>        <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> tqdm(data):<br>            idx += <span class="hljs-number">1</span><br>            is_accurate = exact_presence(d[<span class="hljs-string">&#x27;answers&#x27;</span>], d[<span class="hljs-string">&#x27;rationale&#x27;</span>])<br>            num_accurate += <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> is_accurate <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">if</span> is_asqa:<br>        <span class="hljs-comment"># 打印并保存ASQA的评估结果</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Rationale EM: <span class="hljs-subst">&#123;rationale_str_em:<span class="hljs-number">.1</span>f&#125;</span>%&quot;</span>)<br>        eval_result = &#123;<span class="hljs-string">&quot;EM&quot;</span>: rationale_str_em, <span class="hljs-string">&quot;num_examples&quot;</span>: idx&#125;<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># 打印并保存普通数据集的评估结果</span><br>        accuracy = num_accurate / idx * <span class="hljs-number">100</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Accuracy: <span class="hljs-subst">&#123;accuracy:<span class="hljs-number">.1</span>f&#125;</span>%&quot;</span>)<br>        eval_result = &#123;<span class="hljs-string">&quot;accuracy&quot;</span>: accuracy, <span class="hljs-string">&quot;num_examples&quot;</span>: idx&#125;<br>    <br>    <span class="hljs-comment"># 将评估结果保存到JSON文件</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;save_dir&#125;</span>/metrics.json&quot;</span>, <span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        f.write(json.dumps(eval_result) + <span class="hljs-string">&quot;\n&quot;</span>)   <br><br>    <span class="hljs-keyword">return</span> eval_result  <span class="hljs-comment"># 返回评估结果</span><br></code></pre></td></tr></table></figure>

<ol start="13">
<li>评估结果：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">get_metrics(eval_results, args.output_dir, is_asqa=args.dataset_name == <span class="hljs-string">&#x27;ASQA&#x27;</span>)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">Evaluating results...
Rationale EM: 83.3%
&#123;&#39;EM&#39;: 83.33333333333334, &#39;num_examples&#39;: 0&#125;
</code></pre>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/" class="category-chain-item">代码复现</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/RAG/" class="print-no-link">#RAG</a>
      
        <a href="/tags/LLM/" class="print-no-link">#LLM</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>【论文复现】InstructRAG</div>
      <div>http://xuan-van.github.io/代码复现/【论文复现】instructrag/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>文晋</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年2月26日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="NC - 非商业性使用">
                    <i class="iconfont icon-cc-nc"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - 相同方式共享">
                    <i class="iconfont icon-cc-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8/%E3%80%90%E5%8D%9A%E5%AE%A2%E5%85%A5%E9%97%A8%E3%80%91%E5%9F%BA%E4%BA%8E-hexo-%E7%9A%84%E4%B8%BB%E9%A2%98-fluid-%E6%90%AD%E5%BB%BA-github-%E5%8D%9A%E5%AE%A2/" title="【博客入门】基于 Hexo 的主题 Fluid 搭建 Github 博客">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">【博客入门】基于 Hexo 的主题 Fluid 搭建 Github 博客</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91selfrag/" title="【论文复现】SelfRAG">
                        <span class="hidden-mobile">【论文复现】SelfRAG</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.utils.listenDOMLoaded(function() {
      Fluid.events.registerRefreshCallback(function() {
        if ('mermaid' in window) {
          mermaid.init();
        }
      });
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>




  
<script src="/background/background.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<!-- hexo injector body_end start --><script src="/background/background.js"></script><!-- hexo injector body_end end --></body>
</html>
