

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/background/%E5%9B%BE%E6%A0%87.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="文晋">
  <meta name="keywords" content="">
  
    <meta name="description" content=".jqutrkhwuolq{}   方法图示：   参考项目：Jeryi-Sun&#x2F;ReDEeP-ICLR，详情参见：Xuan-Van&#x2F;ReDeEP。 1 安装1.1 虚拟环境12345678conda create -n redeep python&#x3D;3.9conda activate redeeppip install numpy&#x3D;&#x3D;1.26.0 torch&#x3D;&#x3D;2.0">
<meta property="og:type" content="article">
<meta property="og:title" content="【论文复现】ReDeEP">
<meta property="og:url" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91redeep/index.html">
<meta property="og:site_name" content="文心晋意">
<meta property="og:description" content=".jqutrkhwuolq{}   方法图示：   参考项目：Jeryi-Sun&#x2F;ReDEeP-ICLR，详情参见：Xuan-Van&#x2F;ReDeEP。 1 安装1.1 虚拟环境12345678conda create -n redeep python&#x3D;3.9conda activate redeeppip install numpy&#x3D;&#x3D;1.26.0 torch&#x3D;&#x3D;2.0">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91redeep/1.png">
<meta property="og:image" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91redeep/2.jpg">
<meta property="og:image" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91redeep/3.png">
<meta property="article:published_time" content="2025-05-27T04:00:00.000Z">
<meta property="article:modified_time" content="2025-05-27T02:49:43.305Z">
<meta property="article:author" content="文晋">
<meta property="article:tag" content="RAG">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91redeep/1.png">
  
  
  
  <title>【论文复现】ReDeEP - 文心晋意</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/background/background.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"xuan-van.github.io","root":"/","version":"1.9.8","typing":{"enable":false,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":3},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body><!-- hexo injector body_begin start --><div id="web_bg"></div><!-- hexo injector body_begin end -->
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>文晋的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-image"></i>
                <span>图片</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/images/llama.svg" target="_self">
                    
                    <span>Llama 结构</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">【论文复现】ReDeEP</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-05-27 12:00" pubdate>
          2025年5月27日 中午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          11k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          91 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar category-bar" style="margin-right: -1rem">
    





<div class="category-list">
  
  
    
    
    
    <div class="category row nomargin-x">
      <a class="category-item 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="代码复现"
        id="heading-211acd8e7f189296b7caddd5c95b71af" role="tab" data-toggle="collapse" href="#collapse-211acd8e7f189296b7caddd5c95b71af"
        aria-expanded="true"
      >
        代码复现
        <span class="list-group-count">(8)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-211acd8e7f189296b7caddd5c95b71af"
           role="tabpanel" aria-labelledby="heading-211acd8e7f189296b7caddd5c95b71af">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E4%BB%A3%E7%A0%81%E6%8B%86%E8%A7%A3%E3%80%91trajectory-transformer/" title="【代码拆解】Trajectory Transformer"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【代码拆解】Trajectory Transformer</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87%E3%80%91%E5%B8%B8%E7%94%A8%E9%97%AE%E7%AD%94%E6%95%B0%E6%8D%AE%E9%9B%86/" title="【数据准备】常用问答数据集"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【数据准备】常用问答数据集</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0%E3%80%91%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0-llama3/" title="【模型复现】从零实现 Llama3"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【模型复现】从零实现 Llama3</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91hipporag-hipporag2/" title="【论文复现】HippoRAG &amp; HippoRAG2"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【论文复现】HippoRAG &amp; HippoRAG2</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91instructrag/" title="【论文复现】InstructRAG"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【论文复现】InstructRAG</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91redeep/" title="【论文复现】ReDeEP"
           class="list-group-item list-group-item-action
           active">
          <span class="category-post">【论文复现】ReDeEP</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91selfrag/" title="【论文复现】SelfRAG"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【论文复现】SelfRAG</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91xrag/" title="【论文复现】xRAG"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【论文复现】xRAG</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
</div>


  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">【论文复现】ReDeEP</h1>
            
            
              <div class="markdown-body">
                
                <figure style="text-align: center;">
    <style>.jqutrkhwuolq{}</style><img src="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91redeep/1.png" srcset="/img/loading.gif" lazyload class="jqutrkhwuolq">
</figure>

<p>方法图示：</p>
<img src="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91redeep/2.jpg" srcset="/img/loading.gif" lazyload class="">

<p>参考项目：<a target="_blank" rel="noopener" href="https://github.com/Jeryi-Sun/ReDEeP-ICLR">Jeryi-Sun&#x2F;ReDEeP-ICLR</a>，详情参见：<a target="_blank" rel="noopener" href="https://github.com/Xuan-Van/ReDeEP">Xuan-Van&#x2F;ReDeEP</a>。</p>
<h1 id="1-安装"><a href="#1-安装" class="headerlink" title="1 安装"></a>1 安装</h1><h2 id="1-1-虚拟环境"><a href="#1-1-虚拟环境" class="headerlink" title="1.1 虚拟环境"></a>1.1 虚拟环境</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda create -n redeep python=3.9<br>conda activate redeep<br>pip install numpy==1.26.0 torch==2.0.1 accelerate==0.23.0 pandas==2.1.1 scikit-learn===1.3.1 sentence_transformers ipykernel<br>python -m ipykernel install --user --name redeep<br>jupyter kernelspec list<br><br><span class="hljs-built_in">cd</span> src<br>pip install -e transformers<br></code></pre></td></tr></table></figure>

<h2 id="1-2-项目结构"><a href="#1-2-项目结构" class="headerlink" title="1.2 项目结构"></a>1.2 项目结构</h2><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs nix">dataset<span class="hljs-symbol">/</span><br>    copy_heads <span class="hljs-comment"># 复制头信息</span><br>    dolly <span class="hljs-comment"># 数据集</span><br>    ragtruth <span class="hljs-comment"># 数据集</span><br>    token_hyperparameter <span class="hljs-comment"># AARF.py 的超参数</span><br><br>log<span class="hljs-symbol">/</span> <span class="hljs-comment"># 保存运行结果</span><br><br>src<span class="hljs-symbol">/</span> <span class="hljs-comment"># 保存项目脚本</span><br>    AARF.py<br>    detect.py<br>    regress.py<br><br>transformers<span class="hljs-symbol">/</span> <span class="hljs-comment"># 保存修改的 transformers 库</span><br><br>test.sh <span class="hljs-comment"># 更多研究所使用的脚本</span><br></code></pre></td></tr></table></figure>

<h2 id="1-3-模型"><a href="#1-3-模型" class="headerlink" title="1.3 模型"></a>1.3 模型</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">huggingface-cli download --resume-download meta-llama/Llama-2-7b-chat-hf --token Your_token --local-dir model/Llama-2-7b-chat-hf<br>huggingface-cli download --resume-download BAAI/bge-base-en-v1.5 --local-dir model/bge-base-en-v1.5<br></code></pre></td></tr></table></figure>

<h2 id="1-4-数据集"><a href="#1-4-数据集" class="headerlink" title="1.4 数据集"></a>1.4 数据集</h2><p>数据集下载：<a target="_blank" rel="noopener" href="https://drive.google.com/file/d/1s-pmaBQutC6eQGtk2F3uKaMSkn_iGQwR/view?usp=sharing">google drive</a></p>
<p>以 RAGTruth 数据集为例，其结构为：</p>
<ol>
<li><code>response.jsonl</code>：</li>
</ol>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # 回应的索引 <br>    <span class="hljs-attr">&quot;source_id&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> 来源信息的索引<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;model&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # 生成回应的模型：gpt<span class="hljs-number">-4</span><span class="hljs-number">-0613</span>、gpt<span class="hljs-number">-3.5</span>-turbo<span class="hljs-number">-0613</span>、mistral<span class="hljs-number">-7</span>B-instruct、llama<span class="hljs-number">-2</span><span class="hljs-number">-7</span>b-chat、llama<span class="hljs-number">-2</span><span class="hljs-number">-13</span>b-chat、llama<span class="hljs-number">-2</span><span class="hljs-number">-70</span>b-chat<br>    <span class="hljs-attr">&quot;temperature&quot;</span><span class="hljs-punctuation">:</span> float<span class="hljs-punctuation">,</span> # 生成回应的温度：<span class="hljs-number">0.7</span>、<span class="hljs-number">0.775</span>、<span class="hljs-number">1.0</span>、<span class="hljs-number">0.85</span>、<span class="hljs-number">0.925</span> <br>    <span class="hljs-attr">&quot;labels&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;start&quot;</span><span class="hljs-punctuation">:</span> int<span class="hljs-punctuation">,</span> # 在回应中的起始位置<br>            <span class="hljs-attr">&quot;end&quot;</span><span class="hljs-punctuation">:</span> int<span class="hljs-punctuation">,</span> # 在回应中的终止位置<br>            <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # 回应中的幻觉文本<br>            <span class="hljs-attr">&quot;meta&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # 注释人员对幻觉的评论<br>            <span class="hljs-attr">&quot;label_type&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # 幻觉类型<br>            <span class="hljs-attr">&quot;implicit_true&quot;</span><span class="hljs-punctuation">:</span> bool<span class="hljs-punctuation">,</span> # 是否和上下文冲突：回应正确，上下文没提及<br>            <span class="hljs-attr">&quot;due_to_null&quot;</span><span class="hljs-punctuation">:</span> bool<span class="hljs-punctuation">,</span> # 幻觉是否由 <span class="hljs-literal"><span class="hljs-keyword">null</span></span> 值引起<br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        ...<br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> <br>    <span class="hljs-attr">&quot;split&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # train、test <br>    <span class="hljs-attr">&quot;quality&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # good（回应质量好）、incorrect_refusal（尽管存在相关上下文，模型错误地拒绝回答）、truncated（回应意外截断） <br>    <span class="hljs-attr">&quot;response&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> 大模型对给定指令的回应<br><span class="hljs-punctuation">&#125;</span><br>```  <br><br><span class="hljs-number">2.</span> `source_info.jsonl`：<br>```json<br><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;source_id&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # 来源信息的索引<br>    <span class="hljs-attr">&quot;task_type&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # Summary、QA、Data2txt <br>    <span class="hljs-attr">&quot;source&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # 原始内容来源：CNN/DM、Recent News、Yelp、MARCO <br>    <span class="hljs-attr">&quot;source_info&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # RAG 设置的基本内容：Summary是字符串，其他任务是字典<br>    <span class="hljs-attr">&quot;prompt&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # 用来生成回应的提示<br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>

<h2 id="1-5-更多研究"><a href="#1-5-更多研究" class="headerlink" title="1.5 更多研究"></a>1.5 更多研究</h2><p>在相同的评估指标下，将 Copy Heads 替换为每层的 Attention Heads，得到的结果：  </p>
<img src="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91redeep/3.png" srcset="/img/loading.gif" lazyload class="">

<h1 id="2-脚本分析"><a href="#2-脚本分析" class="headerlink" title="2 脚本分析"></a>2 脚本分析</h1><h2 id="2-1-文件结构"><a href="#2-1-文件结构" class="headerlink" title="2.1 文件结构"></a>2.1 文件结构</h2><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs stata">dataset/<br>    llama2_7B_response_chunk.json：chunk 级别的 <span class="hljs-keyword">regress</span>.py 的数据集构建<br>    llama2_7B_response_token.json：<span class="hljs-keyword">token</span> 级别的 <span class="hljs-keyword">regress</span>.py 的数据集构建<br>    response.jsonl：只有一组数据，用于 <span class="hljs-keyword">token</span> 级别的 detect.py 和 AARF.py<br>    response_spans.jsonl：只有一组数据，用于 chunk 级别的 detect.py<br>    source_info_chunk.jsonl：用于 chunk 级别的 <span class="hljs-keyword">regress</span>.py<br>    source_info.jsonl：只有一组数据，用于 <span class="hljs-keyword">token</span> 级别的 detect.py 和 AARF.py<br>    source_info_spans.jsonl：只有一组数据，用于 chunk 级别的 detect.py<br>    token_hyperparameter.json：AARF.py 的超参数<br>    topk_heads.json：用于 detect.py 和 <span class="hljs-keyword">token</span> 级别的 <span class="hljs-keyword">regress</span>.py<br>    <br>output/<br>    AARF_add_1.2_reduce_0.8_threshold_0.6.json：由 AARF.py 生成<br>    llama2_7B_response_chunk.json：由 chunk 级别的 detect.py 生成<br>    llama2_7B_response_token.json：由 <span class="hljs-keyword">token</span> 级别的 detect.py 生成<br>    ReDeEP_chunk.json：由 chunk 级别的 <span class="hljs-keyword">regress</span>.py 生成<br>    ReDeEP_token.json：由 <span class="hljs-keyword">token</span> 级别的 <span class="hljs-keyword">regress</span>.py 生成<br>    <br>src/ # 脚本分析<br>    token_detect.ipynb<br>    chunk_detect.ipynb<br>    token_regress.ipynb<br>    chunk_regress.ipynb<br>    AARF.ipynb<br>    <br>transformers/ # 修改后的 transformers 包<br></code></pre></td></tr></table></figure>

<h2 id="2-2-detect-py"><a href="#2-2-detect-py" class="headerlink" title="2.2 detect.py"></a>2.2 detect.py</h2><h3 id="2-2-1-token-级别"><a href="#2-2-1-token-级别" class="headerlink" title="2.2.1 token 级别"></a>2.2.1 token 级别</h3><ol>
<li>导入必要的包：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br>sys.path.insert(<span class="hljs-number">0</span>, <span class="hljs-string">&#x27;../transformers/src&#x27;</span>)  <span class="hljs-comment"># 将一个特定的路径添加到 Python 的模块搜索路径中</span><br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure>

<ol start="2">
<li>加载 response：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">response = []<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../dataset/response.jsonl&quot;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>        data = json.loads(line)<br>        response.append(data)<br>        <br><span class="hljs-built_in">print</span>(json.dumps(response, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[
    &#123;
        &quot;id&quot;: &quot;27&quot;,
        &quot;source_id&quot;: &quot;15596&quot;,
        &quot;model&quot;: &quot;llama-2-7b-chat&quot;,
        &quot;temperature&quot;: 0.7,
        &quot;labels&quot;: [],
        &quot;split&quot;: &quot;test&quot;,
        &quot;quality&quot;: &quot;good&quot;,
        &quot;response&quot;: &quot;FBI charges Philadelphia woman with attempting to join ISIS after purchasing electronic visa for Turkey. Keonna Thomas, 30, also known as \&quot;Young Lioness\&quot; and \&quot;Fatayat Al Khilafah,\&quot; made numerous social media posts expressing desire to fight for ISIS. She could face 15 years in prison. Three women have been arrested this week on terror charges, including two in New York who were accused of planning to build an explosive device for attacks in the US.&quot;
    &#125;
]
</code></pre>
<ol start="3">
<li>加载 source_info：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">source_info_dict = &#123;&#125;<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../dataset/source_info.jsonl&quot;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>        data = json.loads(line)<br>        source_info_dict[data[<span class="hljs-string">&#x27;source_id&#x27;</span>]] = data<br>        <br><span class="hljs-built_in">print</span>(json.dumps(source_info_dict, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>))       <br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&#123;
    &quot;15596&quot;: &#123;
        &quot;source_id&quot;: &quot;15596&quot;,
        &quot;task_type&quot;: &quot;Summary&quot;,
        &quot;source&quot;: &quot;CNN/DM&quot;,
        &quot;source_info&quot;: &quot;The FBI charged a Philadelphia woman on Thursday with trying to travel overseas to fight for ISIS. She&#39;s one of three women arrested this week on terror charges. Two New York women were also taken into custody. An FBI complaint cites numerous social media messages dating back to August 2013 that were sent by Keonna Thomas, 30, also known as \&quot;Young Lioness\&quot; and \&quot;Fatayat Al Khilafah.\&quot; One Twitter message said, \&quot;If we truly knew the realities ... we all would be rushing to join our brothers in the front lines pray ALLAH accept us as shuhada [martyrs].\&quot; Another said, \&quot;When you&#39;re a mujahid [violent jihadi fighter] your death becomes a wedding.\&quot; The FBI said Thomas purchased an electronic visa to Turkey on March 23. Turkey is known as the easiest place from which to enter Syria and join ISIS. An ISIS manual advises recruits to buy round-trip tickets to vacation spots such as Spain and then purchase tickets for their real destination once they arrive overseas, the FBI said. On March 26, Thomas purchased a ticket to Barcelona, with a March 29 departure and an April 15 return to the United States, the complaint said. It&#39;s not clear when or where she was arrested. She was charged with knowingly attempting to provide material support and resources to a designated foreign terrorist organization. She could be sentenced to 15 years in prison. On Thursday, Noelle Velentzas, 28, and her former roommate, Asia Siddiqui, 31, were arrested in New York and accused of planning to build an explosive device for attacks in the United States, federal prosecutors said. In the past 18 months, the Justice Department&#39;s National Security Division has prosecuted or is prosecuting more than 30 cases of people attempting to travel abroad to join or provide support to terrorist groups. Of those cases, 18 allegedly involve support to ISIS. \&quot;The terrorist threat is more decentralized, more diffuse, more complicated,\&quot; Homeland Security Secretary Jeh Johnson told reporters Thursday. \&quot;It involves the potential lone wolf actor, it involves the effective use of social media, the Internet.\&quot;\n&quot;,
        &quot;prompt&quot;: &quot;Summarize the following news within 86 words:\nThe FBI charged a Philadelphia woman on Thursday with trying to travel overseas to fight for ISIS. She&#39;s one of three women arrested this week on terror charges. Two New York women were also taken into custody. An FBI complaint cites numerous social media messages dating back to August 2013 that were sent by Keonna Thomas, 30, also known as \&quot;Young Lioness\&quot; and \&quot;Fatayat Al Khilafah.\&quot; One Twitter message said, \&quot;If we truly knew the realities ... we all would be rushing to join our brothers in the front lines pray ALLAH accept us as shuhada [martyrs].\&quot; Another said, \&quot;When you&#39;re a mujahid [violent jihadi fighter] your death becomes a wedding.\&quot; The FBI said Thomas purchased an electronic visa to Turkey on March 23. Turkey is known as the easiest place from which to enter Syria and join ISIS. An ISIS manual advises recruits to buy round-trip tickets to vacation spots such as Spain and then purchase tickets for their real destination once they arrive overseas, the FBI said. On March 26, Thomas purchased a ticket to Barcelona, with a March 29 departure and an April 15 return to the United States, the complaint said. It&#39;s not clear when or where she was arrested. She was charged with knowingly attempting to provide material support and resources to a designated foreign terrorist organization. She could be sentenced to 15 years in prison. On Thursday, Noelle Velentzas, 28, and her former roommate, Asia Siddiqui, 31, were arrested in New York and accused of planning to build an explosive device for attacks in the United States, federal prosecutors said. In the past 18 months, the Justice Department&#39;s National Security Division has prosecuted or is prosecuting more than 30 cases of people attempting to travel abroad to join or provide support to terrorist groups. Of those cases, 18 allegedly involve support to ISIS. \&quot;The terrorist threat is more decentralized, more diffuse, more complicated,\&quot; Homeland Security Secretary Jeh Johnson told reporters Thursday. \&quot;It involves the potential lone wolf actor, it involves the effective use of social media, the Internet.\&quot;\n\noutput:&quot;
    &#125;
&#125;
</code></pre>
<ol start="4">
<li>加载 model 和 tokenizer：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">model_name = <span class="hljs-string">&quot;../../model/Llama-2-7b-chat-hf&quot;</span><br>model = AutoModelForCausalLM.from_pretrained(model_name, device_map=<span class="hljs-string">&quot;auto&quot;</span>, torch_dtype=torch.float16)<br>tokenizer = AutoTokenizer.from_pretrained(model_name)<br>device = <span class="hljs-string">&quot;cuda&quot;</span><br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">Loading checkpoint shards: 100%|██████████| 2/2 [00:35&lt;00:00, 17.92s/it]
</code></pre>
<ol start="5">
<li>加载 copy_heads：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../dataset/topk_heads.json&quot;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    copy_heads = json.load(f)<br>    <br><span class="hljs-built_in">print</span>(copy_heads)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(copy_heads))<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[[25, 0], [18, 13], [18, 10], [27, 9], [5, 29], [23, 8], [31, 28], [3, 0], [31, 24], [13, 20], [31, 18], [1, 14], [2, 5], [22, 10], [2, 22], [15, 7], [3, 19], [20, 17], [10, 20], [23, 30], [20, 22], [1, 27], [20, 1], [31, 19], [28, 18], [20, 15], [1, 21], [19, 1], [20, 5], [16, 1], [18, 9], [5, 13]]
32
</code></pre>
<ol start="6">
<li>选择数据类型，对应 JSONL 的 model 字段：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">data_type = <span class="hljs-string">&quot;llama-2-7b-chat&quot;</span><br><br>select_response = []<br>i = <span class="hljs-number">0</span><br>response[i][<span class="hljs-string">&#x27;model&#x27;</span>] == data_type <span class="hljs-keyword">and</span> response[i][<span class="hljs-string">&quot;split&quot;</span>] == <span class="hljs-string">&quot;test&quot;</span><br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">True
</code></pre>
<ol start="7">
<li>字段提取：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">response_rag = response[i][<span class="hljs-string">&#x27;response&#x27;</span>]<br>source_id = response[i][<span class="hljs-string">&#x27;source_id&#x27;</span>]<br>temperature = response[i][<span class="hljs-string">&#x27;temperature&#x27;</span>]<br>prompt = source_info_dict[source_id][<span class="hljs-string">&#x27;prompt&#x27;</span>]<br><br><span class="hljs-built_in">print</span>(response_rag)<br><span class="hljs-built_in">print</span>(source_id)<br><span class="hljs-built_in">print</span>(temperature)<br><span class="hljs-built_in">print</span>(prompt)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">FBI charges Philadelphia woman with attempting to join ISIS after purchasing electronic visa for Turkey. Keonna Thomas, 30, also known as &quot;Young Lioness&quot; and &quot;Fatayat Al Khilafah,&quot; made numerous social media posts expressing desire to fight for ISIS. She could face 15 years in prison. Three women have been arrested this week on terror charges, including two in New York who were accused of planning to build an explosive device for attacks in the US.
15596
0.7
Summarize the following news within 86 words:
The FBI charged a Philadelphia woman on Thursday with trying to travel overseas to fight for ISIS. She&#39;s one of three women arrested this week on terror charges. Two New York women were also taken into custody. An FBI complaint cites numerous social media messages dating back to August 2013 that were sent by Keonna Thomas, 30, also known as &quot;Young Lioness&quot; and &quot;Fatayat Al Khilafah.&quot; One Twitter message said, &quot;If we truly knew the realities ... we all would be rushing to join our brothers in the front lines pray ALLAH accept us as shuhada [martyrs].&quot; Another said, &quot;When you&#39;re a mujahid [violent jihadi fighter] your death becomes a wedding.&quot; The FBI said Thomas purchased an electronic visa to Turkey on March 23. Turkey is known as the easiest place from which to enter Syria and join ISIS. An ISIS manual advises recruits to buy round-trip tickets to vacation spots such as Spain and then purchase tickets for their real destination once they arrive overseas, the FBI said. On March 26, Thomas purchased a ticket to Barcelona, with a March 29 departure and an April 15 return to the United States, the complaint said. It&#39;s not clear when or where she was arrested. She was charged with knowingly attempting to provide material support and resources to a designated foreign terrorist organization. She could be sentenced to 15 years in prison. On Thursday, Noelle Velentzas, 28, and her former roommate, Asia Siddiqui, 31, were arrested in New York and accused of planning to build an explosive device for attacks in the United States, federal prosecutors said. In the past 18 months, the Justice Department&#39;s National Security Division has prosecuted or is prosecuting more than 30 cases of people attempting to travel abroad to join or provide support to terrorist groups. Of those cases, 18 allegedly involve support to ISIS. &quot;The terrorist threat is more decentralized, more diffuse, more complicated,&quot; Homeland Security Secretary Jeh Johnson told reporters Thursday. &quot;It involves the potential lone wolf actor, it involves the effective use of social media, the Internet.&quot;

output:
</code></pre>
<ol start="8">
<li>构造模型输入：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">messages = [<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>&#125;,<br>            &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: prompt[:<span class="hljs-number">12000</span>]&#125; <span class="hljs-comment"># 截取前 12000 个字符</span><br>        ]<br>messages<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[&#123;&#39;role&#39;: &#39;system&#39;, &#39;content&#39;: &#39;You are a helpful assistant.&#39;&#125;,
&#123;&#39;role&#39;: &#39;user&#39;,
&#39;content&#39;: &#39;Summarize the following news within 86 words:\nThe FBI charged a Philadelphia woman on Thursday with trying to travel overseas to fight for ISIS. She\&#39;s one of three women arrested this week on terror charges. Two New York women were also taken into custody. An FBI complaint cites numerous social media messages dating back to August 2013 that were sent by Keonna Thomas, 30, also known as &quot;Young Lioness&quot; and &quot;Fatayat Al Khilafah.&quot; One Twitter message said, &quot;If we truly knew the realities ... we all would be rushing to join our brothers in the front lines pray ALLAH accept us as shuhada [martyrs].&quot; Another said, &quot;When you\&#39;re a mujahid [violent jihadi fighter] your death becomes a wedding.&quot; The FBI said Thomas purchased an electronic visa to Turkey on March 23. Turkey is known as the easiest place from which to enter Syria and join ISIS. An ISIS manual advises recruits to buy round-trip tickets to vacation spots such as Spain and then purchase tickets for their real destination once they arrive overseas, the FBI said. On March 26, Thomas purchased a ticket to Barcelona, with a March 29 departure and an April 15 return to the United States, the complaint said. It\&#39;s not clear when or where she was arrested. She was charged with knowingly attempting to provide material support and resources to a designated foreign terrorist organization. She could be sentenced to 15 years in prison. On Thursday, Noelle Velentzas, 28, and her former roommate, Asia Siddiqui, 31, were arrested in New York and accused of planning to build an explosive device for attacks in the United States, federal prosecutors said. In the past 18 months, the Justice Department\&#39;s National Security Division has prosecuted or is prosecuting more than 30 cases of people attempting to travel abroad to join or provide support to terrorist groups. Of those cases, 18 allegedly involve support to ISIS. &quot;The terrorist threat is more decentralized, more diffuse, more complicated,&quot; Homeland Security Secretary Jeh Johnson told reporters Thursday. &quot;It involves the potential lone wolf actor, it involves the effective use of social media, the Internet.&quot;\n\noutput:&#39;&#125;]
</code></pre>
<ol start="9">
<li>将 messages 转换为结构化文本字符串：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">text = tokenizer.apply_chat_template(messages, tokenize=<span class="hljs-literal">False</span>, add_generation_prompt=<span class="hljs-literal">True</span>) <span class="hljs-comment"># 不进行分词，同时添加一个生成提示的标记</span><br><span class="hljs-built_in">print</span>(text)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;
You are a helpful assistant.
&lt;&lt;/SYS&gt;&gt;

Summarize the following news within 86 words:
The FBI charged a Philadelphia woman on Thursday with trying to travel overseas to fight for ISIS. She&#39;s one of three women arrested this week on terror charges. Two New York women were also taken into custody. An FBI complaint cites numerous social media messages dating back to August 2013 that were sent by Keonna Thomas, 30, also known as &quot;Young Lioness&quot; and &quot;Fatayat Al Khilafah.&quot; One Twitter message said, &quot;If we truly knew the realities ... we all would be rushing to join our brothers in the front lines pray ALLAH accept us as shuhada [martyrs].&quot; Another said, &quot;When you&#39;re a mujahid [violent jihadi fighter] your death becomes a wedding.&quot; The FBI said Thomas purchased an electronic visa to Turkey on March 23. Turkey is known as the easiest place from which to enter Syria and join ISIS. An ISIS manual advises recruits to buy round-trip tickets to vacation spots such as Spain and then purchase tickets for their real destination once they arrive overseas, the FBI said. On March 26, Thomas purchased a ticket to Barcelona, with a March 29 departure and an April 15 return to the United States, the complaint said. It&#39;s not clear when or where she was arrested. She was charged with knowingly attempting to provide material support and resources to a designated foreign terrorist organization. She could be sentenced to 15 years in prison. On Thursday, Noelle Velentzas, 28, and her former roommate, Asia Siddiqui, 31, were arrested in New York and accused of planning to build an explosive device for attacks in the United States, federal prosecutors said. In the past 18 months, the Justice Department&#39;s National Security Division has prosecuted or is prosecuting more than 30 cases of people attempting to travel abroad to join or provide support to terrorist groups. Of those cases, 18 allegedly involve support to ISIS. &quot;The terrorist threat is more decentralized, more diffuse, more complicated,&quot; Homeland Security Secretary Jeh Johnson told reporters Thursday. &quot;It involves the potential lone wolf actor, it involves the effective use of social media, the Internet.&quot;

output: [/INST]
</code></pre>
<ol start="10">
<li>构建模型完整的输入输出：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">input_text = text + response_rag<br><span class="hljs-built_in">print</span>(input_text)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;
You are a helpful assistant.
&lt;&lt;/SYS&gt;&gt;

Summarize the following news within 86 words:
The FBI charged a Philadelphia woman on Thursday with trying to travel overseas to fight for ISIS. She&#39;s one of three women arrested this week on terror charges. Two New York women were also taken into custody. An FBI complaint cites numerous social media messages dating back to August 2013 that were sent by Keonna Thomas, 30, also known as &quot;Young Lioness&quot; and &quot;Fatayat Al Khilafah.&quot; One Twitter message said, &quot;If we truly knew the realities ... we all would be rushing to join our brothers in the front lines pray ALLAH accept us as shuhada [martyrs].&quot; Another said, &quot;When you&#39;re a mujahid [violent jihadi fighter] your death becomes a wedding.&quot; The FBI said Thomas purchased an electronic visa to Turkey on March 23. Turkey is known as the easiest place from which to enter Syria and join ISIS. An ISIS manual advises recruits to buy round-trip tickets to vacation spots such as Spain and then purchase tickets for their real destination once they arrive overseas, the FBI said. On March 26, Thomas purchased a ticket to Barcelona, with a March 29 departure and an April 15 return to the United States, the complaint said. It&#39;s not clear when or where she was arrested. She was charged with knowingly attempting to provide material support and resources to a designated foreign terrorist organization. She could be sentenced to 15 years in prison. On Thursday, Noelle Velentzas, 28, and her former roommate, Asia Siddiqui, 31, were arrested in New York and accused of planning to build an explosive device for attacks in the United States, federal prosecutors said. In the past 18 months, the Justice Department&#39;s National Security Division has prosecuted or is prosecuting more than 30 cases of people attempting to travel abroad to join or provide support to terrorist groups. Of those cases, 18 allegedly involve support to ISIS. &quot;The terrorist threat is more decentralized, more diffuse, more complicated,&quot; Homeland Security Secretary Jeh Johnson told reporters Thursday. &quot;It involves the potential lone wolf actor, it involves the effective use of social media, the Internet.&quot;

output: [/INST]FBI charges Philadelphia woman with attempting to join ISIS after purchasing electronic visa for Turkey. Keonna Thomas, 30, also known as &quot;Young Lioness&quot; and &quot;Fatayat Al Khilafah,&quot; made numerous social media posts expressing desire to fight for ISIS. She could face 15 years in prison. Three women have been arrested this week on terror charges, including two in New York who were accused of planning to build an explosive device for attacks in the US.
</code></pre>
<ol start="11">
<li>将文本字符串转换为 token ID 序列，text 为模型输入的文本（系统提示+问题），response_rag 为模型的回应：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">input_ids = tokenizer([input_text], return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids <span class="hljs-comment"># input_ids = prefix_ids + continue_ids</span><br>prefix_ids = tokenizer([text], return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids<br>continue_ids = input_ids[<span class="hljs-number">0</span>, prefix_ids.shape[-<span class="hljs-number">1</span>]:]<br><br><span class="hljs-built_in">print</span>(input_ids.shape)<br><span class="hljs-built_in">print</span>(prefix_ids.shape)<br><span class="hljs-built_in">print</span>(continue_ids.shape)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">torch.Size([1, 670])
torch.Size([1, 564])
torch.Size([106])
</code></pre>
<ol start="12">
<li>定位幻觉文本片段，其实就是重新模拟了一下模型的推理过程，因此需要对幻觉文本片段进行重新定位：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_hallucination_spans</span>(<span class="hljs-params">response, text, response_rag, tokenizer, prefix_len</span>):<br>    hallucination_span = []<br><br>    <span class="hljs-comment"># 遍历每个幻觉文本片段</span><br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> response:<br>        <span class="hljs-comment"># 幻觉文本片段的起始和结束位置</span><br>        start_id = item[<span class="hljs-string">&#x27;start&#x27;</span>]<br>        end_id = item[<span class="hljs-string">&#x27;end&#x27;</span>]<br><br>        start_text = text + response_rag[:start_id] <span class="hljs-comment"># 幻觉文本片段之前的文本</span><br>        end_text = text + response_rag[:end_id] <span class="hljs-comment"># 幻觉文本片段之前的文本+幻觉文本片段</span><br><br>        <span class="hljs-comment"># 文本字符串转换为 token ID 序列</span><br>        start_text_id = tokenizer(start_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids<br>        end_text_id = tokenizer(end_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids<br><br>        <span class="hljs-comment"># token ID 序列长度</span><br>        start_id = start_text_id.shape[-<span class="hljs-number">1</span>]<br>        end_id = end_text_id.shape[-<span class="hljs-number">1</span>]<br><br>        <span class="hljs-comment"># 通过长度，就可以返回幻觉文本片段的起止位置</span><br>        hallucination_span.append([start_id, end_id])<br><br>    <span class="hljs-keyword">return</span> hallucination_span<br><br><span class="hljs-comment"># 定位幻觉片段：hallucination_spans 保存 response 中所有的幻觉文本片段在 input_ids 的起止位置</span><br><span class="hljs-keyword">if</span> <span class="hljs-string">&quot;labels&quot;</span> <span class="hljs-keyword">in</span> response[i].keys(): <span class="hljs-comment"># prefix_ids.shape[-1] 是模型输入的长度</span><br>    hallucination_spans = calculate_hallucination_spans(response[i][<span class="hljs-string">&#x27;labels&#x27;</span>], text, response_rag, tokenizer, prefix_ids.shape[-<span class="hljs-number">1</span>])<br><span class="hljs-keyword">else</span>:<br>    hallucination_spans = []<br></code></pre></td></tr></table></figure>

<ol start="13">
<li>执行模型推理：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">start_p, end_p = <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span><br>start, number = <span class="hljs-number">0</span>, <span class="hljs-number">32</span><br><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    logits_dict, outputs = model(<br>        input_ids=input_ids.to(device),<br>        return_dict=<span class="hljs-literal">True</span>,<br>        output_attentions=<span class="hljs-literal">True</span>, <span class="hljs-comment"># 返回每一层的注意力得分</span><br>        output_hidden_states=<span class="hljs-literal">True</span>, <span class="hljs-comment"># 返回每一层的隐藏状态</span><br>        knowledge_layers=<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(start, number)) <span class="hljs-comment"># 返回指定层的 MLP 的输出状态</span><br>    )<br>    <br><span class="hljs-built_in">print</span>(outputs.keys()) <span class="hljs-comment"># past_key_values 是用于加速自回归生成的缓存键值对</span><br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">odict_keys([&#39;logits&#39;, &#39;past_key_values&#39;, &#39;hidden_states&#39;, &#39;attentions&#39;])
</code></pre>
<ol start="14">
<li>对于 MLP 层：value[0] 是 MLP 层的输出，value[1] 是 MLP 层的残差连接：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">logits_dict = &#123;key: [value[<span class="hljs-number">0</span>].to(device), value[<span class="hljs-number">1</span>].to(device)] <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> logits_dict.items()&#125; <span class="hljs-comment"># 张量移到 GPU 上计算</span><br><br><span class="hljs-built_in">print</span>(logits_dict.keys())<br><span class="hljs-built_in">print</span>(logits_dict[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].shape, logits_dict[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>].shape)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
torch.Size([1, 670, 32000]) torch.Size([1, 670, 32000])
</code></pre>
<ol start="15">
<li>outputs 是模型的输出，包含了 logits、hidden_states 和 attentions：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">hidden_states = outputs[<span class="hljs-string">&quot;hidden_states&quot;</span>]  <span class="hljs-comment"># 所有层的隐藏状态</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(hidden_states))<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(hidden_states)) <span class="hljs-comment"># embedding 层 + 32 个 layer 层</span><br><span class="hljs-built_in">print</span>(hidden_states[<span class="hljs-number">0</span>].shape) <span class="hljs-comment"># 每层形状</span><br><br>last_hidden_states = hidden_states[-<span class="hljs-number">1</span>][<span class="hljs-number">0</span>, :, :]  <span class="hljs-comment"># 最后一层的隐藏状态，用于计算 ECS</span><br><span class="hljs-built_in">print</span>(last_hidden_states.shape)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&lt;class &#39;tuple&#39;&gt;
33
torch.Size([1, 670, 4096])
torch.Size([670, 4096])
</code></pre>
<ol start="16">
<li>定义幻觉检测变量：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">external_similarity = []  <span class="hljs-comment"># ECS</span><br>parameter_knowledge_difference = [] <span class="hljs-comment"># PKS</span><br>hallucination_label = [] <span class="hljs-comment"># 幻觉标签</span><br></code></pre></td></tr></table></figure>

<ol start="17">
<li>保存 copy heads 的注意力得分：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">attentions_list = []<br><span class="hljs-keyword">for</span> attentions_layer_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(outputs.attentions)): <span class="hljs-comment"># 每一层 layer</span><br>    <span class="hljs-keyword">for</span> head_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(outputs.attentions[attentions_layer_id].shape[<span class="hljs-number">1</span>]): <span class="hljs-comment"># 每一层的每一个 head</span><br>        <span class="hljs-keyword">if</span> [attentions_layer_id, head_id] <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> copy_heads: <span class="hljs-comment"># 只选择 copy heads 中的 head</span><br>            <span class="hljs-keyword">continue</span><br>        attentions_list.append(&#123;<span class="hljs-string">&quot;layer_head&quot;</span>: (attentions_layer_id, head_id), <span class="hljs-comment"># 记录 layer 和 head 的 ID</span><br>                                <span class="hljs-string">&quot;attention_score&quot;</span>: outputs.attentions[attentions_layer_id][:, head_id, :, :]&#125;) <span class="hljs-comment"># 记录对应的注意力得分</span><br><br><span class="hljs-built_in">print</span>(outputs.attentions[attentions_layer_id].shape)<br><span class="hljs-built_in">print</span>(outputs.attentions[attentions_layer_id][:, head_id, :, :].shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(attentions_list))<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">torch.Size([1, 32, 670, 670])
torch.Size([1, 670, 670])
32
</code></pre>
<ol start="18">
<li>JS 散度计算和判断幻觉 token 的函数：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 计算 JS散度：两个概率分布之间的相似度</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_dist</span>(<span class="hljs-params">sep_vocabulary_dist, sep_attention_dist</span>):<br>    <span class="hljs-comment"># 将输入分布转换为概率分布</span><br>    softmax_mature_layer = F.softmax(sep_vocabulary_dist, dim=-<span class="hljs-number">1</span>)<br>    softmax_anchor_layer = F.softmax(sep_attention_dist, dim=-<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 计算两个概率分布的平均分布</span><br>    M = <span class="hljs-number">0.5</span> * (softmax_mature_layer + softmax_anchor_layer)<br><br>    <span class="hljs-comment"># 计算两个概率分布的对数形式</span><br>    log_softmax_mature_layer = F.log_softmax(sep_vocabulary_dist, dim=-<span class="hljs-number">1</span>)<br>    log_softmax_anchor_layer = F.log_softmax(sep_attention_dist, dim=-<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 计算两个分布对于平均分布的 KL 散度</span><br>    kl1 = F.kl_div(log_softmax_mature_layer, M, reduction=<span class="hljs-string">&#x27;none&#x27;</span>).mean(-<span class="hljs-number">1</span>)<br>    kl2 = F.kl_div(log_softmax_anchor_layer, M, reduction=<span class="hljs-string">&#x27;none&#x27;</span>).mean(-<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 计算 JS 散度</span><br>    js_divs = <span class="hljs-number">0.5</span> * (kl1 + kl2)<br><br>    <span class="hljs-keyword">return</span> js_divs.cpu().item() * <span class="hljs-number">10e5</span>  <span class="hljs-comment"># 乘以 10e5 是为了放大数值，便于观察</span><br><br><span class="hljs-comment"># 判断给定的 token 是否属于预定义的幻觉文本片段</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">is_hallucination_token</span>(<span class="hljs-params">token_id, hallucination_spans</span>):<br>    <span class="hljs-keyword">for</span> span <span class="hljs-keyword">in</span> hallucination_spans:<br>        <span class="hljs-keyword">if</span> token_id &gt;= span[<span class="hljs-number">0</span>] <span class="hljs-keyword">and</span> token_id &lt;= span[<span class="hljs-number">1</span>]:<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure>

<ol start="19">
<li>计算 ECS 和 PKS，标记幻觉标签：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 遍历 response 的每一个 token id</span><br><span class="hljs-keyword">for</span> seq_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(prefix_ids.shape[-<span class="hljs-number">1</span>] - <span class="hljs-number">1</span>, input_ids.shape[-<span class="hljs-number">1</span>] - <span class="hljs-number">1</span>):<br>    pointer_scores_list = [attention_dict[<span class="hljs-string">&quot;attention_score&quot;</span>][:, seq_i, :] <span class="hljs-keyword">for</span> attention_dict <span class="hljs-keyword">in</span> attentions_list] <span class="hljs-comment"># 每个 copy_head 中该 token id 对应的那一行的注意力得分</span><br><br>    <span class="hljs-keyword">if</span> start_p != <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> end_p != <span class="hljs-literal">None</span>: <br>        pointer_probs_list = torch.cat([pointer_scores[:, start_p:end_p] <span class="hljs-keyword">for</span> pointer_scores <span class="hljs-keyword">in</span> pointer_scores_list], dim=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">else</span>: <span class="hljs-comment"># 截取模型输入的那部分注意力得分</span><br>        pointer_probs_list = torch.cat([pointer_scores[:, :prefix_ids.shape[-<span class="hljs-number">1</span>]] <span class="hljs-keyword">for</span> pointer_scores <span class="hljs-keyword">in</span> pointer_scores_list], dim=<span class="hljs-number">0</span>)<br><br>    top_k = <span class="hljs-built_in">int</span>(pointer_probs_list.shape[-<span class="hljs-number">1</span>] * <span class="hljs-number">0.1</span>)  <span class="hljs-comment"># 得到 top_k 的长度，即要关注多少个得分最高的 token ID</span><br>    sorted_indices = torch.argsort(pointer_probs_list, dim=<span class="hljs-number">1</span>, descending=<span class="hljs-literal">True</span>) <span class="hljs-comment"># 获取排序后的索引，按照概率从大到小排序</span><br>    top_k_indices = sorted_indices[:, :top_k] <span class="hljs-comment"># 选择前 top_k 个索引</span><br>    flattened_indices = top_k_indices.flatten() <span class="hljs-comment"># 将 top_k_indices 展平</span><br>    <br>    selected_hidden_states = last_hidden_states[flattened_indices] <span class="hljs-comment"># 在 last_hidden_states 中查找相应的 hidden_state</span><br>    top_k_hidden_states = selected_hidden_states.view(top_k_indices.shape[<span class="hljs-number">0</span>], top_k_indices.shape[<span class="hljs-number">1</span>], -<span class="hljs-number">1</span>) <span class="hljs-comment"># 重新改变形状</span><br>    attend_token_hidden_state = torch.mean(top_k_hidden_states, dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># 计算隐藏状态均值</span><br><br>    current_hidden_state = last_hidden_states[seq_i, :] <span class="hljs-comment"># 获取当前 token ID 的最后一层隐藏状态</span><br>    current_hidden_state = current_hidden_state.unsqueeze(<span class="hljs-number">0</span>).expand(attend_token_hidden_state.shape) <span class="hljs-comment"># 扩展为与 attend_token_hidden_state 一致的维度，即一直复制 current_hidden_state</span><br><br>    cosine_similarity = F.cosine_similarity(attend_token_hidden_state.to(device), current_hidden_state.to(device), dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># 计算余弦相似度</span><br><br>    <span class="hljs-keyword">if</span> is_hallucination_token(seq_i, hallucination_spans): <span class="hljs-comment"># 确认当前 token ID 是否属于幻觉文本片段</span><br>        hallucination_label.append(<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">else</span>:<br>        hallucination_label.append(<span class="hljs-number">0</span>)<br><br>    external_similarity.append(cosine_similarity.cpu().tolist())<br>    parameter_knowledge_difference.append([calculate_dist(value[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>, seq_i, :], value[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>, seq_i, :]) <span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> logits_dict.values()])<br>    torch.cuda.empty_cache()<br>    <br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(pointer_scores_list), pointer_scores_list[<span class="hljs-number">0</span>].shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(pointer_probs_list), pointer_probs_list[<span class="hljs-number">0</span>].shape)<br><span class="hljs-built_in">print</span>(top_k)<br><span class="hljs-built_in">print</span>(sorted_indices.shape)<br><span class="hljs-built_in">print</span>(top_k_indices.shape)<br><span class="hljs-built_in">print</span>(flattened_indices.shape)<br><span class="hljs-built_in">print</span>(selected_hidden_states.shape)<br><span class="hljs-built_in">print</span>(top_k_hidden_states.shape)<br><span class="hljs-built_in">print</span>(attend_token_hidden_state.shape)<br><span class="hljs-built_in">print</span>(current_hidden_state.shape)<br><span class="hljs-built_in">print</span>(current_hidden_state[<span class="hljs-number">0</span>]==current_hidden_state[-<span class="hljs-number">1</span>])<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">32 torch.Size([1, 670])
32 torch.Size([564])
56
torch.Size([32, 564])
torch.Size([32, 56])
torch.Size([1792])
torch.Size([1792, 4096])
torch.Size([32, 56, 4096])
torch.Size([32, 4096])
torch.Size([32, 4096])
tensor([True, True, True,  ..., True, True, True], device=&#39;cuda:0&#39;)
</code></pre>
<ol start="20">
<li>查看结果：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">response[i][<span class="hljs-string">&quot;external_similarity&quot;</span>] = external_similarity<br>response[i][<span class="hljs-string">&quot;parameter_knowledge_difference&quot;</span>] = parameter_knowledge_difference<br>response[i][<span class="hljs-string">&quot;hallucination_label&quot;</span>] = hallucination_label<br><br>select_response.append(response[i])<br><span class="hljs-built_in">print</span>(select_response[i].keys())<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(select_response[i][<span class="hljs-string">&quot;external_similarity&quot;</span>]), <span class="hljs-built_in">len</span>(select_response[i][<span class="hljs-string">&quot;external_similarity&quot;</span>][<span class="hljs-number">0</span>]))<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(select_response[i][<span class="hljs-string">&quot;parameter_knowledge_difference&quot;</span>]), <span class="hljs-built_in">len</span>(select_response[i][<span class="hljs-string">&quot;parameter_knowledge_difference&quot;</span>][<span class="hljs-number">0</span>]))<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(select_response[i][<span class="hljs-string">&quot;hallucination_label&quot;</span>]))<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">dict_keys([&#39;id&#39;, &#39;source_id&#39;, &#39;model&#39;, &#39;temperature&#39;, &#39;labels&#39;, &#39;split&#39;, &#39;quality&#39;, &#39;response&#39;, &#39;external_similarity&#39;, &#39;parameter_knowledge_difference&#39;, &#39;hallucination_label&#39;])
106 32
106 32
106
</code></pre>
<ol start="21">
<li>保存结果：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../output/llama2_7B_response_token.json&quot;</span>, <span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    json.dump(select_response, f, ensure_ascii=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>

<h3 id="2-2-2-chunk-级别"><a href="#2-2-2-chunk-级别" class="headerlink" title="2.2.2 chunk 级别"></a>2.2.2 chunk 级别</h3><ol>
<li>导入必要的包：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br>sys.path.insert(<span class="hljs-number">0</span>, <span class="hljs-string">&#x27;../transformers/src&#x27;</span>)<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer <br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer<br></code></pre></td></tr></table></figure>

<ol start="2">
<li>加载 embedding 模型：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">bge_model = SentenceTransformer(<span class="hljs-string">&#x27;../../model/bge-base-en-v1.5/&#x27;</span>).to(<span class="hljs-string">&quot;cuda:0&quot;</span>)<br></code></pre></td></tr></table></figure>

<ol start="3">
<li>加载 response：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">response = []<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../dataset/response_spans.jsonl&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>        data = json.loads(line)<br>        response.append(data)<br>    <br><span class="hljs-built_in">print</span>(json.dumps(response, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[
    &#123;
        &quot;id&quot;: &quot;45&quot;,
        &quot;source_id&quot;: &quot;15599&quot;,
        &quot;model&quot;: &quot;llama-2-7b-chat&quot;,
        &quot;temperature&quot;: 0.7,
        &quot;labels&quot;: [],
        &quot;split&quot;: &quot;test&quot;,
        &quot;quality&quot;: &quot;good&quot;,
        &quot;response&quot;: &quot;Blue Bell ice cream has temporarily shut down one of its manufacturing plants after discovering listeria contamination in a serving of ice cream produced at the plant. The Centers for Disease Control and Prevention (CDC) has warned consumers not to eat any Blue Bell-branded products made at the Broken Arrow, Oklahoma plant, including 3-ounce servings of ice cream marked with certain codes. This is the third time Blue Bell has taken action due to a listeria outbreak at a Kansas hospital that served the company&#39;s ice cream. Investigations into the possible connection between the ice cream and the infections are ongoing. The company has recalled other products and advises individuals and institutions to check their freezers for the recalled items and throw them away. This is the first product recall in Blue Bell&#39;s 108-year history.&quot;,
        &quot;response_spans&quot;: [
            [
                0,
                506
            ],
            [
                491,
                840
            ]
        ]
    &#125;
]
</code></pre>
<ol start="4">
<li>加载 source_info：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">source_info_dict = &#123;&#125;<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../dataset/source_info_spans.jsonl&quot;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>        data = json.loads(line)<br>        source_info_dict[data[<span class="hljs-string">&#x27;source_id&#x27;</span>]] = data<br>        <br><span class="hljs-built_in">print</span>(json.dumps(source_info_dict, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&#123;
    &quot;15599&quot;: &#123;
        &quot;source_id&quot;: &quot;15599&quot;,
        &quot;task_type&quot;: &quot;Summary&quot;,
        &quot;source&quot;: &quot;CNN/DM&quot;,
        &quot;source_info&quot;: &quot;Blue Bell ice cream has temporarily shut down one of its manufacturing plants over the discovery of listeria contamination in a serving of ice cream originating from that plant. Public health officials warned consumers Friday not to eat any Blue Bell-branded products made at the company&#39;s Broken Arrow, Oklahoma, plant. That includes 3-ounce servings of Blue Bell ice cream from this plant that went to institutions in containers marked with the letters O, P, Q, R, S or T behind the coding date. The warning by the Centers for Disease Control and Prevention does not affect other Blue Bell ice cream, including other 3-ounce servings, not made at the plant. But Blue Bell has recalled other products. The company is shutting down the Broken Arrow facility \&quot;out of an abundance of caution\&quot; to search for a possible cause of contamination. It is the third time Blue Bell has taken action in light of a listeria outbreak at a Kansas hospital that served the company&#39;s ice cream. Listeria monocytogenes was recently found in a cup of ice cream recovered from the hospital. The cup contaminated with the bacteria was produced at the Broken Arrow plant in April 2014, Blue Bell said. And, according to the CDC, listeria bacteria was found in additional samples of the same product that were recovered from the plant. The bacteria in the hospital sample and the factory sample appeared to match each other genetically, the CDC said. But they did not appear identical to listeria samples taken from patients infected in the Kansas outbreak. In a separate outbreak in Texas, the CDC did find that listeria samples taken from patients who came down with listeriosis between 2010 and 2014 in a hospital that served 3-ounce Blue Bell cups matched the listeria in recovered samples. None of this means the ice cream is the source of either spate of the infections. \&quot;Investigation to determine whether these illnesses are related to exposure to Blue Bell products is ongoing,\&quot; the CDC said. In early March, in light of the Kansas listeria outbreak, Blue Bell recalled a group of products made at a plant in Texas. It later added 3-ounce cup servings to the recall. Five people were infected and three died in the past year in Kansas from listeria that might be linked to Blue Bell Creameries products, according to the CDC. All five of them were hospitalized at the same hospital before developing listeriosis, the CDC said. At least four of them had consumed milkshakes made with Blue Bell ice cream before developing the infection. \&quot;We are devastated and know that Blue Bell has to be and can be better than this,\&quot; Paul Kruse, Blue Bell CEO and president, said in a statement. \&quot;Quality and safety have always been our top priorities. We are deeply saddened and concerned for all those who have been affected.\&quot; The CDC advises that individuals and institutions should check their freezers for the recalled products and throw them away. In a statement on its website, Blue Bell said \&quot;this recall in no way includes Blue Bell ice cream half gallons, pints, quarts, 3 gallons or other 3 oz. cups.\&quot; This has been the first product recall in the 108-year history of Blue Bell Creameries, the company said. Listeriosis is a serious infection caused by eating food contaminated with listeria, and primarily affects the elderly, pregnant women, newborns and people with weakened immune systems, according to the CDC. Symptoms of a listeria infection are fever and muscle aches, sometimes associated with diarrhea or other gastrointestinal symptoms. In the United States, an estimated 1,600 people become seriously ill each year, and approximately 16% of these illnesses result in death. Cervical infections caused by listeriosis in pregnant women may result in stillbirth or spontaneous abortion during the second or third trimesters. CNN&#39;s Debra Goldschmidt, Amanda Watts and Jacque Wilson contributed to this report.\n&quot;,
        &quot;prompt&quot;: &quot;Summarize the following news within 161 words:\nBlue Bell ice cream has temporarily shut down one of its manufacturing plants over the discovery of listeria contamination in a serving of ice cream originating from that plant. Public health officials warned consumers Friday not to eat any Blue Bell-branded products made at the company&#39;s Broken Arrow, Oklahoma, plant. That includes 3-ounce servings of Blue Bell ice cream from this plant that went to institutions in containers marked with the letters O, P, Q, R, S or T behind the coding date. The warning by the Centers for Disease Control and Prevention does not affect other Blue Bell ice cream, including other 3-ounce servings, not made at the plant. But Blue Bell has recalled other products. The company is shutting down the Broken Arrow facility \&quot;out of an abundance of caution\&quot; to search for a possible cause of contamination. It is the third time Blue Bell has taken action in light of a listeria outbreak at a Kansas hospital that served the company&#39;s ice cream. Listeria monocytogenes was recently found in a cup of ice cream recovered from the hospital. The cup contaminated with the bacteria was produced at the Broken Arrow plant in April 2014, Blue Bell said. And, according to the CDC, listeria bacteria was found in additional samples of the same product that were recovered from the plant. The bacteria in the hospital sample and the factory sample appeared to match each other genetically, the CDC said. But they did not appear identical to listeria samples taken from patients infected in the Kansas outbreak. In a separate outbreak in Texas, the CDC did find that listeria samples taken from patients who came down with listeriosis between 2010 and 2014 in a hospital that served 3-ounce Blue Bell cups matched the listeria in recovered samples. None of this means the ice cream is the source of either spate of the infections. \&quot;Investigation to determine whether these illnesses are related to exposure to Blue Bell products is ongoing,\&quot; the CDC said. In early March, in light of the Kansas listeria outbreak, Blue Bell recalled a group of products made at a plant in Texas. It later added 3-ounce cup servings to the recall. Five people were infected and three died in the past year in Kansas from listeria that might be linked to Blue Bell Creameries products, according to the CDC. All five of them were hospitalized at the same hospital before developing listeriosis, the CDC said. At least four of them had consumed milkshakes made with Blue Bell ice cream before developing the infection. \&quot;We are devastated and know that Blue Bell has to be and can be better than this,\&quot; Paul Kruse, Blue Bell CEO and president, said in a statement. \&quot;Quality and safety have always been our top priorities. We are deeply saddened and concerned for all those who have been affected.\&quot; The CDC advises that individuals and institutions should check their freezers for the recalled products and throw them away. In a statement on its website, Blue Bell said \&quot;this recall in no way includes Blue Bell ice cream half gallons, pints, quarts, 3 gallons or other 3 oz. cups.\&quot; This has been the first product recall in the 108-year history of Blue Bell Creameries, the company said. Listeriosis is a serious infection caused by eating food contaminated with listeria, and primarily affects the elderly, pregnant women, newborns and people with weakened immune systems, according to the CDC. Symptoms of a listeria infection are fever and muscle aches, sometimes associated with diarrhea or other gastrointestinal symptoms. In the United States, an estimated 1,600 people become seriously ill each year, and approximately 16% of these illnesses result in death. Cervical infections caused by listeriosis in pregnant women may result in stillbirth or spontaneous abortion during the second or third trimesters. CNN&#39;s Debra Goldschmidt, Amanda Watts and Jacque Wilson contributed to this report.\n\noutput:&quot;,
        &quot;prompt_spans&quot;: [
            [
                0,
                46
            ],
            [
                47,
                556
            ],
            [
                539,
                1047
            ],
            [
                1034,
                1539
            ],
            [
                1521,
                2028
            ],
            [
                2012,
                2520
            ],
            [
                2506,
                3017
            ],
            [
                3003,
                3505
            ],
            [
                3488,
                3946
            ],
            [
                3948,
                3955
            ]
        ]
    &#125;
&#125;
</code></pre>
<ol start="5">
<li>加载模型和分词器：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">model_name = <span class="hljs-string">&quot;../../model/Llama-2-7b-chat-hf&quot;</span><br>model = AutoModelForCausalLM.from_pretrained(model_name, device_map=<span class="hljs-string">&quot;auto&quot;</span>, torch_dtype=torch.float16)<br>tokenizer = AutoTokenizer.from_pretrained(model_name)<br>device = <span class="hljs-string">&quot;cuda&quot;</span><br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">Loading checkpoint shards: 100%|██████████| 2/2 [00:21&lt;00:00, 10.71s/it]
</code></pre>
<ol start="6">
<li>加载 copy_heads：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../dataset/topk_heads.json&quot;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    copy_heads = json.load(f)[:<span class="hljs-number">32</span>]<br>    <br><span class="hljs-built_in">print</span>(copy_heads)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(copy_heads))<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[[25, 0], [18, 13], [18, 10], [27, 9], [5, 29], [23, 8], [31, 28], [3, 0], [31, 24], [13, 20], [31, 18], [1, 14], [2, 5], [22, 10], [2, 22], [15, 7], [3, 19], [20, 17], [10, 20], [23, 30], [20, 22], [1, 27], [20, 1], [31, 19], [28, 18], [20, 15], [1, 21], [19, 1], [20, 5], [16, 1], [18, 9], [5, 13]]
32
</code></pre>
<ol start="7">
<li>选择数据类型，对应 JSONL 的 model 字段：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">data_type = <span class="hljs-string">&quot;llama-2-7b-chat&quot;</span><br><br>select_response = []<br>i = <span class="hljs-number">0</span><br>response[i][<span class="hljs-string">&#x27;model&#x27;</span>] == data_type <span class="hljs-keyword">and</span> response[i][<span class="hljs-string">&quot;split&quot;</span>] == <span class="hljs-string">&quot;test&quot;</span><br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">True
</code></pre>
<ol start="8">
<li>字段提取：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">response_rag = response[i][<span class="hljs-string">&#x27;response&#x27;</span>]<br>source_id = response[i][<span class="hljs-string">&#x27;source_id&#x27;</span>]<br>temperature = response[i][<span class="hljs-string">&#x27;temperature&#x27;</span>]<br>prompt =  source_info_dict[source_id][<span class="hljs-string">&#x27;prompt&#x27;</span>]<br>original_prompt_spans = source_info_dict[source_id][<span class="hljs-string">&#x27;prompt_spans&#x27;</span>] <span class="hljs-comment"># prompt 切分</span><br>original_response_spans = response[i][<span class="hljs-string">&#x27;response_spans&#x27;</span>] <span class="hljs-comment"># response 切分</span><br><br><span class="hljs-built_in">print</span>(response_rag)<br><span class="hljs-built_in">print</span>(source_id)<br><span class="hljs-built_in">print</span>(temperature)<br><span class="hljs-built_in">print</span>(prompt)<br><span class="hljs-built_in">print</span>(original_prompt_spans)<br><span class="hljs-built_in">print</span>(original_response_spans)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">Blue Bell ice cream has temporarily shut down one of its manufacturing plants after discovering listeria contamination in a serving of ice cream produced at the plant. The Centers for Disease Control and Prevention (CDC) has warned consumers not to eat any Blue Bell-branded products made at the Broken Arrow, Oklahoma plant, including 3-ounce servings of ice cream marked with certain codes. This is the third time Blue Bell has taken action due to a listeria outbreak at a Kansas hospital that served the company&#39;s ice cream. Investigations into the possible connection between the ice cream and the infections are ongoing. The company has recalled other products and advises individuals and institutions to check their freezers for the recalled items and throw them away. This is the first product recall in Blue Bell&#39;s 108-year history.
15599
0.7
Summarize the following news within 161 words:
Blue Bell ice cream has temporarily shut down one of its manufacturing plants over the discovery of listeria contamination in a serving of ice cream originating from that plant. Public health officials warned consumers Friday not to eat any Blue Bell-branded products made at the company&#39;s Broken Arrow, Oklahoma, plant. That includes 3-ounce servings of Blue Bell ice cream from this plant that went to institutions in containers marked with the letters O, P, Q, R, S or T behind the coding date. The warning by the Centers for Disease Control and Prevention does not affect other Blue Bell ice cream, including other 3-ounce servings, not made at the plant. But Blue Bell has recalled other products. The company is shutting down the Broken Arrow facility &quot;out of an abundance of caution&quot; to search for a possible cause of contamination. It is the third time Blue Bell has taken action in light of a listeria outbreak at a Kansas hospital that served the company&#39;s ice cream. Listeria monocytogenes was recently found in a cup of ice cream recovered from the hospital. The cup contaminated with the bacteria was produced at the Broken Arrow plant in April 2014, Blue Bell said. And, according to the CDC, listeria bacteria was found in additional samples of the same product that were recovered from the plant. The bacteria in the hospital sample and the factory sample appeared to match each other genetically, the CDC said. But they did not appear identical to listeria samples taken from patients infected in the Kansas outbreak. In a separate outbreak in Texas, the CDC did find that listeria samples taken from patients who came down with listeriosis between 2010 and 2014 in a hospital that served 3-ounce Blue Bell cups matched the listeria in recovered samples. None of this means the ice cream is the source of either spate of the infections. &quot;Investigation to determine whether these illnesses are related to exposure to Blue Bell products is ongoing,&quot; the CDC said. In early March, in light of the Kansas listeria outbreak, Blue Bell recalled a group of products made at a plant in Texas. It later added 3-ounce cup servings to the recall. Five people were infected and three died in the past year in Kansas from listeria that might be linked to Blue Bell Creameries products, according to the CDC. All five of them were hospitalized at the same hospital before developing listeriosis, the CDC said. At least four of them had consumed milkshakes made with Blue Bell ice cream before developing the infection. &quot;We are devastated and know that Blue Bell has to be and can be better than this,&quot; Paul Kruse, Blue Bell CEO and president, said in a statement. &quot;Quality and safety have always been our top priorities. We are deeply saddened and concerned for all those who have been affected.&quot; The CDC advises that individuals and institutions should check their freezers for the recalled products and throw them away. In a statement on its website, Blue Bell said &quot;this recall in no way includes Blue Bell ice cream half gallons, pints, quarts, 3 gallons or other 3 oz. cups.&quot; This has been the first product recall in the 108-year history of Blue Bell Creameries, the company said. Listeriosis is a serious infection caused by eating food contaminated with listeria, and primarily affects the elderly, pregnant women, newborns and people with weakened immune systems, according to the CDC. Symptoms of a listeria infection are fever and muscle aches, sometimes associated with diarrhea or other gastrointestinal symptoms. In the United States, an estimated 1,600 people become seriously ill each year, and approximately 16% of these illnesses result in death. Cervical infections caused by listeriosis in pregnant women may result in stillbirth or spontaneous abortion during the second or third trimesters. CNN&#39;s Debra Goldschmidt, Amanda Watts and Jacque Wilson contributed to this report.

output:
[[0, 46], [47, 556], [539, 1047], [1034, 1539], [1521, 2028], [2012, 2520], [2506, 3017], [3003, 3505], [3488, 3946], [3948, 3955]]
[[0, 506], [491, 840]]
</code></pre>
<ol start="9">
<li>构造模型输入：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">add_special_template</span>(<span class="hljs-params">prompt</span>):<br>    messages = [<br>                &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>&#125;,<br>                &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: prompt&#125;<br>            ]<br>    text = tokenizer.apply_chat_template(messages, tokenize=<span class="hljs-literal">False</span>, add_generation_prompt=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> text<br><br>text = add_special_template(prompt[:<span class="hljs-number">12000</span>])<br><span class="hljs-built_in">print</span>(text)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;
You are a helpful assistant.
&lt;&lt;/SYS&gt;&gt;

Summarize the following news within 161 words:
Blue Bell ice cream has temporarily shut down one of its manufacturing plants over the discovery of listeria contamination in a serving of ice cream originating from that plant. Public health officials warned consumers Friday not to eat any Blue Bell-branded products made at the company&#39;s Broken Arrow, Oklahoma, plant. That includes 3-ounce servings of Blue Bell ice cream from this plant that went to institutions in containers marked with the letters O, P, Q, R, S or T behind the coding date. The warning by the Centers for Disease Control and Prevention does not affect other Blue Bell ice cream, including other 3-ounce servings, not made at the plant. But Blue Bell has recalled other products. The company is shutting down the Broken Arrow facility &quot;out of an abundance of caution&quot; to search for a possible cause of contamination. It is the third time Blue Bell has taken action in light of a listeria outbreak at a Kansas hospital that served the company&#39;s ice cream. Listeria monocytogenes was recently found in a cup of ice cream recovered from the hospital. The cup contaminated with the bacteria was produced at the Broken Arrow plant in April 2014, Blue Bell said. And, according to the CDC, listeria bacteria was found in additional samples of the same product that were recovered from the plant. The bacteria in the hospital sample and the factory sample appeared to match each other genetically, the CDC said. But they did not appear identical to listeria samples taken from patients infected in the Kansas outbreak. In a separate outbreak in Texas, the CDC did find that listeria samples taken from patients who came down with listeriosis between 2010 and 2014 in a hospital that served 3-ounce Blue Bell cups matched the listeria in recovered samples. None of this means the ice cream is the source of either spate of the infections. &quot;Investigation to determine whether these illnesses are related to exposure to Blue Bell products is ongoing,&quot; the CDC said. In early March, in light of the Kansas listeria outbreak, Blue Bell recalled a group of products made at a plant in Texas. It later added 3-ounce cup servings to the recall. Five people were infected and three died in the past year in Kansas from listeria that might be linked to Blue Bell Creameries products, according to the CDC. All five of them were hospitalized at the same hospital before developing listeriosis, the CDC said. At least four of them had consumed milkshakes made with Blue Bell ice cream before developing the infection. &quot;We are devastated and know that Blue Bell has to be and can be better than this,&quot; Paul Kruse, Blue Bell CEO and president, said in a statement. &quot;Quality and safety have always been our top priorities. We are deeply saddened and concerned for all those who have been affected.&quot; The CDC advises that individuals and institutions should check their freezers for the recalled products and throw them away. In a statement on its website, Blue Bell said &quot;this recall in no way includes Blue Bell ice cream half gallons, pints, quarts, 3 gallons or other 3 oz. cups.&quot; This has been the first product recall in the 108-year history of Blue Bell Creameries, the company said. Listeriosis is a serious infection caused by eating food contaminated with listeria, and primarily affects the elderly, pregnant women, newborns and people with weakened immune systems, according to the CDC. Symptoms of a listeria infection are fever and muscle aches, sometimes associated with diarrhea or other gastrointestinal symptoms. In the United States, an estimated 1,600 people become seriously ill each year, and approximately 16% of these illnesses result in death. Cervical infections caused by listeriosis in pregnant women may result in stillbirth or spontaneous abortion during the second or third trimesters. CNN&#39;s Debra Goldschmidt, Amanda Watts and Jacque Wilson contributed to this report.

output: [/INST]
</code></pre>
<ol start="10">
<li>构建模型完整的输入输出：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">input_text = text + response_rag<br><span class="hljs-built_in">print</span>(input_text)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;
You are a helpful assistant.
&lt;&lt;/SYS&gt;&gt;

Summarize the following news within 161 words:
Blue Bell ice cream has temporarily shut down one of its manufacturing plants over the discovery of listeria contamination in a serving of ice cream originating from that plant. Public health officials warned consumers Friday not to eat any Blue Bell-branded products made at the company&#39;s Broken Arrow, Oklahoma, plant. That includes 3-ounce servings of Blue Bell ice cream from this plant that went to institutions in containers marked with the letters O, P, Q, R, S or T behind the coding date. The warning by the Centers for Disease Control and Prevention does not affect other Blue Bell ice cream, including other 3-ounce servings, not made at the plant. But Blue Bell has recalled other products. The company is shutting down the Broken Arrow facility &quot;out of an abundance of caution&quot; to search for a possible cause of contamination. It is the third time Blue Bell has taken action in light of a listeria outbreak at a Kansas hospital that served the company&#39;s ice cream. Listeria monocytogenes was recently found in a cup of ice cream recovered from the hospital. The cup contaminated with the bacteria was produced at the Broken Arrow plant in April 2014, Blue Bell said. And, according to the CDC, listeria bacteria was found in additional samples of the same product that were recovered from the plant. The bacteria in the hospital sample and the factory sample appeared to match each other genetically, the CDC said. But they did not appear identical to listeria samples taken from patients infected in the Kansas outbreak. In a separate outbreak in Texas, the CDC did find that listeria samples taken from patients who came down with listeriosis between 2010 and 2014 in a hospital that served 3-ounce Blue Bell cups matched the listeria in recovered samples. None of this means the ice cream is the source of either spate of the infections. &quot;Investigation to determine whether these illnesses are related to exposure to Blue Bell products is ongoing,&quot; the CDC said. In early March, in light of the Kansas listeria outbreak, Blue Bell recalled a group of products made at a plant in Texas. It later added 3-ounce cup servings to the recall. Five people were infected and three died in the past year in Kansas from listeria that might be linked to Blue Bell Creameries products, according to the CDC. All five of them were hospitalized at the same hospital before developing listeriosis, the CDC said. At least four of them had consumed milkshakes made with Blue Bell ice cream before developing the infection. &quot;We are devastated and know that Blue Bell has to be and can be better than this,&quot; Paul Kruse, Blue Bell CEO and president, said in a statement. &quot;Quality and safety have always been our top priorities. We are deeply saddened and concerned for all those who have been affected.&quot; The CDC advises that individuals and institutions should check their freezers for the recalled products and throw them away. In a statement on its website, Blue Bell said &quot;this recall in no way includes Blue Bell ice cream half gallons, pints, quarts, 3 gallons or other 3 oz. cups.&quot; This has been the first product recall in the 108-year history of Blue Bell Creameries, the company said. Listeriosis is a serious infection caused by eating food contaminated with listeria, and primarily affects the elderly, pregnant women, newborns and people with weakened immune systems, according to the CDC. Symptoms of a listeria infection are fever and muscle aches, sometimes associated with diarrhea or other gastrointestinal symptoms. In the United States, an estimated 1,600 people become seriously ill each year, and approximately 16% of these illnesses result in death. Cervical infections caused by listeriosis in pregnant women may result in stillbirth or spontaneous abortion during the second or third trimesters. CNN&#39;s Debra Goldschmidt, Amanda Watts and Jacque Wilson contributed to this report.

output: [/INST]Blue Bell ice cream has temporarily shut down one of its manufacturing plants after discovering listeria contamination in a serving of ice cream produced at the plant. The Centers for Disease Control and Prevention (CDC) has warned consumers not to eat any Blue Bell-branded products made at the Broken Arrow, Oklahoma plant, including 3-ounce servings of ice cream marked with certain codes. This is the third time Blue Bell has taken action due to a listeria outbreak at a Kansas hospital that served the company&#39;s ice cream. Investigations into the possible connection between the ice cream and the infections are ongoing. The company has recalled other products and advises individuals and institutions to check their freezers for the recalled items and throw them away. This is the first product recall in Blue Bell&#39;s 108-year history.
</code></pre>
<ol start="11">
<li>获取 token ID 序列：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">input_ids = tokenizer([input_text], return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids<br>prefix_ids = tokenizer([text], return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids<br>continue_ids = input_ids[<span class="hljs-number">0</span>, prefix_ids.shape[-<span class="hljs-number">1</span>]:]<br><br><span class="hljs-built_in">print</span>(input_ids.shape)<br><span class="hljs-built_in">print</span>(prefix_ids.shape)<br><span class="hljs-built_in">print</span>(continue_ids.shape)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">torch.Size([1, 1189])
torch.Size([1, 995])
torch.Size([194])
</code></pre>
<ol start="12">
<li>定位幻觉片段：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_hallucination_spans</span>(<span class="hljs-params">response, text, response_rag, tokenizer, prefix_len</span>):<br>    hallucination_span = []<br>    <br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> response:<br>        start_id = item[<span class="hljs-string">&#x27;start&#x27;</span>]<br>        end_id = item[<span class="hljs-string">&#x27;end&#x27;</span>]<br>        start_text = text+response_rag[:start_id]<br>        end_text = text+response_rag[:end_id]<br>        start_text_id = tokenizer(start_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids<br>        end_text_id = tokenizer(end_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids<br>        start_id = start_text_id.shape[-<span class="hljs-number">1</span>]<br>        end_id = end_text_id.shape[-<span class="hljs-number">1</span>]<br>        hallucination_span.append([start_id, end_id])<br>    <br>    <span class="hljs-keyword">return</span> hallucination_span<br><br><span class="hljs-keyword">if</span> <span class="hljs-string">&quot;labels&quot;</span> <span class="hljs-keyword">in</span> response[i].keys():<br>    hallucination_spans = calculate_hallucination_spans(response[i][<span class="hljs-string">&#x27;labels&#x27;</span>], text, response_rag, tokenizer, prefix_ids.shape[-<span class="hljs-number">1</span>])<br><span class="hljs-keyword">else</span>:<br>    hallucination_spans = []<br></code></pre></td></tr></table></figure>

<ol start="13">
<li>定位 prompt 对应的 token ID 片段：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_prompt_spans</span>(<span class="hljs-params">raw_prompt_spans, prompt, tokenizer</span>):<br>    prompt_spans = []<br>    <br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> raw_prompt_spans:<br>        start_id = item[<span class="hljs-number">0</span>]<br>        end_id = item[<span class="hljs-number">1</span>]<br>        start_text = prompt[:start_id]<br>        end_text = prompt[:end_id]<br>        added_start_text = add_special_template(start_text)<br>        added_end_text = add_special_template(end_text)<br>        <br>        <span class="hljs-comment"># 减 4 是为了去除特殊 token</span><br>        start_text_id = tokenizer(added_start_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids.shape[-<span class="hljs-number">1</span>] - <span class="hljs-number">4</span><br>        end_text_id = tokenizer(added_end_text,return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids.shape[-<span class="hljs-number">1</span>] -<span class="hljs-number">4</span><br>        prompt_spans.append([start_text_id, end_text_id])<br>    <span class="hljs-keyword">return</span> prompt_spans<br><br>prompt_spans = calculate_prompt_spans(source_info_dict[source_id][<span class="hljs-string">&#x27;prompt_spans&#x27;</span>], prompt, tokenizer)<br><span class="hljs-built_in">print</span>(prompt_spans)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[[22, 37], [37, 155], [151, 275], [270, 390], [387, 513], [507, 629], [626, 740], [737, 875], [869, 987], [987, 991]]
</code></pre>
<ol start="14">
<li>定位 response 对应的 token ID 片段：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_respond_spans</span>(<span class="hljs-params">raw_response_spans, text, response_rag, tokenizer</span>):<br>    respond_spans = []<br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> raw_response_spans:<br>        start_id = item[<span class="hljs-number">0</span>]<br>        end_id = item[<span class="hljs-number">1</span>]<br>        start_text = text+response_rag[:start_id]<br>        end_text = text+response_rag[:end_id]<br>        start_text_id = tokenizer(start_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids<br>        end_text_id = tokenizer(end_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids<br>        start_id = start_text_id.shape[-<span class="hljs-number">1</span>]<br>        end_id = end_text_id.shape[-<span class="hljs-number">1</span>]<br>        respond_spans.append([start_id, end_id])<br>    <span class="hljs-keyword">return</span> respond_spans<br><br>respond_spans = calculate_respond_spans(response[i][<span class="hljs-string">&#x27;response_spans&#x27;</span>], text, response_rag, tokenizer)<br><span class="hljs-built_in">print</span>(respond_spans)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[[995, 1114], [1112, 1189]]
</code></pre>
<ol start="15">
<li>执行模型推理：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">start_p, end_p = <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span><br>start, number = <span class="hljs-number">0</span>, <span class="hljs-number">32</span><br><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    logits_dict, outputs = model(<br>            input_ids=input_ids, <br>            return_dict=<span class="hljs-literal">True</span>,<br>            output_attentions=<span class="hljs-literal">True</span>,<br>            output_hidden_states=<span class="hljs-literal">True</span>,<br>            knowledge_layers=<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(start, number))<br>        )<br>    <br><span class="hljs-built_in">print</span>(outputs.keys())<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">odict_keys([&#39;logits&#39;, &#39;past_key_values&#39;, &#39;hidden_states&#39;, &#39;attentions&#39;])
</code></pre>
<ol start="16">
<li>获取 MLP 层的内容：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">logits_dict = &#123;key: [value[<span class="hljs-number">0</span>].to(device), value[<span class="hljs-number">1</span>].to(device)] <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> logits_dict.items()&#125;<br><br><span class="hljs-built_in">print</span>(logits_dict.keys())<br><span class="hljs-built_in">print</span>(logits_dict[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].shape, logits_dict[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>].shape)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])
torch.Size([1, 1189, 32000]) torch.Size([1, 1189, 32000])
</code></pre>
<ol start="17">
<li>获取隐藏状态：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">hidden_states = outputs[<span class="hljs-string">&quot;hidden_states&quot;</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(hidden_states))<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(hidden_states)) <span class="hljs-comment"># embedding 层 + 32 个 layer 层</span><br><span class="hljs-built_in">print</span>(hidden_states[<span class="hljs-number">0</span>].shape) <span class="hljs-comment"># 每层形状</span><br><br>last_hidden_states = hidden_states[-<span class="hljs-number">1</span>][<span class="hljs-number">0</span>, :, :]<br><span class="hljs-built_in">print</span>(last_hidden_states.shape)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&lt;class &#39;tuple&#39;&gt;
33
torch.Size([1, 1189, 4096])
torch.Size([1189, 4096])
</code></pre>
<ol start="18">
<li>定义幻觉检测变量：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">external_similarity = []<br>parameter_knowledge_difference = []<br>hallucination_label = []<br></code></pre></td></tr></table></figure>

<ol start="19">
<li>计算 ECS：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_sentence_similarity</span>(<span class="hljs-params">r_text, p_text</span>):<br>    part_embedding = bge_model.encode([r_text], normalize_embeddings=<span class="hljs-literal">True</span>)<br>    q_embeddings = bge_model.encode([p_text], normalize_embeddings=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># 计算得分：用点积计算，因为向量已经归一化</span><br>    scores_named = np.matmul(q_embeddings, part_embedding.T).flatten()<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(scores_named[<span class="hljs-number">0</span>])<br><br>span_socre_dict = []<br><span class="hljs-keyword">for</span> r_id, r_span <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(respond_spans):<br>    layer_head_span = &#123;&#125;<br>    <span class="hljs-keyword">for</span> attentions_layer_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(outputs.attentions)): <span class="hljs-comment"># 每一层 layer</span><br>        <span class="hljs-keyword">for</span> head_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(outputs.attentions[attentions_layer_id].shape[<span class="hljs-number">1</span>]): <span class="hljs-comment"># 每一层的每一个 head</span><br>            <span class="hljs-keyword">if</span> [attentions_layer_id, head_id] <span class="hljs-keyword">in</span> copy_heads: <span class="hljs-comment"># 只选择 copy heads 中的 head</span><br>                layer_head = (attentions_layer_id, head_id)<br>                attention_score = outputs.attentions[attentions_layer_id][<span class="hljs-number">0</span>,head_id,:,:]<br>                <br>                p_span_score_dict = []<br>                <span class="hljs-keyword">for</span> p_span <span class="hljs-keyword">in</span> prompt_spans:<br>                    <span class="hljs-comment"># 在注意力得分矩阵中，取 response 片段对应的那些行和 prompt 片段对应的那些列组成的矩阵</span><br>                    <span class="hljs-comment"># 矩阵求元素总和作为该 reponse 片段关注 prompt 片段的注意力得分</span><br>                    p_span_score_dict.append([p_span, torch.<span class="hljs-built_in">sum</span>(attention_score[r_span[<span class="hljs-number">0</span>]:r_span[<span class="hljs-number">1</span>], p_span[<span class="hljs-number">0</span>]:p_span[<span class="hljs-number">1</span>]]).cpu().item()])<br>                <span class="hljs-comment"># 取出最大的得分对应的 prompt 片段</span><br>                p_id = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(p_span_score_dict)), key=<span class="hljs-keyword">lambda</span> i: p_span_score_dict[i][<span class="hljs-number">1</span>])<br>                <span class="hljs-comment"># 找到 response 片段 最关注的 prompt 片段和这个 response 片段</span><br>                prompt_span_text, respond_span_text = prompt[original_prompt_spans[p_id][<span class="hljs-number">0</span>]:original_prompt_spans[p_id][<span class="hljs-number">1</span>]], response_rag[original_response_spans[r_id][<span class="hljs-number">0</span>]:original_response_spans[r_id][<span class="hljs-number">1</span>]]<br>                <span class="hljs-comment"># 计算向量相似度</span><br>                layer_head_span[<span class="hljs-built_in">str</span>(layer_head)] = calculate_sentence_similarity(prompt_span_text, respond_span_text)<br>                <br><span class="hljs-built_in">print</span>(outputs.attentions[attentions_layer_id].shape)<br><span class="hljs-built_in">print</span>(outputs.attentions[attentions_layer_id][:, head_id, :, :].shape)<br><span class="hljs-built_in">print</span>(p_span_score_dict)<br><span class="hljs-built_in">print</span>(prompt_span_text)<br><span class="hljs-built_in">print</span>(respond_span_text)<br><span class="hljs-built_in">print</span>(layer_head_span)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">torch.Size([1, 32, 1189, 1189])
torch.Size([1, 1189, 1189])
[[[22, 37], 0.11279296875], [[37, 155], 4.30078125], [[151, 275], 1.498046875], [[270, 390], 0.69775390625], [[387, 513], 0.25341796875], [[507, 629], 0.27685546875], [[626, 740], 0.76806640625], [[737, 875], 1.3994140625], [[869, 987], 6.05078125], [[987, 991], 0.0654296875]]
and muscle aches, sometimes associated with diarrhea or other gastrointestinal symptoms. In the United States, an estimated 1,600 people become seriously ill each year, and approximately 16% of these illnesses result in death. Cervical infections caused by listeriosis in pregnant women may result in stillbirth or spontaneous abortion during the second or third trimesters. CNN&#39;s Debra Goldschmidt, Amanda Watts and Jacque Wilson contributed to this report.
that served the company&#39;s ice cream. Investigations into the possible connection between the ice cream and the infections are ongoing. The company has recalled other products and advises individuals and institutions to check their freezers for the recalled items and throw them away. This is the first product recall in Blue Bell&#39;s 108-year history.
&#123;&#39;(1, 14)&#39;: 0.7934820652008057, &#39;(1, 21)&#39;: 0.5256378650665283, &#39;(1, 27)&#39;: 0.7934820652008057, &#39;(2, 5)&#39;: 0.5256378650665283, &#39;(2, 22)&#39;: 0.5256378650665283, &#39;(3, 0)&#39;: 0.5256378650665283, &#39;(3, 19)&#39;: 0.5256378650665283, &#39;(5, 13)&#39;: 0.5256378650665283, &#39;(5, 29)&#39;: 0.5256378650665283, &#39;(10, 20)&#39;: 0.5256378650665283, &#39;(13, 20)&#39;: 0.5256378650665283, &#39;(15, 7)&#39;: 0.5256378650665283, &#39;(16, 1)&#39;: 0.7934820652008057, &#39;(18, 9)&#39;: 0.7934820652008057, &#39;(18, 10)&#39;: 0.7934820652008057, &#39;(18, 13)&#39;: 0.5256378650665283, &#39;(19, 1)&#39;: 0.5256378650665283, &#39;(20, 1)&#39;: 0.7861142158508301, &#39;(20, 5)&#39;: 0.7861142158508301, &#39;(20, 15)&#39;: 0.5256378650665283, &#39;(20, 17)&#39;: 0.7934820652008057, &#39;(20, 22)&#39;: 0.5256378650665283, &#39;(22, 10)&#39;: 0.5256378650665283, &#39;(23, 8)&#39;: 0.7861142158508301, &#39;(23, 30)&#39;: 0.5256378650665283, &#39;(25, 0)&#39;: 0.7861142158508301, &#39;(27, 9)&#39;: 0.5256378650665283, &#39;(28, 18)&#39;: 0.5256378650665283, &#39;(31, 18)&#39;: 0.5256378650665283, &#39;(31, 19)&#39;: 0.5256378650665283, &#39;(31, 24)&#39;: 0.7118228077888489, &#39;(31, 28)&#39;: 0.5256378650665283&#125;
</code></pre>
<ol start="20">
<li>JS 散度计算函数：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_dist_2d</span>(<span class="hljs-params">sep_vocabulary_dist, sep_attention_dist</span>):<br>    softmax_mature_layer = F.softmax(sep_vocabulary_dist, dim=-<span class="hljs-number">1</span>)  <br>    softmax_anchor_layer = F.softmax(sep_attention_dist, dim=-<span class="hljs-number">1</span>)  <br><br>    M = <span class="hljs-number">0.5</span> * (softmax_mature_layer + softmax_anchor_layer) <br><br>    log_softmax_mature_layer = F.log_softmax(sep_vocabulary_dist, dim=-<span class="hljs-number">1</span>)<br>    log_softmax_anchor_layer = F.log_softmax(sep_attention_dist, dim=-<span class="hljs-number">1</span>)<br><br>    kl1 = F.kl_div(log_softmax_mature_layer, M, reduction=<span class="hljs-string">&#x27;none&#x27;</span>).<span class="hljs-built_in">sum</span>(dim=-<span class="hljs-number">1</span>)  <br>    kl2 = F.kl_div(log_softmax_anchor_layer, M, reduction=<span class="hljs-string">&#x27;none&#x27;</span>).<span class="hljs-built_in">sum</span>(dim=-<span class="hljs-number">1</span>)  <br>    js_divs = <span class="hljs-number">0.5</span> * (kl1 + kl2)<br>    <br>    scores = js_divs.cpu().tolist() <span class="hljs-comment"># 换成了散度的和</span><br>    <br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(scores)<br></code></pre></td></tr></table></figure>
<br/>

<ol start="21">
<li>幻觉片段判断函数：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">is_hallucination_span</span>(<span class="hljs-params">r_span, hallucination_spans</span>):<br>    <span class="hljs-keyword">for</span> token_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(r_span[<span class="hljs-number">0</span>], r_span[<span class="hljs-number">1</span>]):<br>        <span class="hljs-keyword">for</span> span <span class="hljs-keyword">in</span> hallucination_spans:<br>            <span class="hljs-keyword">if</span> token_id &gt;= span[<span class="hljs-number">0</span>] <span class="hljs-keyword">and</span> token_id &lt;= span[<span class="hljs-number">1</span>]:<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure>

<ol start="22">
<li>计算 PKS：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> r_id, r_span <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(respond_spans):<br>    parameter_knowledge_scores = [calculate_dist_2d(value[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>,r_span[<span class="hljs-number">0</span>]:r_span[<span class="hljs-number">1</span>],:], value[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>,r_span[<span class="hljs-number">0</span>]:r_span[<span class="hljs-number">1</span>],:]) <span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> logits_dict.values()]<br>    parameter_knowledge_dict = &#123;<span class="hljs-string">f&quot;layer_<span class="hljs-subst">&#123;i&#125;</span>&quot;</span>: value <span class="hljs-keyword">for</span> i, value <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(parameter_knowledge_scores)&#125;<br>    <br>    span_socre_dict.append(&#123;<br>        <span class="hljs-string">&quot;prompt_attention_score&quot;</span>:layer_head_span, <span class="hljs-comment"># </span><br>        <span class="hljs-string">&quot;r_span&quot;</span>: r_span,<br>        <span class="hljs-string">&quot;hallucination_label&quot;</span>: <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> is_hallucination_span(r_span, hallucination_spans) <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>,<br>        <span class="hljs-string">&quot;parameter_knowledge_scores&quot;</span>: parameter_knowledge_dict<br>    &#125;)<br><br>parameter_knowledge_dict<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&#123;&#39;layer_0&#39;: 6.265625,
&#39;layer_1&#39;: 11.825347900390625,
&#39;layer_2&#39;: 7.304943084716797,
&#39;layer_3&#39;: 8.502777099609375,
&#39;layer_4&#39;: 8.751604080200195,
&#39;layer_5&#39;: 9.063507080078125,
&#39;layer_6&#39;: 10.59210205078125,
&#39;layer_7&#39;: 10.3037109375,
&#39;layer_8&#39;: 9.185203552246094,
&#39;layer_9&#39;: 8.613269805908203,
&#39;layer_10&#39;: 8.374945402145386,
&#39;layer_11&#39;: 6.96978759765625,
&#39;layer_12&#39;: 7.036556243896484,
&#39;layer_13&#39;: 6.907812118530273,
&#39;layer_14&#39;: 6.779157400131226,
&#39;layer_15&#39;: 6.831340312957764,
&#39;layer_16&#39;: 5.449123382568359,
&#39;layer_17&#39;: 7.206271290779114,
&#39;layer_18&#39;: 4.6526288986206055,
&#39;layer_19&#39;: 5.492448091506958,
&#39;layer_20&#39;: 4.489939272403717,
&#39;layer_21&#39;: 3.39082270860672,
&#39;layer_22&#39;: 2.022574782371521,
&#39;layer_23&#39;: 1.9388360977172852,
&#39;layer_24&#39;: 4.99117386341095,
&#39;layer_25&#39;: 15.26219892501831,
&#39;layer_26&#39;: 6.535698175430298,
&#39;layer_27&#39;: 6.107271254062653,
&#39;layer_28&#39;: 3.5565916895866394,
&#39;layer_29&#39;: 1.0493692755699158,
&#39;layer_30&#39;: 4.485132694244385,
&#39;layer_31&#39;: 5.870414137840271&#125;
</code></pre>
<ol start="23">
<li>结果查看：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">response[i][<span class="hljs-string">&quot;scores&quot;</span>] = span_socre_dict<br>select_response.append(response[i])<br><br><span class="hljs-built_in">print</span>(json.dumps(select_response, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[
    &#123;
        &quot;id&quot;: &quot;45&quot;,
        &quot;source_id&quot;: &quot;15599&quot;,
        &quot;model&quot;: &quot;llama-2-7b-chat&quot;,
        &quot;temperature&quot;: 0.7,
        &quot;labels&quot;: [],
        &quot;split&quot;: &quot;test&quot;,
        &quot;quality&quot;: &quot;good&quot;,
        &quot;response&quot;: &quot;Blue Bell ice cream has temporarily shut down one of its manufacturing plants after discovering listeria contamination in a serving of ice cream produced at the plant. The Centers for Disease Control and Prevention (CDC) has warned consumers not to eat any Blue Bell-branded products made at the Broken Arrow, Oklahoma plant, including 3-ounce servings of ice cream marked with certain codes. This is the third time Blue Bell has taken action due to a listeria outbreak at a Kansas hospital that served the company&#39;s ice cream. Investigations into the possible connection between the ice cream and the infections are ongoing. The company has recalled other products and advises individuals and institutions to check their freezers for the recalled items and throw them away. This is the first product recall in Blue Bell&#39;s 108-year history.&quot;,
        &quot;response_spans&quot;: [
            [
                0,
                506
            ],
            [
                491,
                840
            ]
        ],
        &quot;scores&quot;: [
            &#123;
                &quot;prompt_attention_score&quot;: &#123;
                    &quot;(1, 14)&quot;: 0.7934820652008057,
                    &quot;(1, 21)&quot;: 0.5256378650665283,
                    &quot;(1, 27)&quot;: 0.7934820652008057,
                    &quot;(2, 5)&quot;: 0.5256378650665283,
                    &quot;(2, 22)&quot;: 0.5256378650665283,
                    &quot;(3, 0)&quot;: 0.5256378650665283,
                    &quot;(3, 19)&quot;: 0.5256378650665283,
                    &quot;(5, 13)&quot;: 0.5256378650665283,
                    &quot;(5, 29)&quot;: 0.5256378650665283,
                    &quot;(10, 20)&quot;: 0.5256378650665283,
                    &quot;(13, 20)&quot;: 0.5256378650665283,
                    &quot;(15, 7)&quot;: 0.5256378650665283,
                    &quot;(16, 1)&quot;: 0.7934820652008057,
                    &quot;(18, 9)&quot;: 0.7934820652008057,
                    &quot;(18, 10)&quot;: 0.7934820652008057,
                    &quot;(18, 13)&quot;: 0.5256378650665283,
                    &quot;(19, 1)&quot;: 0.5256378650665283,
                    &quot;(20, 1)&quot;: 0.7861142158508301,
                    &quot;(20, 5)&quot;: 0.7861142158508301,
                    &quot;(20, 15)&quot;: 0.5256378650665283,
                    &quot;(20, 17)&quot;: 0.7934820652008057,
                    &quot;(20, 22)&quot;: 0.5256378650665283,
                    &quot;(22, 10)&quot;: 0.5256378650665283,
                    &quot;(23, 8)&quot;: 0.7861142158508301,
                    &quot;(23, 30)&quot;: 0.5256378650665283,
                    &quot;(25, 0)&quot;: 0.7861142158508301,
                    &quot;(27, 9)&quot;: 0.5256378650665283,
                    &quot;(28, 18)&quot;: 0.5256378650665283,
                    &quot;(31, 18)&quot;: 0.5256378650665283,
                    &quot;(31, 19)&quot;: 0.5256378650665283,
                    &quot;(31, 24)&quot;: 0.7118228077888489,
                    &quot;(31, 28)&quot;: 0.5256378650665283
                &#125;,
                &quot;r_span&quot;: [
                    995,
                    1114
                ],
                &quot;hallucination_label&quot;: 0,
                &quot;parameter_knowledge_scores&quot;: &#123;
                    &quot;layer_0&quot;: 10.039642333984375,
                    &quot;layer_1&quot;: 19.6171875,
                    &quot;layer_2&quot;: 13.364913940429688,
                    &quot;layer_3&quot;: 15.792007446289062,
                    &quot;layer_4&quot;: 16.167789459228516,
                    &quot;layer_5&quot;: 14.672402381896973,
                    &quot;layer_6&quot;: 14.83043384552002,
                    &quot;layer_7&quot;: 16.115909576416016,
                    &quot;layer_8&quot;: 14.244064331054688,
                    &quot;layer_9&quot;: 13.896240234375,
                    &quot;layer_10&quot;: 13.285934448242188,
                    &quot;layer_11&quot;: 11.34033203125,
                    &quot;layer_12&quot;: 10.39111328125,
                    &quot;layer_13&quot;: 9.857498168945312,
                    &quot;layer_14&quot;: 9.97247314453125,
                    &quot;layer_15&quot;: 9.715774536132812,
                    &quot;layer_16&quot;: 9.486862182617188,
                    &quot;layer_17&quot;: 7.691881537437439,
                    &quot;layer_18&quot;: 11.035508871078491,
                    &quot;layer_19&quot;: 8.649388074874878,
                    &quot;layer_20&quot;: 7.8278902769088745,
                    &quot;layer_21&quot;: 4.75305837392807,
                    &quot;layer_22&quot;: 4.245644927024841,
                    &quot;layer_23&quot;: 6.389559030532837,
                    &quot;layer_24&quot;: 15.33685153722763,
                    &quot;layer_25&quot;: 2.7393543124198914,
                    &quot;layer_26&quot;: 2.4489996433258057,
                    &quot;layer_27&quot;: 1.971637487411499,
                    &quot;layer_28&quot;: 5.669117510318756,
                    &quot;layer_29&quot;: 2.5789473056793213,
                    &quot;layer_30&quot;: 7.760132610797882,
                    &quot;layer_31&quot;: 6.783948659896851
                &#125;
            &#125;,
            &#123;
                &quot;prompt_attention_score&quot;: &#123;
                    &quot;(1, 14)&quot;: 0.7934820652008057,
                    &quot;(1, 21)&quot;: 0.5256378650665283,
                    &quot;(1, 27)&quot;: 0.7934820652008057,
                    &quot;(2, 5)&quot;: 0.5256378650665283,
                    &quot;(2, 22)&quot;: 0.5256378650665283,
                    &quot;(3, 0)&quot;: 0.5256378650665283,
                    &quot;(3, 19)&quot;: 0.5256378650665283,
                    &quot;(5, 13)&quot;: 0.5256378650665283,
                    &quot;(5, 29)&quot;: 0.5256378650665283,
                    &quot;(10, 20)&quot;: 0.5256378650665283,
                    &quot;(13, 20)&quot;: 0.5256378650665283,
                    &quot;(15, 7)&quot;: 0.5256378650665283,
                    &quot;(16, 1)&quot;: 0.7934820652008057,
                    &quot;(18, 9)&quot;: 0.7934820652008057,
                    &quot;(18, 10)&quot;: 0.7934820652008057,
                    &quot;(18, 13)&quot;: 0.5256378650665283,
                    &quot;(19, 1)&quot;: 0.5256378650665283,
                    &quot;(20, 1)&quot;: 0.7861142158508301,
                    &quot;(20, 5)&quot;: 0.7861142158508301,
                    &quot;(20, 15)&quot;: 0.5256378650665283,
                    &quot;(20, 17)&quot;: 0.7934820652008057,
                    &quot;(20, 22)&quot;: 0.5256378650665283,
                    &quot;(22, 10)&quot;: 0.5256378650665283,
                    &quot;(23, 8)&quot;: 0.7861142158508301,
                    &quot;(23, 30)&quot;: 0.5256378650665283,
                    &quot;(25, 0)&quot;: 0.7861142158508301,
                    &quot;(27, 9)&quot;: 0.5256378650665283,
                    &quot;(28, 18)&quot;: 0.5256378650665283,
                    &quot;(31, 18)&quot;: 0.5256378650665283,
                    &quot;(31, 19)&quot;: 0.5256378650665283,
                    &quot;(31, 24)&quot;: 0.7118228077888489,
                    &quot;(31, 28)&quot;: 0.5256378650665283
                &#125;,
                &quot;r_span&quot;: [
                    1112,
                    1189
                ],
                &quot;hallucination_label&quot;: 0,
                &quot;parameter_knowledge_scores&quot;: &#123;
                    &quot;layer_0&quot;: 6.265625,
                    &quot;layer_1&quot;: 11.825347900390625,
                    &quot;layer_2&quot;: 7.304943084716797,
                    &quot;layer_3&quot;: 8.502777099609375,
                    &quot;layer_4&quot;: 8.751604080200195,
                    &quot;layer_5&quot;: 9.063507080078125,
                    &quot;layer_6&quot;: 10.59210205078125,
                    &quot;layer_7&quot;: 10.3037109375,
                    &quot;layer_8&quot;: 9.185203552246094,
                    &quot;layer_9&quot;: 8.613269805908203,
                    &quot;layer_10&quot;: 8.374945402145386,
                    &quot;layer_11&quot;: 6.96978759765625,
                    &quot;layer_12&quot;: 7.036556243896484,
                    &quot;layer_13&quot;: 6.907812118530273,
                    &quot;layer_14&quot;: 6.779157400131226,
                    &quot;layer_15&quot;: 6.831340312957764,
                    &quot;layer_16&quot;: 5.449123382568359,
                    &quot;layer_17&quot;: 7.206271290779114,
                    &quot;layer_18&quot;: 4.6526288986206055,
                    &quot;layer_19&quot;: 5.492448091506958,
                    &quot;layer_20&quot;: 4.489939272403717,
                    &quot;layer_21&quot;: 3.39082270860672,
                    &quot;layer_22&quot;: 2.022574782371521,
                    &quot;layer_23&quot;: 1.9388360977172852,
                    &quot;layer_24&quot;: 4.99117386341095,
                    &quot;layer_25&quot;: 15.26219892501831,
                    &quot;layer_26&quot;: 6.535698175430298,
                    &quot;layer_27&quot;: 6.107271254062653,
                    &quot;layer_28&quot;: 3.5565916895866394,
                    &quot;layer_29&quot;: 1.0493692755699158,
                    &quot;layer_30&quot;: 4.485132694244385,
                    &quot;layer_31&quot;: 5.870414137840271
                &#125;
            &#125;
        ]
    &#125;
]
</code></pre>
<ol start="24">
<li>保存结果：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../output/llama2_7B_response_chunk.json&quot;</span>, <span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    json.dump(select_response, f, ensure_ascii=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>

<h2 id="2-3-regress-py"><a href="#2-3-regress-py" class="headerlink" title="2.3 regress.py"></a>2.3 regress.py</h2><h3 id="2-3-1-token-级别"><a href="#2-3-1-token-级别" class="headerlink" title="2.3.1 token 级别"></a>2.3.1 token 级别</h3><ol>
<li>导入必要的包：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_auc_score<br><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> pearsonr<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MinMaxScaler<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br></code></pre></td></tr></table></figure>

<ol start="2">
<li>加载 copy_heads：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">topk_head_path = <span class="hljs-string">&quot;../dataset/topk_heads.json&quot;</span><br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(topk_head_path, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    copy_heads = json.load(f)<br>sorted_copy_heads = <span class="hljs-built_in">sorted</span>(copy_heads, key=<span class="hljs-keyword">lambda</span> x: (x[<span class="hljs-number">0</span>], x[<span class="hljs-number">1</span>])) <span class="hljs-comment"># 按 layer 层和注意力头升序排序</span><br><br><span class="hljs-built_in">print</span>(sorted_copy_heads)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[[1, 14], [1, 21], [1, 27], [2, 5], [2, 22], [3, 0], [3, 19], [5, 13], [5, 29], [10, 20], [13, 20], [15, 7], [16, 1], [18, 9], [18, 10], [18, 13], [19, 1], [20, 1], [20, 5], [20, 15], [20, 17], [20, 22], [22, 10], [23, 8], [23, 30], [25, 0], [27, 9], [28, 18], [31, 18], [31, 19], [31, 24], [31, 28]]
</code></pre>
<ol start="3">
<li>构建数据集：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">construct_dataframe</span>(<span class="hljs-params">file_path, number</span>):<br>    <span class="hljs-comment"># 读取数据集</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        response = json.load(f)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(response))<br>    <span class="hljs-built_in">print</span>(response[<span class="hljs-number">0</span>].keys())<br>    <br>    <span class="hljs-comment"># 定义表头：索引、ECS、PKS、幻觉标签</span><br>    data_dict = &#123;<br>        <span class="hljs-string">&quot;identifier&quot;</span>: [],<br>        **&#123;<span class="hljs-string">f&quot;external_similarity_<span class="hljs-subst">&#123;k&#125;</span>&quot;</span>: [] <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(number)&#125;,<br>        **&#123;<span class="hljs-string">f&quot;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&quot;</span>: [] <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(number)&#125;,<br>        <span class="hljs-string">&quot;hallucination_label&quot;</span>: []<br>    &#125;<br><br>    <span class="hljs-comment"># response_i 表示第 i 个 response，item_j 表示第 j 个 token ID</span><br>    <span class="hljs-keyword">for</span> i, resp <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(response): <span class="hljs-comment"># 遍历每个 response</span><br>        <span class="hljs-keyword">if</span> resp[<span class="hljs-string">&quot;split&quot;</span>] != <span class="hljs-string">&quot;test&quot;</span>:<br>            <span class="hljs-keyword">continue</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(resp[<span class="hljs-string">&quot;external_similarity&quot;</span>])): <span class="hljs-comment"># 遍历每个 token ID</span><br>            data_dict[<span class="hljs-string">&quot;identifier&quot;</span>].append(<span class="hljs-string">f&quot;response_<span class="hljs-subst">&#123;i&#125;</span>_item_<span class="hljs-subst">&#123;j&#125;</span>&quot;</span>)<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(number): <span class="hljs-comment"># 遍历每个具体的得分</span><br>                data_dict[<span class="hljs-string">f&quot;external_similarity_<span class="hljs-subst">&#123;k&#125;</span>&quot;</span>].append(resp[<span class="hljs-string">&quot;external_similarity&quot;</span>][j][k])<br>                data_dict[<span class="hljs-string">f&quot;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&quot;</span>].append(resp[<span class="hljs-string">&quot;parameter_knowledge_difference&quot;</span>][j][k])<br>            data_dict[<span class="hljs-string">&quot;hallucination_label&quot;</span>].append(resp[<span class="hljs-string">&quot;hallucination_label&quot;</span>][j])<br><br>    df = pd.DataFrame(data_dict) <span class="hljs-comment"># 转换为 DataFrame</span><br><br>    <span class="hljs-built_in">print</span>(df[<span class="hljs-string">&quot;hallucination_label&quot;</span>].value_counts(normalize=<span class="hljs-literal">True</span>)) <span class="hljs-comment"># 查看幻觉标签的比例</span><br>    <span class="hljs-keyword">return</span> df<br><br><span class="hljs-comment"># 读取数据</span><br>data_path = <span class="hljs-string">&quot;../dataset/llama2_7B_response_token.json&quot;</span><br>number = <span class="hljs-number">32</span><br>df = construct_dataframe(data_path, number) <span class="hljs-comment"># 构建数据集</span><br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">450
dict_keys([&#39;id&#39;, &#39;source_id&#39;, &#39;model&#39;, &#39;temperature&#39;, &#39;labels&#39;, &#39;split&#39;, &#39;quality&#39;, &#39;response&#39;, &#39;external_similarity&#39;, &#39;parameter_knowledge_difference&#39;, &#39;hallucination_label&#39;])
hallucination_label
0    0.937957
1    0.062043
Name: proportion, dtype: float64
</code></pre>
<ol start="4">
<li>计算 ECS 和 PKS 的 AUC 和 PCC：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 计算 ECS、PKS 的 AUC（曲线下面积）和 Pearson 相关系数（PCC）</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_auc_pcc</span>(<span class="hljs-params">df, number</span>):<br>    auc_external_similarity = []<br>    pearson_external_similarity = []<br><br>    auc_parameter_knowledge_difference = []<br>    pearson_parameter_knowledge_difference = []<br><br>    <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(number):<br>        <span class="hljs-comment"># ECS 和幻觉标签的 AUC 和 PCC：负相关</span><br>        auc_ext = roc_auc_score(<span class="hljs-number">1</span> - df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], df[<span class="hljs-string">f&#x27;external_similarity_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>])<br>        pearson_ext, _ = pearsonr(df[<span class="hljs-string">f&#x27;external_similarity_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>], <span class="hljs-number">1</span> - df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>])<br>        auc_external_similarity.append((auc_ext, <span class="hljs-string">f&#x27;external_similarity_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>))<br>        pearson_external_similarity.append((pearson_ext, <span class="hljs-string">f&#x27;external_similarity_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>))<br><br>        <span class="hljs-comment"># PKS 和幻觉标签的 AUC 和 PCC：正相关</span><br>        auc_param = roc_auc_score(df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], df[<span class="hljs-string">f&#x27;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>])<br>        <span class="hljs-keyword">if</span> df[<span class="hljs-string">f&#x27;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>].nunique() == <span class="hljs-number">1</span>: <span class="hljs-comment"># 检查 PKS 某一列是否所有值都相同</span><br>            <span class="hljs-built_in">print</span>(k)<br>        pearson_param, _ = pearsonr(df[<span class="hljs-string">f&#x27;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>], df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>])<br>        auc_parameter_knowledge_difference.append((auc_param, <span class="hljs-string">f&#x27;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>))<br>        pearson_parameter_knowledge_difference.append((pearson_param, <span class="hljs-string">f&#x27;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>))<br>    <br>    <span class="hljs-keyword">return</span> auc_external_similarity, auc_parameter_knowledge_difference<br><br><span class="hljs-comment"># 计算 ECS、PKS 各自和幻觉标签的 AUC</span><br>auc_external_similarity, auc_parameter_knowledge_difference = calculate_auc_pcc(df, number)<br><span class="hljs-built_in">print</span>(auc_external_similarity)<br><span class="hljs-built_in">print</span>(auc_parameter_knowledge_difference)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[(0.5241438817940267, &#39;external_similarity_0&#39;), (0.5303407378212408, &#39;external_similarity_1&#39;), (0.5210631524747991, &#39;external_similarity_2&#39;), (0.5298950697568433, &#39;external_similarity_3&#39;), (0.5381268749312161, &#39;external_similarity_4&#39;), (0.5443052544867116, &#39;external_similarity_5&#39;), (0.5284039282339847, &#39;external_similarity_6&#39;), (0.5456647839911151, &#39;external_similarity_7&#39;), (0.5235929010288944, &#39;external_similarity_8&#39;), (0.54994054648032, &#39;external_similarity_9&#39;), (0.551097841783863, &#39;external_similarity_10&#39;), (0.5452417434757976, &#39;external_similarity_11&#39;), (0.5516958013996187, &#39;external_similarity_12&#39;), (0.560198923892558, &#39;external_similarity_13&#39;), (0.5523331302903907, &#39;external_similarity_14&#39;), (0.5286836290578362, &#39;external_similarity_15&#39;), (0.5421496701504019, &#39;external_similarity_16&#39;), (0.5671844186584903, &#39;external_similarity_17&#39;), (0.5620680003417163, &#39;external_similarity_18&#39;), (0.5234921142777087, &#39;external_similarity_19&#39;), (0.5597268861531965, &#39;external_similarity_20&#39;), (0.5459607978014505, &#39;external_similarity_21&#39;), (0.5186293371214259, &#39;external_similarity_22&#39;), (0.5639456416859279, &#39;external_similarity_23&#39;), (0.5400120719837709, &#39;external_similarity_24&#39;), (0.5673763213378886, &#39;external_similarity_25&#39;), (0.5318546025350572, &#39;external_similarity_26&#39;), (0.5223420844588798, &#39;external_similarity_27&#39;), (0.5204039479779862, &#39;external_similarity_28&#39;), (0.5314390022982304, &#39;external_similarity_29&#39;), (0.5486740941122893, &#39;external_similarity_30&#39;), (0.5228121170168041, &#39;external_similarity_31&#39;)]
[(0.4957178339023127, &#39;parameter_knowledge_difference_0&#39;), (0.4910236843698426, &#39;parameter_knowledge_difference_1&#39;), (0.5019680855806161, &#39;parameter_knowledge_difference_2&#39;), (0.5017760641733695, &#39;parameter_knowledge_difference_3&#39;), (0.5065210786948295, &#39;parameter_knowledge_difference_4&#39;), (0.5304081180737897, &#39;parameter_knowledge_difference_5&#39;), (0.5378957151086584, &#39;parameter_knowledge_difference_6&#39;), (0.5357647382182317, &#39;parameter_knowledge_difference_7&#39;), (0.5370695759592025, &#39;parameter_knowledge_difference_8&#39;), (0.5203812973429356, &#39;parameter_knowledge_difference_9&#39;), (0.46947324971983245, &#39;parameter_knowledge_difference_10&#39;), (0.5191418423684, &#39;parameter_knowledge_difference_11&#39;), (0.5176579289529697, &#39;parameter_knowledge_difference_12&#39;), (0.5108610113873528, &#39;parameter_knowledge_difference_13&#39;), (0.5318679407293433, &#39;parameter_knowledge_difference_14&#39;), (0.523121552570652, &#39;parameter_knowledge_difference_15&#39;), (0.5637065413888521, &#39;parameter_knowledge_difference_16&#39;), (0.5603452361775584, &#39;parameter_knowledge_difference_17&#39;), (0.5589974486374809, &#39;parameter_knowledge_difference_18&#39;), (0.5465907018043785, &#39;parameter_knowledge_difference_19&#39;), (0.5557532354685331, &#39;parameter_knowledge_difference_20&#39;), (0.5648406814639895, &#39;parameter_knowledge_difference_21&#39;), (0.5478857807758221, &#39;parameter_knowledge_difference_22&#39;), (0.5692361568028578, &#39;parameter_knowledge_difference_23&#39;), (0.5659032649245824, &#39;parameter_knowledge_difference_24&#39;), (0.5641498623795829, &#39;parameter_knowledge_difference_25&#39;), (0.5503712647298249, &#39;parameter_knowledge_difference_26&#39;), (0.5519855226339968, &#39;parameter_knowledge_difference_27&#39;), (0.559005634263019, &#39;parameter_knowledge_difference_28&#39;), (0.5528760122772071, &#39;parameter_knowledge_difference_29&#39;), (0.5467555938982988, &#39;parameter_knowledge_difference_30&#39;), (0.5321519256497191, &#39;parameter_knowledge_difference_31&#39;)]
</code></pre>
<ol start="5">
<li>计算 response 的 AUC 和 PCC：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 计算 response 的 AUC 和 PCC</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_auc_pcc_32_32</span>(<span class="hljs-params">df, top_n, top_k, alpha, auc_external_similarity, auc_parameter_knowledge_difference, m=<span class="hljs-number">1</span></span>):<br>    collect_info = &#123;&#125;<br>    <span class="hljs-comment"># 选择 ECS 的 AUC 分数最高的 top_n 个特征</span><br>    top_auc_external_similarity = <span class="hljs-built_in">sorted</span>(auc_external_similarity, reverse=<span class="hljs-literal">True</span>)[:top_n]<br>    <span class="hljs-built_in">print</span>(top_auc_external_similarity)<br>    collect_info.update(&#123;<span class="hljs-string">&quot;select_heads&quot;</span>: [sorted_copy_heads[<span class="hljs-built_in">eval</span>(name.split(<span class="hljs-string">&#x27;_&#x27;</span>)[-<span class="hljs-number">1</span>])] <span class="hljs-keyword">for</span> _, name <span class="hljs-keyword">in</span> top_auc_external_similarity]&#125;)<br><br>    <span class="hljs-comment"># 选择 PKS 的 AUC 分数最高的 top_k 个特征</span><br>    top_auc_parameter_knowledge_difference = <span class="hljs-built_in">sorted</span>(auc_parameter_knowledge_difference, reverse=<span class="hljs-literal">True</span>)[:top_k]<br>    <span class="hljs-built_in">print</span>(top_auc_parameter_knowledge_difference)<br>    base_layer = <span class="hljs-number">0</span><br>    collect_info.update(&#123;<span class="hljs-string">&quot;select_layers&quot;</span>: [<span class="hljs-built_in">eval</span>(name.split(<span class="hljs-string">&#x27;_&#x27;</span>)[-<span class="hljs-number">1</span>]) + base_layer <span class="hljs-keyword">for</span> _, name <span class="hljs-keyword">in</span> top_auc_parameter_knowledge_difference]&#125;)<br><br>    <span class="hljs-comment"># 对于选择好的特征，求其对应 df 列的和，表示为 ECS 和 PKS 的和</span><br>    df[<span class="hljs-string">&#x27;external_similarity_sum&#x27;</span>] = df[[col <span class="hljs-keyword">for</span> _, col <span class="hljs-keyword">in</span> top_auc_external_similarity]].<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>)<br>    df[<span class="hljs-string">&#x27;parameter_knowledge_difference_sum&#x27;</span>] = df[[col <span class="hljs-keyword">for</span> _, col <span class="hljs-keyword">in</span> top_auc_parameter_knowledge_difference]].<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 计算 ECS、PKS 和的 AUC</span><br>    final_auc_external_similarity = roc_auc_score(<span class="hljs-number">1</span> - df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], df[<span class="hljs-string">&#x27;external_similarity_sum&#x27;</span>])<br>    final_auc_parameter_knowledge_difference = roc_auc_score(df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], df[<span class="hljs-string">&#x27;parameter_knowledge_difference_sum&#x27;</span>])<br><br>    <span class="hljs-comment"># 计算 ECS、PKS 和的 PCC</span><br>    final_pearson_external_similarity, _ = pearsonr(df[<span class="hljs-string">&#x27;external_similarity_sum&#x27;</span>], <span class="hljs-number">1</span> - df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>])<br>    final_pearson_parameter_knowledge_difference, _ = pearsonr(df[<span class="hljs-string">&#x27;parameter_knowledge_difference_sum&#x27;</span>], df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>])<br><br>    <span class="hljs-comment"># 存放结果</span><br>    results = &#123;<br>        <span class="hljs-string">f&quot;Top <span class="hljs-subst">&#123;top_n&#125;</span> AUC External Similarity&quot;</span>: final_auc_external_similarity,<br>        <span class="hljs-string">f&quot;Top <span class="hljs-subst">&#123;top_n&#125;</span> AUC Parameter Knowledge Difference&quot;</span>: final_auc_parameter_knowledge_difference,<br>        <span class="hljs-string">f&quot;Top <span class="hljs-subst">&#123;top_k&#125;</span> Pearson Correlation External Similarity&quot;</span>: final_pearson_external_similarity,<br>        <span class="hljs-string">f&quot;Top <span class="hljs-subst">&#123;top_k&#125;</span> Pearson Correlation Parameter Knowledge Difference&quot;</span>: final_pearson_parameter_knowledge_difference<br>    &#125;<br><br>    <span class="hljs-comment"># 最小最大归一化</span><br>    scaler = MinMaxScaler()<br><br>    <span class="hljs-comment"># 归一化 ECS 和的列</span><br>    df[<span class="hljs-string">&#x27;external_similarity_sum_normalized&#x27;</span>] = scaler.fit_transform(df[[<span class="hljs-string">&#x27;external_similarity_sum&#x27;</span>]])<br>    external_similarity_sum_max_value = scaler.data_max_[<span class="hljs-number">0</span>]<br>    external_similarity_sum_min_value = scaler.data_min_[<span class="hljs-number">0</span>]<br>    collect_info.update(&#123;<span class="hljs-string">&quot;head_max_min&quot;</span>: [external_similarity_sum_max_value, external_similarity_sum_min_value]&#125;)<br>    <br>    <span class="hljs-comment"># 归一化 PKS 和的列</span><br>    df[<span class="hljs-string">&#x27;parameter_knowledge_difference_sum_normalized&#x27;</span>] = scaler.fit_transform(df[[<span class="hljs-string">&#x27;parameter_knowledge_difference_sum&#x27;</span>]])<br>    parameter_knowledge_sum_max_value = scaler.data_max_[<span class="hljs-number">0</span>]<br>    parameter_knowledge_sum_min_value = scaler.data_min_[<span class="hljs-number">0</span>]<br>    collect_info.update(&#123;<span class="hljs-string">&quot;layers_max_min&quot;</span>: [parameter_knowledge_sum_max_value, parameter_knowledge_sum_min_value]&#125;)<br><br>    <span class="hljs-comment"># 线性拟合 ECS 和 PKS 为 difference_normalized</span><br>    df[<span class="hljs-string">&#x27;difference_normalized&#x27;</span>] = m * df[<span class="hljs-string">&#x27;parameter_knowledge_difference_sum_normalized&#x27;</span>] - alpha * df[<span class="hljs-string">&#x27;external_similarity_sum_normalized&#x27;</span>]<br><br>    <span class="hljs-comment"># 计算 difference_normalized 的 AUC 和 PCC</span><br>    auc_difference_normalized = roc_auc_score(df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], df[<span class="hljs-string">&#x27;difference_normalized&#x27;</span>])<br>    person_difference_normalized, _ = pearsonr(df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], df[<span class="hljs-string">&#x27;difference_normalized&#x27;</span>])<br>    results.update(&#123;<span class="hljs-string">&quot;Normalized Difference AUC&quot;</span>: auc_difference_normalized&#125;)<br>    results.update(&#123;<span class="hljs-string">&quot;Normalized Difference Pearson Correlation&quot;</span>: person_difference_normalized&#125;)<br><br>    <span class="hljs-comment"># 将 token 级别的预测结果转换为 response 级别的评估</span><br>    df[<span class="hljs-string">&#x27;response_group&#x27;</span>] = df[<span class="hljs-string">&#x27;identifier&#x27;</span>].<span class="hljs-built_in">str</span>.extract(<span class="hljs-string">r&#x27;(response_\d+)&#x27;</span>) <span class="hljs-comment"># 只区分 response，忽略 token</span><br>    grouped_df = df.groupby(<span class="hljs-string">&#x27;response_group&#x27;</span>).agg( <span class="hljs-comment"># 按 response_group 分组，对每组内的数据计算聚合统计值</span><br>        difference_normalized_mean=(<span class="hljs-string">&#x27;difference_normalized&#x27;</span>, <span class="hljs-string">&#x27;mean&#x27;</span>), <span class="hljs-comment"># 计算 difference_normalized 的均值</span><br>        hallucination_label=(<span class="hljs-string">&#x27;hallucination_label&#x27;</span>, <span class="hljs-string">&#x27;max&#x27;</span>) <span class="hljs-comment"># 有一个幻觉 token 就表明是幻觉 response</span><br>    ).reset_index()<br>    <br>    <span class="hljs-comment"># 进行归一化</span><br>    min_val = grouped_df[<span class="hljs-string">&#x27;difference_normalized_mean&#x27;</span>].<span class="hljs-built_in">min</span>()<br>    max_val = grouped_df[<span class="hljs-string">&#x27;difference_normalized_mean&#x27;</span>].<span class="hljs-built_in">max</span>()<br>    collect_info.update(&#123;<span class="hljs-string">&#x27;final_max_min&#x27;</span>: [max_val, min_val]&#125;)<br>    grouped_df[<span class="hljs-string">&#x27;difference_normalized_mean_norm&#x27;</span>] = (grouped_df[<span class="hljs-string">&#x27;difference_normalized_mean&#x27;</span>] - min_val) / (max_val - min_val)<br><br>    <span class="hljs-comment"># 计算 response 的 AUC 和 PCC</span><br>    auc_difference_normalized = roc_auc_score(grouped_df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], grouped_df[<span class="hljs-string">&#x27;difference_normalized_mean_norm&#x27;</span>])<br>    person_difference_normalized, _ = pearsonr(grouped_df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], grouped_df[<span class="hljs-string">&#x27;difference_normalized_mean_norm&#x27;</span>])<br><br>    results.update(&#123;<span class="hljs-string">&quot;Grouped means AUC&quot;</span>: auc_difference_normalized&#125;)<br>    results.update(&#123;<span class="hljs-string">&quot;Grouped means Pearson Correlation&quot;</span>: person_difference_normalized&#125;)<br>    <br>    <span class="hljs-built_in">print</span>(collect_info)<br>    <span class="hljs-built_in">print</span>(results)<br>    <span class="hljs-built_in">print</span>(df.iloc[:, <span class="hljs-number">66</span>:])<br>    <span class="hljs-built_in">print</span>(grouped_df)<br>    <br>    <span class="hljs-keyword">return</span> auc_difference_normalized, person_difference_normalized<br><br><span class="hljs-comment"># i：AUC 最高的前 i 个 ECS；j：AUC 最高的前 j 个 PKS</span><br><span class="hljs-comment"># k：ECS 的权重衰减系数 alpha；m：PKS 的权重系数</span><br>i, j, k, m = <span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">1</span><br>auc_difference_normalized, person_difference_normalized = calculate_auc_pcc_32_32(df, i, j, k, auc_external_similarity, auc_parameter_knowledge_difference, m)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[(0.5673763213378886, &#39;external_similarity_25&#39;)]
[(0.5692361568028578, &#39;parameter_knowledge_difference_23&#39;), (0.5659032649245824, &#39;parameter_knowledge_difference_24&#39;), (0.5648406814639895, &#39;parameter_knowledge_difference_21&#39;), (0.5641498623795829, &#39;parameter_knowledge_difference_25&#39;), (0.5637065413888521, &#39;parameter_knowledge_difference_16&#39;), (0.5603452361775584, &#39;parameter_knowledge_difference_17&#39;), (0.559005634263019, &#39;parameter_knowledge_difference_28&#39;), (0.5589974486374809, &#39;parameter_knowledge_difference_18&#39;), (0.5557532354685331, &#39;parameter_knowledge_difference_20&#39;), (0.5528760122772071, &#39;parameter_knowledge_difference_29&#39;)]
&#123;&#39;select_heads&#39;: [[25, 0]], &#39;select_layers&#39;: [23, 24, 21, 25, 16, 17, 28, 18, 20, 29], &#39;head_max_min&#39;: [0.70703125, -0.06622314453125], &#39;layers_max_min&#39;: [403.1658172607422, 0.0], &#39;final_max_min&#39;: [0.019226928463994836, -0.0883788238921643]&#125;
&#123;&#39;Top 1 AUC External Similarity&#39;: 0.5673763213378886, &#39;Top 1 AUC Parameter Knowledge Difference&#39;: 0.583095315694985, &#39;Top 10 Pearson Correlation External Similarity&#39;: 0.05559519158826022, &#39;Top 10 Pearson Correlation Parameter Knowledge Difference&#39;: 0.041942949285387915, &#39;Normalized Difference AUC&#39;: 0.5923123608321358, &#39;Normalized Difference Pearson Correlation&#39;: 0.058753678172965486, &#39;Grouped means AUC&#39;: 0.732498419721871, &#39;Grouped means Pearson Correlation&#39;: 0.39790584030340576&#125;
    external_similarity_sum  parameter_knowledge_difference_sum  \
0                     0.315674                           10.013580   
1                     0.219116                           18.298626   
2                     0.395020                           12.934208   
3                     0.325684                            9.894371   
4                     0.328369                            1.430511   
...                        ...                                 ...   
88401                 0.264160                           10.788441   
88402                 0.242554                           16.868114   
88403                 0.427490                            4.231930   
88404                 0.212402                            6.914139   
88405                 0.335205                           40.113926   

    external_similarity_sum_normalized  \
0                                0.493883   
1                                0.369011   
2                                0.596495   
3                                0.506828   
4                                0.510301   
...                                   ...   
88401                            0.427263   
88402                            0.399321   
88403                            0.638488   
88404                            0.360328   
88405                            0.519141   

    parameter_knowledge_difference_sum_normalized  difference_normalized  \
0                                           0.024837              -0.073939   
1                                           0.045387              -0.028415   
2                                           0.032082              -0.087217   
3                                           0.024542              -0.076824   
4                                           0.003548              -0.098512   
...                                              ...                    ...   
88401                                       0.026759              -0.058693   
88402                                       0.041839              -0.038025   
88403                                       0.010497              -0.117201   
88404                                       0.017150              -0.054916   
88405                                       0.099497              -0.004331   

    response_group  
0         response_0  
1         response_0  
2         response_0  
3         response_0  
4         response_0  
...              ...  
88401   response_449  
88402   response_449  
88403   response_449  
88404   response_449  
88405   response_449  

[88406 rows x 6 columns]
    response_group  difference_normalized_mean  hallucination_label  \
0       response_0                   -0.050396                    0   
1       response_1                   -0.036515                    0   
2      response_10                   -0.028513                    0   
3     response_100                   -0.035463                    0   
4     response_101                   -0.043027                    0   
..             ...                         ...                  ...   
445    response_95                   -0.048167                    1   
446    response_96                    0.005520                    0   
447    response_97                   -0.041191                    0   
448    response_98                   -0.027022                    1   
449    response_99                   -0.025304                    1   

    difference_normalized_mean_norm  
0                           0.352977  
1                           0.481976  
2                           0.556339  
3                           0.491755  
4                           0.421465  
..                               ...  
445                         0.373694  
446                         0.872623  
447                         0.438529  
448                         0.570205  
449                         0.586166  

[450 rows x 4 columns]
</code></pre>
<ol start="6">
<li>查看结果：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">result_dict = &#123;<span class="hljs-string">&quot;auc&quot;</span>: auc_difference_normalized, <span class="hljs-string">&quot;pcc&quot;</span>: person_difference_normalized&#125;<br><span class="hljs-built_in">print</span>(result_dict)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&#123;&#39;auc&#39;: 0.732498419721871, &#39;pcc&#39;: 0.39790584030340576&#125;
</code></pre>
<ol start="7">
<li>保存结果：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">save_path = <span class="hljs-string">&quot;../output/ReDeEP_token.json&quot;</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(save_path, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    json.dump(result_dict, f, ensure_ascii=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>

<h3 id="2-3-2-chunk-级别"><a href="#2-3-2-chunk-级别" class="headerlink" title="2.3.2 chunk 级别"></a>2.3.2 chunk 级别</h3><ol>
<li>导入必要的包：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_auc_score<br><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> pearsonr<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MinMaxScaler<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br></code></pre></td></tr></table></figure>

<ol start="2">
<li>加载 source_info：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">source_info_path = <span class="hljs-string">&quot;../dataset/source_info_chunk.jsonl&quot;</span><br>source_info_dict = &#123;&#125;<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(source_info_path, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>        data = json.loads(line)<br>        source_info_dict[data[<span class="hljs-string">&#x27;source_id&#x27;</span>]] = data<br>        <br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(source_info_dict))<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">2965
</code></pre>
<ol start="3">
<li>构建数据集：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">construct_dataframe</span>(<span class="hljs-params">file_path, number</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        response = json.load(f)  <br><br>    data_dict = &#123;<br>        <span class="hljs-string">&quot;identifier&quot;</span>: [],<br>        <span class="hljs-string">&quot;type&quot;</span>:[], <span class="hljs-comment"># 任务类型</span><br>        **&#123;<span class="hljs-string">f&quot;external_similarity_<span class="hljs-subst">&#123;k&#125;</span>&quot;</span>: [] <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(number)&#125;,<br>        **&#123;<span class="hljs-string">f&quot;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&quot;</span>: [] <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(number)&#125;,<br>        <span class="hljs-string">&quot;hallucination_label&quot;</span>: []<br>    &#125;<br>  <br>    <span class="hljs-keyword">for</span> i, resp <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(response): <span class="hljs-comment"># 遍历每个 response</span><br>        <span class="hljs-keyword">if</span> resp[<span class="hljs-string">&quot;split&quot;</span>] != <span class="hljs-string">&quot;test&quot;</span>:<br>            <span class="hljs-keyword">continue</span><br>        respond_ids = resp[<span class="hljs-string">&quot;source_id&quot;</span>]<br>        rep_type = source_info_dict[respond_ids][<span class="hljs-string">&quot;task_type&quot;</span>] <span class="hljs-comment"># 获取任务类型</span><br><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(resp[<span class="hljs-string">&quot;scores&quot;</span>])): <span class="hljs-comment"># 遍历每个 response 片段</span><br>            data_dict[<span class="hljs-string">&quot;identifier&quot;</span>].append(<span class="hljs-string">f&quot;response_<span class="hljs-subst">&#123;i&#125;</span>_item_<span class="hljs-subst">&#123;j&#125;</span>&quot;</span>)<br>            data_dict[<span class="hljs-string">&quot;type&quot;</span>].append(rep_type)<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(number):<br>                data_dict[<span class="hljs-string">f&quot;external_similarity_<span class="hljs-subst">&#123;k&#125;</span>&quot;</span>].append(<span class="hljs-built_in">list</span>(resp[<span class="hljs-string">&quot;scores&quot;</span>][j][<span class="hljs-string">&quot;prompt_attention_score&quot;</span>].values())[k])<br>                data_dict[<span class="hljs-string">f&quot;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&quot;</span>].append(<span class="hljs-built_in">list</span>(resp[<span class="hljs-string">&quot;scores&quot;</span>][j][<span class="hljs-string">&quot;parameter_knowledge_scores&quot;</span>].values())[k])<br>            data_dict[<span class="hljs-string">&quot;hallucination_label&quot;</span>].append(resp[<span class="hljs-string">&quot;scores&quot;</span>][j][<span class="hljs-string">&quot;hallucination_label&quot;</span>])<br>        <span class="hljs-keyword">if</span> i == <span class="hljs-built_in">len</span>(response)-<span class="hljs-number">1</span>: <span class="hljs-comment"># 记录 copy_heads 和 layers</span><br>            ext_map_dict = &#123;<span class="hljs-string">f&quot;external_similarity_<span class="hljs-subst">&#123;k&#125;</span>&quot;</span>:<span class="hljs-built_in">list</span>(resp[<span class="hljs-string">&quot;scores&quot;</span>][j][<span class="hljs-string">&quot;prompt_attention_score&quot;</span>].keys())[k] <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(number)&#125;<br>            para_map_dict = &#123;<span class="hljs-string">f&quot;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&quot;</span>:<span class="hljs-built_in">list</span>(resp[<span class="hljs-string">&quot;scores&quot;</span>][j][<span class="hljs-string">&quot;parameter_knowledge_scores&quot;</span>].keys())[k] <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(number)&#125;<br><br>    df = pd.DataFrame(data_dict)<br><br>    <span class="hljs-built_in">print</span>(df[<span class="hljs-string">&quot;hallucination_label&quot;</span>].value_counts(normalize=<span class="hljs-literal">True</span>))  <span class="hljs-comment"># 查看幻觉标签的比例</span><br>    <span class="hljs-keyword">return</span> df, ext_map_dict, para_map_dict<br><br>data_path = <span class="hljs-string">&quot;../dataset/llama2_7B_response_chunk.json&quot;</span><br>number = <span class="hljs-number">32</span><br>df, ext_map_dict, para_map_dict = construct_dataframe(data_path, number)<br><span class="hljs-built_in">print</span>(ext_map_dict)<br><span class="hljs-built_in">print</span>(para_map_dict)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">hallucination_label
0    0.748921
1    0.251079
Name: proportion, dtype: float64
&#123;&#39;external_similarity_0&#39;: &#39;(1, 14)&#39;, &#39;external_similarity_1&#39;: &#39;(1, 21)&#39;, &#39;external_similarity_2&#39;: &#39;(1, 27)&#39;, &#39;external_similarity_3&#39;: &#39;(2, 5)&#39;, &#39;external_similarity_4&#39;: &#39;(2, 22)&#39;, &#39;external_similarity_5&#39;: &#39;(3, 0)&#39;, &#39;external_similarity_6&#39;: &#39;(3, 19)&#39;, &#39;external_similarity_7&#39;: &#39;(5, 13)&#39;, &#39;external_similarity_8&#39;: &#39;(5, 29)&#39;, &#39;external_similarity_9&#39;: &#39;(10, 20)&#39;, &#39;external_similarity_10&#39;: &#39;(13, 20)&#39;, &#39;external_similarity_11&#39;: &#39;(15, 7)&#39;, &#39;external_similarity_12&#39;: &#39;(16, 1)&#39;, &#39;external_similarity_13&#39;: &#39;(18, 9)&#39;, &#39;external_similarity_14&#39;: &#39;(18, 10)&#39;, &#39;external_similarity_15&#39;: &#39;(18, 13)&#39;, &#39;external_similarity_16&#39;: &#39;(19, 1)&#39;, &#39;external_similarity_17&#39;: &#39;(20, 1)&#39;, &#39;external_similarity_18&#39;: &#39;(20, 5)&#39;, &#39;external_similarity_19&#39;: &#39;(20, 15)&#39;, &#39;external_similarity_20&#39;: &#39;(20, 17)&#39;, &#39;external_similarity_21&#39;: &#39;(20, 22)&#39;, &#39;external_similarity_22&#39;: &#39;(22, 10)&#39;, &#39;external_similarity_23&#39;: &#39;(23, 8)&#39;, &#39;external_similarity_24&#39;: &#39;(23, 30)&#39;, &#39;external_similarity_25&#39;: &#39;(25, 0)&#39;, &#39;external_similarity_26&#39;: &#39;(27, 9)&#39;, &#39;external_similarity_27&#39;: &#39;(28, 18)&#39;, &#39;external_similarity_28&#39;: &#39;(31, 18)&#39;, &#39;external_similarity_29&#39;: &#39;(31, 19)&#39;, &#39;external_similarity_30&#39;: &#39;(31, 24)&#39;, &#39;external_similarity_31&#39;: &#39;(31, 28)&#39;&#125;
&#123;&#39;parameter_knowledge_difference_0&#39;: &#39;layer_0&#39;, &#39;parameter_knowledge_difference_1&#39;: &#39;layer_1&#39;, &#39;parameter_knowledge_difference_2&#39;: &#39;layer_2&#39;, &#39;parameter_knowledge_difference_3&#39;: &#39;layer_3&#39;, &#39;parameter_knowledge_difference_4&#39;: &#39;layer_4&#39;, &#39;parameter_knowledge_difference_5&#39;: &#39;layer_5&#39;, &#39;parameter_knowledge_difference_6&#39;: &#39;layer_6&#39;, &#39;parameter_knowledge_difference_7&#39;: &#39;layer_7&#39;, &#39;parameter_knowledge_difference_8&#39;: &#39;layer_8&#39;, &#39;parameter_knowledge_difference_9&#39;: &#39;layer_9&#39;, &#39;parameter_knowledge_difference_10&#39;: &#39;layer_10&#39;, &#39;parameter_knowledge_difference_11&#39;: &#39;layer_11&#39;, &#39;parameter_knowledge_difference_12&#39;: &#39;layer_12&#39;, &#39;parameter_knowledge_difference_13&#39;: &#39;layer_13&#39;, &#39;parameter_knowledge_difference_14&#39;: &#39;layer_14&#39;, &#39;parameter_knowledge_difference_15&#39;: &#39;layer_15&#39;, &#39;parameter_knowledge_difference_16&#39;: &#39;layer_16&#39;, &#39;parameter_knowledge_difference_17&#39;: &#39;layer_17&#39;, &#39;parameter_knowledge_difference_18&#39;: &#39;layer_18&#39;, &#39;parameter_knowledge_difference_19&#39;: &#39;layer_19&#39;, &#39;parameter_knowledge_difference_20&#39;: &#39;layer_20&#39;, &#39;parameter_knowledge_difference_21&#39;: &#39;layer_21&#39;, &#39;parameter_knowledge_difference_22&#39;: &#39;layer_22&#39;, &#39;parameter_knowledge_difference_23&#39;: &#39;layer_23&#39;, &#39;parameter_knowledge_difference_24&#39;: &#39;layer_24&#39;, &#39;parameter_knowledge_difference_25&#39;: &#39;layer_25&#39;, &#39;parameter_knowledge_difference_26&#39;: &#39;layer_26&#39;, &#39;parameter_knowledge_difference_27&#39;: &#39;layer_27&#39;, &#39;parameter_knowledge_difference_28&#39;: &#39;layer_28&#39;, &#39;parameter_knowledge_difference_29&#39;: &#39;layer_29&#39;, &#39;parameter_knowledge_difference_30&#39;: &#39;layer_30&#39;, &#39;parameter_knowledge_difference_31&#39;: &#39;layer_31&#39;&#125;
</code></pre>
<ol start="4">
<li>计算 ECS 和 PKS 的 AUC 和 PCC：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_auc_pcc</span>(<span class="hljs-params">df, ext_map_dict, para_map_dict, number</span>):<br>    auc_external_similarity = []<br>    pearson_external_similarity = []<br><br>    auc_parameter_knowledge_difference = []<br>    pearson_parameter_knowledge_difference = []<br><br>    <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(number):<br>        auc_ext = roc_auc_score(<span class="hljs-number">1</span> - df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], df[<span class="hljs-string">f&#x27;external_similarity_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>])<br>        pearson_ext, _ = pearsonr(df[<span class="hljs-string">f&#x27;external_similarity_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>], <span class="hljs-number">1</span> - df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>])<br>        auc_external_similarity.append((auc_ext, <span class="hljs-string">f&#x27;external_similarity_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>))<br>        pearson_external_similarity.append((pearson_ext, <span class="hljs-string">f&#x27;external_similarity_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>))<br><br>        auc_param = roc_auc_score(df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], df[<span class="hljs-string">f&#x27;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>])<br>        <span class="hljs-keyword">if</span> df[<span class="hljs-string">f&#x27;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>].nunique() == <span class="hljs-number">1</span>:<br>            <span class="hljs-built_in">print</span>(k)<br>        pearson_param, _ = pearsonr(df[<span class="hljs-string">f&#x27;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>], df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>])<br>        auc_parameter_knowledge_difference.append((auc_param, <span class="hljs-string">f&#x27;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>))<br>        pearson_parameter_knowledge_difference.append((pearson_param, <span class="hljs-string">f&#x27;parameter_knowledge_difference_<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>))<br>        <br>        <span class="hljs-comment"># 把表头换成对应的 copy_heads 或 layers</span><br>        auc_external_similarity_rename = [[a, ext_map_dict[k]] <span class="hljs-keyword">for</span> a, k <span class="hljs-keyword">in</span> auc_external_similarity]<br>        auc_parameter_knowledge_difference_rename = [[a, para_map_dict[k]] <span class="hljs-keyword">for</span> a, k <span class="hljs-keyword">in</span> auc_parameter_knowledge_difference]<br>    <br>    <span class="hljs-keyword">return</span> auc_external_similarity, auc_external_similarity_rename, auc_parameter_knowledge_difference, auc_parameter_knowledge_difference_rename<br><br>auc_external_similarity, _, auc_parameter_knowledge_difference, _ = calculate_auc_pcc(df, ext_map_dict, para_map_dict, number)<br><span class="hljs-built_in">print</span>(auc_external_similarity)<br><span class="hljs-built_in">print</span>(auc_parameter_knowledge_difference)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[(0.5417913756789713, &#39;external_similarity_0&#39;), (0.5143078847767907, &#39;external_similarity_1&#39;), (0.5400969167181339, &#39;external_similarity_2&#39;), (0.5450100559013096, &#39;external_similarity_3&#39;), (0.5260186548846342, &#39;external_similarity_4&#39;), (0.5401800560596703, &#39;external_similarity_5&#39;), (0.5466134574880834, &#39;external_similarity_6&#39;), (0.5124511061491441, &#39;external_similarity_7&#39;), (0.4991488115033177, &#39;external_similarity_8&#39;), (0.523128573012178, &#39;external_similarity_9&#39;), (0.5573978177902355, &#39;external_similarity_10&#39;), (0.530745720303419, &#39;external_similarity_11&#39;), (0.5855345463759165, &#39;external_similarity_12&#39;), (0.5388973347902513, &#39;external_similarity_13&#39;), (0.5480901705544206, &#39;external_similarity_14&#39;), (0.5474488099197111, &#39;external_similarity_15&#39;), (0.5465342771628106, &#39;external_similarity_16&#39;), (0.5572513341884808, &#39;external_similarity_17&#39;), (0.5647813831219219, &#39;external_similarity_18&#39;), (0.608108857111185, &#39;external_similarity_19&#39;), (0.5305081793276007, &#39;external_similarity_20&#39;), (0.5807520547294408, &#39;external_similarity_21&#39;), (0.5671765879614233, &#39;external_similarity_22&#39;), (0.5516018179802683, &#39;external_similarity_23&#39;), (0.4836096726685353, &#39;external_similarity_24&#39;), (0.531842367808447, &#39;external_similarity_25&#39;), (0.5856137267011893, &#39;external_similarity_26&#39;), (0.5822010546819326, &#39;external_similarity_27&#39;), (0.6184379305430188, &#39;external_similarity_28&#39;), (0.5941652018306491, &#39;external_similarity_29&#39;), (0.6002462508115983, &#39;external_similarity_30&#39;), (0.586021505376344, &#39;external_similarity_31&#39;)]
[(0.6850483791787416, &#39;parameter_knowledge_difference_0&#39;), (0.6821503792737581, &#39;parameter_knowledge_difference_1&#39;), (0.6848246947598461, &#39;parameter_knowledge_difference_2&#39;), (0.6746480434541626, &#39;parameter_knowledge_difference_3&#39;), (0.675837727841386, &#39;parameter_knowledge_difference_4&#39;), (0.6899852724594993, &#39;parameter_knowledge_difference_5&#39;), (0.6916282642089093, &#39;parameter_knowledge_difference_6&#39;), (0.6975430345067857, &#39;parameter_knowledge_difference_7&#39;), (0.6916005510950639, &#39;parameter_knowledge_difference_8&#39;), (0.6826294202416584, &#39;parameter_knowledge_difference_9&#39;), (0.6991484156016913, &#39;parameter_knowledge_difference_10&#39;), (0.6927130346651464, &#39;parameter_knowledge_difference_11&#39;), (0.6973252886122856, &#39;parameter_knowledge_difference_12&#39;), (0.7113124930717214, &#39;parameter_knowledge_difference_13&#39;), (0.7076820751579647, &#39;parameter_knowledge_difference_14&#39;), (0.704795952301772, &#39;parameter_knowledge_difference_15&#39;), (0.7249156729535846, &#39;parameter_knowledge_difference_16&#39;), (0.732604082537571, &#39;parameter_knowledge_difference_17&#39;), (0.7431350657988504, &#39;parameter_knowledge_difference_18&#39;), (0.6827204776157221, &#39;parameter_knowledge_difference_19&#39;), (0.7435863936529051, &#39;parameter_knowledge_difference_20&#39;), (0.7425926805707317, &#39;parameter_knowledge_difference_21&#39;), (0.7210318779989547, &#39;parameter_knowledge_difference_22&#39;), (0.7266378450282674, &#39;parameter_knowledge_difference_23&#39;), (0.7004766655581421, &#39;parameter_knowledge_difference_24&#39;), (0.6884056249703074, &#39;parameter_knowledge_difference_25&#39;), (0.6712710025812786, &#39;parameter_knowledge_difference_26&#39;), (0.6899971495082903, &#39;parameter_knowledge_difference_27&#39;), (0.686271715204206, &#39;parameter_knowledge_difference_28&#39;), (0.7507324180087731, &#39;parameter_knowledge_difference_29&#39;), (0.7555505408016215, &#39;parameter_knowledge_difference_30&#39;), (0.691774747810664, &#39;parameter_knowledge_difference_31&#39;)]
</code></pre>
<ol start="5">
<li>计算 response 的 AUC 和 PCC：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_auc_pcc_32_32</span>(<span class="hljs-params">df, top_n, top_k, alpha, auc_external_similarity, auc_parameter_knowledge_difference, m=<span class="hljs-number">1</span></span>):<br>    top_auc_external_similarity = <span class="hljs-built_in">sorted</span>(auc_external_similarity, reverse=<span class="hljs-literal">True</span>)[:top_n]<br>    <span class="hljs-built_in">print</span>(top_auc_external_similarity)<br>    <br>    top_auc_parameter_knowledge_difference = <span class="hljs-built_in">sorted</span>(auc_parameter_knowledge_difference, reverse=<span class="hljs-literal">True</span>)[:top_k]<br>    <span class="hljs-built_in">print</span>(top_auc_parameter_knowledge_difference)<br>    <br>    df[<span class="hljs-string">&#x27;external_similarity_sum&#x27;</span>] = df[[col <span class="hljs-keyword">for</span> _, col <span class="hljs-keyword">in</span> top_auc_external_similarity]].<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>)<br>    df[<span class="hljs-string">&#x27;parameter_knowledge_difference_sum&#x27;</span>] = df[[col <span class="hljs-keyword">for</span> _, col <span class="hljs-keyword">in</span> top_auc_parameter_knowledge_difference]].<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>)<br><br>    final_auc_external_similarity = roc_auc_score(<span class="hljs-number">1</span> - df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], df[<span class="hljs-string">&#x27;external_similarity_sum&#x27;</span>])<br>    final_auc_parameter_knowledge_difference = roc_auc_score(df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], df[<span class="hljs-string">&#x27;parameter_knowledge_difference_sum&#x27;</span>])<br><br>    final_pearson_external_similarity, _ = pearsonr(df[<span class="hljs-string">&#x27;external_similarity_sum&#x27;</span>], <span class="hljs-number">1</span> - df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>])<br>    final_pearson_parameter_knowledge_difference, _ = pearsonr(df[<span class="hljs-string">&#x27;parameter_knowledge_difference_sum&#x27;</span>], df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>])<br><br>    results = &#123;<br>        <span class="hljs-string">f&quot;Top <span class="hljs-subst">&#123;top_n&#125;</span> AUC External Similarity&quot;</span>: final_auc_external_similarity,<br>        <span class="hljs-string">f&quot;Top <span class="hljs-subst">&#123;top_k&#125;</span> N AUC Parameter Knowledge Difference&quot;</span>: final_auc_parameter_knowledge_difference,<br>        <span class="hljs-string">f&quot;Top <span class="hljs-subst">&#123;top_n&#125;</span> Pearson Correlation External Similarity&quot;</span>: final_pearson_external_similarity,<br>        <span class="hljs-string">f&quot;Top <span class="hljs-subst">&#123;top_k&#125;</span> Pearson Correlation Parameter Knowledge Difference&quot;</span>: final_pearson_parameter_knowledge_difference<br>    &#125;<br><br>    scaler = MinMaxScaler()<br>    <br>    df[<span class="hljs-string">&#x27;external_similarity_sum_normalized&#x27;</span>] = scaler.fit_transform(df[[<span class="hljs-string">&#x27;external_similarity_sum&#x27;</span>]])<br>    <br>    df[<span class="hljs-string">&#x27;parameter_knowledge_difference_sum_normalized&#x27;</span>] = scaler.fit_transform(df[[<span class="hljs-string">&#x27;parameter_knowledge_difference_sum&#x27;</span>]])<br><br>    df[<span class="hljs-string">&#x27;difference_normalized&#x27;</span>] = m * df[<span class="hljs-string">&#x27;parameter_knowledge_difference_sum_normalized&#x27;</span>] - alpha * df[<span class="hljs-string">&#x27;external_similarity_sum_normalized&#x27;</span>]<br><br>    auc_difference_normalized = roc_auc_score(df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], df[<span class="hljs-string">&#x27;difference_normalized&#x27;</span>])<br>    person_difference_normalized, _ = pearsonr(df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], df[<span class="hljs-string">&#x27;difference_normalized&#x27;</span>])<br>    <br>    results.update(&#123;<span class="hljs-string">&quot;Normalized Difference AUC&quot;</span>: auc_difference_normalized&#125;)<br>    results.update(&#123;<span class="hljs-string">&quot;Normalized Difference Pearson Correlation&quot;</span>: person_difference_normalized&#125;)<br><br>    df[<span class="hljs-string">&#x27;response_group&#x27;</span>] = df[<span class="hljs-string">&#x27;identifier&#x27;</span>].<span class="hljs-built_in">str</span>.extract(<span class="hljs-string">r&#x27;(response_\d+)&#x27;</span>)<br>    grouped_df = df.groupby(<span class="hljs-string">&#x27;response_group&#x27;</span>).agg(<br>        difference_normalized_mean=(<span class="hljs-string">&#x27;difference_normalized&#x27;</span>, <span class="hljs-string">&#x27;mean&#x27;</span>),<br>        hallucination_label=(<span class="hljs-string">&#x27;hallucination_label&#x27;</span>, <span class="hljs-string">&#x27;max&#x27;</span>),<br>        resp_type=(<span class="hljs-string">&#x27;type&#x27;</span>, <span class="hljs-string">&#x27;first&#x27;</span>)<br>    ).reset_index()<br>    <br>    min_val = grouped_df[<span class="hljs-string">&#x27;difference_normalized_mean&#x27;</span>].<span class="hljs-built_in">min</span>()<br>    max_val = grouped_df[<span class="hljs-string">&#x27;difference_normalized_mean&#x27;</span>].<span class="hljs-built_in">max</span>()<br>    grouped_df[<span class="hljs-string">&#x27;difference_normalized_mean_norm&#x27;</span>] = (grouped_df[<span class="hljs-string">&#x27;difference_normalized_mean&#x27;</span>] - min_val) / (max_val - min_val)<br><br>    auc_difference_normalized = roc_auc_score(grouped_df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], grouped_df[<span class="hljs-string">&#x27;difference_normalized_mean_norm&#x27;</span>])<br>    person_difference_normalized, _ = pearsonr(grouped_df[<span class="hljs-string">&#x27;hallucination_label&#x27;</span>], grouped_df[<span class="hljs-string">&#x27;difference_normalized_mean_norm&#x27;</span>])<br><br>    results.update(&#123;<span class="hljs-string">&quot;Grouped means AUC&quot;</span>: auc_difference_normalized&#125;)<br>    results.update(&#123;<span class="hljs-string">&quot;Grouped means Pearson Correlation&quot;</span>: person_difference_normalized&#125;)<br><br>    <span class="hljs-built_in">print</span>(results)<br>    <span class="hljs-built_in">print</span>(df.iloc[:, <span class="hljs-number">67</span>:])<br>    <span class="hljs-built_in">print</span>(grouped_df)<br><br>    <span class="hljs-keyword">return</span> auc_difference_normalized, person_difference_normalized<br><br>i, j, k, m = <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">0.6</span>, <span class="hljs-number">1</span><br>auc_difference_normalized, person_difference_normalized = calculate_auc_pcc_32_32(df, i, j, k, auc_external_similarity, auc_parameter_knowledge_difference, m)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[(0.6184379305430188, &#39;external_similarity_28&#39;), (0.608108857111185, &#39;external_similarity_19&#39;), (0.6002462508115983, &#39;external_similarity_30&#39;)]
[(0.7555505408016215, &#39;parameter_knowledge_difference_30&#39;), (0.7507324180087731, &#39;parameter_knowledge_difference_29&#39;), (0.7435863936529051, &#39;parameter_knowledge_difference_20&#39;), (0.7431350657988504, &#39;parameter_knowledge_difference_18&#39;)]
&#123;&#39;Top 3 AUC External Similarity&#39;: 0.6122024799277875, &#39;Top 4 N AUC Parameter Knowledge Difference&#39;: 0.7696604747652304, &#39;Top 3 Pearson Correlation External Similarity&#39;: 0.1803052828551513, &#39;Top 4 Pearson Correlation Parameter Knowledge Difference&#39;: 0.41798093066978415, &#39;Normalized Difference AUC&#39;: 0.7716399828970497, &#39;Normalized Difference Pearson Correlation&#39;: 0.4246730120824572, &#39;Grouped means AUC&#39;: 0.747451801517067, &#39;Grouped means Pearson Correlation&#39;: 0.42077140374980926&#125;
    external_similarity_sum  parameter_knowledge_difference_sum  \
0                    2.803634                           25.189286   
1                    2.527066                           29.186299   
2                    1.762983                           14.667820   
3                    2.516881                           30.397039   
4                    1.768611                           39.194237   
...                       ...                                 ...   
1154                 2.443222                           28.610018   
1155                 2.540920                            4.499433   
1156                 2.376156                           26.957270   
1157                 2.114817                            6.117686   
1158                 2.275002                            7.565648   

    external_similarity_sum_normalized  \
0                               0.915263   
1                               0.766601   
2                               0.355887   
3                               0.761126   
4                               0.358912   
...                                  ...   
1154                            0.721533   
1155                            0.774048   
1156                            0.685483   
1157                            0.545007   
1158                            0.631110   

    parameter_knowledge_difference_sum_normalized  difference_normalized  \
0                                          0.349987              -0.199171   
1                                          0.405634              -0.054326   
2                                          0.203504              -0.010028   
3                                          0.422491              -0.034185   
4                                          0.544968               0.329620   
...                                             ...                    ...   
1154                                       0.397611              -0.035308   
1155                                       0.061937              -0.402491   
1156                                       0.374601              -0.036689   
1157                                       0.084467              -0.242537   
1158                                       0.104626              -0.274040   

    response_group  
0        response_0  
1        response_1  
2        response_1  
3        response_2  
4        response_2  
...             ...  
1154   response_448  
1155   response_449  
1156   response_449  
1157   response_449  
1158   response_449  

[1159 rows x 6 columns]
    response_group  difference_normalized_mean  hallucination_label resp_type  \
0       response_0                   -0.199171                    0   Summary   
1       response_1                   -0.032177                    0   Summary   
2      response_10                   -0.053839                    0   Summary   
3     response_100                   -0.064660                    0   Summary   
4     response_101                   -0.007987                    0   Summary   
..             ...                         ...                  ...       ...   
445    response_95                    0.040043                    1   Summary   
446    response_96                   -0.003845                    0   Summary   
447    response_97                   -0.021714                    0   Summary   
448    response_98                    0.045525                    1   Summary   
449    response_99                   -0.075167                    1   Summary   

    difference_normalized_mean_norm  
0                           0.153055  
1                           0.311814  
2                           0.291220  
3                           0.280932  
4                           0.334811  
..                               ...  
445                         0.380473  
446                         0.338749  
447                         0.321761  
448                         0.385684  
449                         0.270944  

[450 rows x 5 columns]
</code></pre>
<ol start="6">
<li>查看结果：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">result_dict = &#123;<span class="hljs-string">&quot;auc&quot;</span>:auc_difference_normalized, <span class="hljs-string">&quot;pcc&quot;</span>: person_difference_normalized&#125;<br><span class="hljs-built_in">print</span>(result_dict)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&#123;&#39;auc&#39;: 0.747451801517067, &#39;pcc&#39;: 0.42077140374980926&#125;
</code></pre>
<ol start="7">
<li>保存结果：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">save_path = <span class="hljs-string">&quot;../output/ReDeEP_chunk.json&quot;</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(save_path, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    json.dump(result_dict, f, ensure_ascii=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>

<h2 id="2-4-AARF-py"><a href="#2-4-AARF-py" class="headerlink" title="2.4 AARF.py"></a>2.4 AARF.py</h2><ol>
<li>导入必要的包：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br>sys.path.insert(<span class="hljs-number">0</span>, <span class="hljs-string">&#x27;../transformers/src&#x27;</span>)<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM<br></code></pre></td></tr></table></figure>

<ol start="2">
<li>加载 source_info：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">source_info_path = <span class="hljs-string">&quot;../dataset/source_info.jsonl&quot;</span><br>source_info_dict = &#123;&#125;<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(source_info_path, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>        data = json.loads(line)<br>        source_info_dict[data[<span class="hljs-string">&#x27;source_id&#x27;</span>]] = data<br>        <br><span class="hljs-built_in">print</span>(json.dumps(source_info_dict, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&#123;
    &quot;15596&quot;: &#123;
        &quot;source_id&quot;: &quot;15596&quot;,
        &quot;task_type&quot;: &quot;Summary&quot;,
        &quot;source&quot;: &quot;CNN/DM&quot;,
        &quot;source_info&quot;: &quot;The FBI charged a Philadelphia woman on Thursday with trying to travel overseas to fight for ISIS. She&#39;s one of three women arrested this week on terror charges. Two New York women were also taken into custody. An FBI complaint cites numerous social media messages dating back to August 2013 that were sent by Keonna Thomas, 30, also known as \&quot;Young Lioness\&quot; and \&quot;Fatayat Al Khilafah.\&quot; One Twitter message said, \&quot;If we truly knew the realities ... we all would be rushing to join our brothers in the front lines pray ALLAH accept us as shuhada [martyrs].\&quot; Another said, \&quot;When you&#39;re a mujahid [violent jihadi fighter] your death becomes a wedding.\&quot; The FBI said Thomas purchased an electronic visa to Turkey on March 23. Turkey is known as the easiest place from which to enter Syria and join ISIS. An ISIS manual advises recruits to buy round-trip tickets to vacation spots such as Spain and then purchase tickets for their real destination once they arrive overseas, the FBI said. On March 26, Thomas purchased a ticket to Barcelona, with a March 29 departure and an April 15 return to the United States, the complaint said. It&#39;s not clear when or where she was arrested. She was charged with knowingly attempting to provide material support and resources to a designated foreign terrorist organization. She could be sentenced to 15 years in prison. On Thursday, Noelle Velentzas, 28, and her former roommate, Asia Siddiqui, 31, were arrested in New York and accused of planning to build an explosive device for attacks in the United States, federal prosecutors said. In the past 18 months, the Justice Department&#39;s National Security Division has prosecuted or is prosecuting more than 30 cases of people attempting to travel abroad to join or provide support to terrorist groups. Of those cases, 18 allegedly involve support to ISIS. \&quot;The terrorist threat is more decentralized, more diffuse, more complicated,\&quot; Homeland Security Secretary Jeh Johnson told reporters Thursday. \&quot;It involves the potential lone wolf actor, it involves the effective use of social media, the Internet.\&quot;\n&quot;,
        &quot;prompt&quot;: &quot;Summarize the following news within 86 words:\nThe FBI charged a Philadelphia woman on Thursday with trying to travel overseas to fight for ISIS. She&#39;s one of three women arrested this week on terror charges. Two New York women were also taken into custody. An FBI complaint cites numerous social media messages dating back to August 2013 that were sent by Keonna Thomas, 30, also known as \&quot;Young Lioness\&quot; and \&quot;Fatayat Al Khilafah.\&quot; One Twitter message said, \&quot;If we truly knew the realities ... we all would be rushing to join our brothers in the front lines pray ALLAH accept us as shuhada [martyrs].\&quot; Another said, \&quot;When you&#39;re a mujahid [violent jihadi fighter] your death becomes a wedding.\&quot; The FBI said Thomas purchased an electronic visa to Turkey on March 23. Turkey is known as the easiest place from which to enter Syria and join ISIS. An ISIS manual advises recruits to buy round-trip tickets to vacation spots such as Spain and then purchase tickets for their real destination once they arrive overseas, the FBI said. On March 26, Thomas purchased a ticket to Barcelona, with a March 29 departure and an April 15 return to the United States, the complaint said. It&#39;s not clear when or where she was arrested. She was charged with knowingly attempting to provide material support and resources to a designated foreign terrorist organization. She could be sentenced to 15 years in prison. On Thursday, Noelle Velentzas, 28, and her former roommate, Asia Siddiqui, 31, were arrested in New York and accused of planning to build an explosive device for attacks in the United States, federal prosecutors said. In the past 18 months, the Justice Department&#39;s National Security Division has prosecuted or is prosecuting more than 30 cases of people attempting to travel abroad to join or provide support to terrorist groups. Of those cases, 18 allegedly involve support to ISIS. \&quot;The terrorist threat is more decentralized, more diffuse, more complicated,\&quot; Homeland Security Secretary Jeh Johnson told reporters Thursday. \&quot;It involves the potential lone wolf actor, it involves the effective use of social media, the Internet.\&quot;\n\noutput:&quot;
    &#125;
&#125;
</code></pre>
<ol start="3">
<li>获取 reponse 的 source_id：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">source_id_list = []<br><br>response_path = <span class="hljs-string">&quot;../dataset/response.jsonl&quot;</span><br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(response_path, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>        data = json.loads(line)<br>        <span class="hljs-keyword">if</span> data[<span class="hljs-string">&quot;split&quot;</span>] == <span class="hljs-string">&quot;test&quot;</span>:<br>            source_id_list.append(data[<span class="hljs-string">&quot;source_id&quot;</span>])<br>            <br><span class="hljs-built_in">print</span>(json.dumps(source_id_list, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[
    &quot;15596&quot;
]
</code></pre>
<ol start="4">
<li>获取 source_id 对应的 source_info：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">test_datas_dict = &#123;&#125;<br><br><br>source_id_set = <span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(source_id_list)))<br><br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> source_id_set:<br>    test_datas_dict[item] = source_info_dict[item]<br>    <br><span class="hljs-built_in">print</span>(json.dumps(test_datas_dict, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&#123;
    &quot;15596&quot;: &#123;
        &quot;source_id&quot;: &quot;15596&quot;,
        &quot;task_type&quot;: &quot;Summary&quot;,
        &quot;source&quot;: &quot;CNN/DM&quot;,
        &quot;source_info&quot;: &quot;The FBI charged a Philadelphia woman on Thursday with trying to travel overseas to fight for ISIS. She&#39;s one of three women arrested this week on terror charges. Two New York women were also taken into custody. An FBI complaint cites numerous social media messages dating back to August 2013 that were sent by Keonna Thomas, 30, also known as \&quot;Young Lioness\&quot; and \&quot;Fatayat Al Khilafah.\&quot; One Twitter message said, \&quot;If we truly knew the realities ... we all would be rushing to join our brothers in the front lines pray ALLAH accept us as shuhada [martyrs].\&quot; Another said, \&quot;When you&#39;re a mujahid [violent jihadi fighter] your death becomes a wedding.\&quot; The FBI said Thomas purchased an electronic visa to Turkey on March 23. Turkey is known as the easiest place from which to enter Syria and join ISIS. An ISIS manual advises recruits to buy round-trip tickets to vacation spots such as Spain and then purchase tickets for their real destination once they arrive overseas, the FBI said. On March 26, Thomas purchased a ticket to Barcelona, with a March 29 departure and an April 15 return to the United States, the complaint said. It&#39;s not clear when or where she was arrested. She was charged with knowingly attempting to provide material support and resources to a designated foreign terrorist organization. She could be sentenced to 15 years in prison. On Thursday, Noelle Velentzas, 28, and her former roommate, Asia Siddiqui, 31, were arrested in New York and accused of planning to build an explosive device for attacks in the United States, federal prosecutors said. In the past 18 months, the Justice Department&#39;s National Security Division has prosecuted or is prosecuting more than 30 cases of people attempting to travel abroad to join or provide support to terrorist groups. Of those cases, 18 allegedly involve support to ISIS. \&quot;The terrorist threat is more decentralized, more diffuse, more complicated,\&quot; Homeland Security Secretary Jeh Johnson told reporters Thursday. \&quot;It involves the potential lone wolf actor, it involves the effective use of social media, the Internet.\&quot;\n&quot;,
        &quot;prompt&quot;: &quot;Summarize the following news within 86 words:\nThe FBI charged a Philadelphia woman on Thursday with trying to travel overseas to fight for ISIS. She&#39;s one of three women arrested this week on terror charges. Two New York women were also taken into custody. An FBI complaint cites numerous social media messages dating back to August 2013 that were sent by Keonna Thomas, 30, also known as \&quot;Young Lioness\&quot; and \&quot;Fatayat Al Khilafah.\&quot; One Twitter message said, \&quot;If we truly knew the realities ... we all would be rushing to join our brothers in the front lines pray ALLAH accept us as shuhada [martyrs].\&quot; Another said, \&quot;When you&#39;re a mujahid [violent jihadi fighter] your death becomes a wedding.\&quot; The FBI said Thomas purchased an electronic visa to Turkey on March 23. Turkey is known as the easiest place from which to enter Syria and join ISIS. An ISIS manual advises recruits to buy round-trip tickets to vacation spots such as Spain and then purchase tickets for their real destination once they arrive overseas, the FBI said. On March 26, Thomas purchased a ticket to Barcelona, with a March 29 departure and an April 15 return to the United States, the complaint said. It&#39;s not clear when or where she was arrested. She was charged with knowingly attempting to provide material support and resources to a designated foreign terrorist organization. She could be sentenced to 15 years in prison. On Thursday, Noelle Velentzas, 28, and her former roommate, Asia Siddiqui, 31, were arrested in New York and accused of planning to build an explosive device for attacks in the United States, federal prosecutors said. In the past 18 months, the Justice Department&#39;s National Security Division has prosecuted or is prosecuting more than 30 cases of people attempting to travel abroad to join or provide support to terrorist groups. Of those cases, 18 allegedly involve support to ISIS. \&quot;The terrorist threat is more decentralized, more diffuse, more complicated,\&quot; Homeland Security Secretary Jeh Johnson told reporters Thursday. \&quot;It involves the potential lone wolf actor, it involves the effective use of social media, the Internet.\&quot;\n\noutput:&quot;
    &#125;
&#125;
</code></pre>
<ol start="5">
<li>加载超参数：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">save_path = <span class="hljs-string">&quot;../dataset/token_hyperparameter.json&quot;</span><br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(save_path, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    hypter_parameter = json.load(f)<br>    <br>hypter_parameter<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&#123;&#39;select_heads&#39;: [[25, 0]],
&#39;select_layers&#39;: [23, 24, 21, 25, 16, 17, 28, 18, 20, 29],
&#39;head_max_min&#39;: [0.70703125, -0.06622314453125],
&#39;layers_max_min&#39;: [403.1658172607422, 0.0],
&#39;final_max_min&#39;: [0.019226928463994836, -0.0883788238921643],
&#39;weight&#39;: 0.2&#125;
</code></pre>
<ol start="6">
<li>定义变量：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">select_layers = hypter_parameter[<span class="hljs-string">&quot;select_layers&quot;</span>]<br>select_heads = hypter_parameter[<span class="hljs-string">&quot;select_heads&quot;</span>]<br>layers_max_min = hypter_parameter[<span class="hljs-string">&quot;layers_max_min&quot;</span>]<br>head_max_min  = hypter_parameter[<span class="hljs-string">&quot;head_max_min&quot;</span>]<br>weight = hypter_parameter[<span class="hljs-string">&quot;weight&quot;</span>]<br>final_max_min = hypter_parameter[<span class="hljs-string">&quot;final_max_min&quot;</span>]<br><br>data_type = <span class="hljs-string">&quot;llama-2-7b-chat&quot;</span><br><br>model_name = <span class="hljs-string">&quot;../../model/Llama-2-7b-chat-hf&quot;</span><br>tokenizer = AutoTokenizer.from_pretrained(model_name)<br></code></pre></td></tr></table></figure>

<ol start="7">
<li>加载模型：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">model = AutoModelForCausalLM.from_pretrained(<br>        model_name,<br>        torch_dtype=torch.float16,<br>        device_map=<span class="hljs-string">&quot;auto&quot;</span>,<br>        select_layers=select_layers,<br>        select_heads=select_heads,<br>        layers_max_min=layers_max_min,<br>        head_max_min=head_max_min,<br>        weight=weight,<br>        final_max_min=final_max_min<br>    )<br>model.add_attention_weight = <span class="hljs-number">1.2</span><br>model.reduce_ffn_weight = <span class="hljs-number">0.8</span><br>model.threshold = <span class="hljs-number">0.6</span><br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">Loading checkpoint shards: 100%|██████████| 2/2 [00:45&lt;00:00, 22.97s/it]
</code></pre>
<ol start="8">
<li>构造模型输入：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">add_special_template</span>(<span class="hljs-params">prompt</span>):<br>    messages = [<br>                &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>&#125;,<br>                &#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: prompt&#125;<br>            ]<br>    text = tokenizer.apply_chat_template(<br>        messages,<br>        tokenize=<span class="hljs-literal">False</span>,<br>        add_generation_prompt=<span class="hljs-literal">True</span>,<br>    )<br>    <span class="hljs-keyword">return</span> text<br><br>final_datas = []<br></code></pre></td></tr></table></figure>

<ol start="9">
<li>执行模型推理：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> key, prompt <span class="hljs-keyword">in</span> tqdm(test_datas_dict.items()):<br>    text = add_special_template(prompt[<span class="hljs-string">&quot;prompt&quot;</span>][:<span class="hljs-number">8000</span>])<br>    input_ids = tokenizer(text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids.to(<span class="hljs-string">&quot;cuda&quot;</span>)<br>    model.prefix_len = input_ids.shape[-<span class="hljs-number">1</span>]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;input_ids&quot;</span>, input_ids.shape)<br>    outputs = model.generate(<br>        input_ids,<br>        do_sample=<span class="hljs-literal">False</span>,<br>        temperature=<span class="hljs-literal">None</span>,<br>        top_p=<span class="hljs-literal">None</span>,<br>        max_new_tokens=<span class="hljs-number">1024</span><br>    )<br><br>    response = outputs[<span class="hljs-number">0</span>][input_ids.shape[-<span class="hljs-number">1</span>]:]<br>    result = tokenizer.decode(response, skip_special_tokens=<span class="hljs-literal">True</span>)<br>    <span class="hljs-built_in">print</span>(result)<br>    final_datas.append(&#123;<span class="hljs-string">&quot;id&quot;</span>:key, <span class="hljs-string">&quot;prompt&quot;</span>:prompt[<span class="hljs-string">&quot;prompt&quot;</span>], <span class="hljs-string">&quot;response&quot;</span>:result&#125;)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">0%|          | 0/1 [00:00&lt;?, ?it/s]
input_ids torch.Size([1, 564])
100%|██████████| 1/1 [00:07&lt;00:00,  7.60s/it]
FBI charges Philadelphia woman, Keonna Thomas, with attempting to provide material support to ISIS. She purchased an electronic visa to Turkey and had social media messages expressing desire to join ISIS. Two other women were arrested in New York on similar charges. The FBI has prosecuted or is prosecuting over 30 cases of people attempting to travel abroad to join or provide support to terrorist groups, with 18 involving ISIS.
</code></pre>
<ol start="10">
<li>保存并查看结果：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">f&quot;../output/AARF_add_<span class="hljs-subst">&#123;model.add_attention_weight&#125;</span>_reduce_<span class="hljs-subst">&#123;model.reduce_ffn_weight&#125;</span>_threshold_<span class="hljs-subst">&#123;model.threshold&#125;</span>.json&quot;</span>, <span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    json.dump(final_datas, f, indent=<span class="hljs-number">4</span>, ensure_ascii=<span class="hljs-literal">False</span>)<br>final_datas<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[&#123;&#39;id&#39;: &#39;15596&#39;,
&#39;prompt&#39;: &#39;Summarize the following news within 86 words:\nThe FBI charged a Philadelphia woman on Thursday with trying to travel overseas to fight for ISIS. She\&#39;s one of three women arrested this week on terror charges. Two New York women were also taken into custody. An FBI complaint cites numerous social media messages dating back to August 2013 that were sent by Keonna Thomas, 30, also known as &quot;Young Lioness&quot; and &quot;Fatayat Al Khilafah.&quot; One Twitter message said, &quot;If we truly knew the realities ... we all would be rushing to join our brothers in the front lines pray ALLAH accept us as shuhada [martyrs].&quot; Another said, &quot;When you\&#39;re a mujahid [violent jihadi fighter] your death becomes a wedding.&quot; The FBI said Thomas purchased an electronic visa to Turkey on March 23. Turkey is known as the easiest place from which to enter Syria and join ISIS. An ISIS manual advises recruits to buy round-trip tickets to vacation spots such as Spain and then purchase tickets for their real destination once they arrive overseas, the FBI said. On March 26, Thomas purchased a ticket to Barcelona, with a March 29 departure and an April 15 return to the United States, the complaint said. It\&#39;s not clear when or where she was arrested. She was charged with knowingly attempting to provide material support and resources to a designated foreign terrorist organization. She could be sentenced to 15 years in prison. On Thursday, Noelle Velentzas, 28, and her former roommate, Asia Siddiqui, 31, were arrested in New York and accused of planning to build an explosive device for attacks in the United States, federal prosecutors said. In the past 18 months, the Justice Department\&#39;s National Security Division has prosecuted or is prosecuting more than 30 cases of people attempting to travel abroad to join or provide support to terrorist groups. Of those cases, 18 allegedly involve support to ISIS. &quot;The terrorist threat is more decentralized, more diffuse, more complicated,&quot; Homeland Security Secretary Jeh Johnson told reporters Thursday. &quot;It involves the potential lone wolf actor, it involves the effective use of social media, the Internet.&quot;\n\noutput:&#39;,
&#39;response&#39;: &#39; FBI charges Philadelphia woman, Keonna Thomas, with attempting to provide material support to ISIS. She purchased an electronic visa to Turkey and had social media messages expressing desire to join ISIS. Two other women were arrested in New York on similar charges. The FBI has prosecuted or is prosecuting over 30 cases of people attempting to travel abroad to join or provide support to terrorist groups, with 18 involving ISIS.&#39;&#125;]
</code></pre>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/" class="category-chain-item">代码复现</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/RAG/" class="print-no-link">#RAG</a>
      
        <a href="/tags/LLM/" class="print-no-link">#LLM</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>【论文复现】ReDeEP</div>
      <div>http://xuan-van.github.io/代码复现/【论文复现】redeep/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>文晋</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年5月27日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="NC - 非商业性使用">
                    <i class="iconfont icon-cc-nc"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - 相同方式共享">
                    <i class="iconfont icon-cc-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91xrag/" title="【论文复现】xRAG">
                        <span class="hidden-mobile">【论文复现】xRAG</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.utils.listenDOMLoaded(function() {
      Fluid.events.registerRefreshCallback(function() {
        if ('mermaid' in window) {
          mermaid.init();
        }
      });
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>




  
<script src="/background/background.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<!-- hexo injector body_end start --><script src="/background/background.js"></script><!-- hexo injector body_end end --></body>
</html>
