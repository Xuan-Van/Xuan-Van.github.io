

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/background/%E5%9B%BE%E6%A0%87.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="文晋">
  <meta name="keywords" content="">
  
    <meta name="description" content=".weplofdmtera{}   模型结构：   参考项目：Hannibal046&#x2F;xRAG 1 安装1.1 虚拟环境12345conda create -n xrag python&#x3D;3.9pip install torch&#x3D;&#x3D;2.1.1 transformers&#x3D;&#x3D;4.38.0 accelerate&#x3D;&#x3D;0.27.2 datasets&#x3D;&#x3D;2.17.1 deepspeed&#x3D;&#x3D;0">
<meta property="og:type" content="article">
<meta property="og:title" content="【论文复现】xRAG">
<meta property="og:url" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91xrag/index.html">
<meta property="og:site_name" content="文心晋意">
<meta property="og:description" content=".weplofdmtera{}   模型结构：   参考项目：Hannibal046&#x2F;xRAG 1 安装1.1 虚拟环境12345conda create -n xrag python&#x3D;3.9pip install torch&#x3D;&#x3D;2.1.1 transformers&#x3D;&#x3D;4.38.0 accelerate&#x3D;&#x3D;0.27.2 datasets&#x3D;&#x3D;2.17.1 deepspeed&#x3D;&#x3D;0">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91xrag/1.png">
<meta property="og:image" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91xrag/2.jpg">
<meta property="og:image" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91xrag/3.jpg">
<meta property="article:published_time" content="2025-04-26T04:00:00.000Z">
<meta property="article:modified_time" content="2025-04-26T10:59:17.398Z">
<meta property="article:author" content="文晋">
<meta property="article:tag" content="RAG">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://xuan-van.github.io/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91xrag/1.png">
  
  
  
  <title>【论文复现】xRAG - 文心晋意</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/background/background.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"xuan-van.github.io","root":"/","version":"1.9.8","typing":{"enable":false,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":3},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body><!-- hexo injector body_begin start --><div id="web_bg"></div><!-- hexo injector body_begin end -->
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>文晋的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-image"></i>
                <span>图片</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/images/llama.svg" target="_self">
                    
                    <span>Llama 结构</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">【论文复现】xRAG</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-04-26 12:00" pubdate>
          2025年4月26日 中午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          2.9k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          25 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar category-bar" style="margin-right: -1rem">
    





<div class="category-list">
  
  
    
    
    
    <div class="category row nomargin-x">
      <a class="category-item 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="代码复现"
        id="heading-211acd8e7f189296b7caddd5c95b71af" role="tab" data-toggle="collapse" href="#collapse-211acd8e7f189296b7caddd5c95b71af"
        aria-expanded="true"
      >
        代码复现
        <span class="list-group-count">(7)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-211acd8e7f189296b7caddd5c95b71af"
           role="tabpanel" aria-labelledby="heading-211acd8e7f189296b7caddd5c95b71af">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E4%BB%A3%E7%A0%81%E6%8B%86%E8%A7%A3%E3%80%91trajectory-transformer/" title="【代码拆解】Trajectory Transformer"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【代码拆解】Trajectory Transformer</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87%E3%80%91%E5%B8%B8%E7%94%A8%E9%97%AE%E7%AD%94%E6%95%B0%E6%8D%AE%E9%9B%86/" title="【数据准备】常用问答数据集"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【数据准备】常用问答数据集</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0%E3%80%91%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0-llama3/" title="【模型复现】从零实现 Llama3"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【模型复现】从零实现 Llama3</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91hipporag-hipporag2/" title="【论文复现】HippoRAG &amp; HippoRAG2"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【论文复现】HippoRAG &amp; HippoRAG2</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91instructrag/" title="【论文复现】InstructRAG"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【论文复现】InstructRAG</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91selfrag/" title="【论文复现】SelfRAG"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">【论文复现】SelfRAG</span>
        </a>
      
    
      
      
        <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91xrag/" title="【论文复现】xRAG"
           class="list-group-item list-group-item-action
           active">
          <span class="category-post">【论文复现】xRAG</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
</div>


  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">【论文复现】xRAG</h1>
            
            
              <div class="markdown-body">
                
                <figure style="text-align: center;">
    <style>.weplofdmtera{}</style><img src="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91xrag/1.png" srcset="/img/loading.gif" lazyload class="weplofdmtera">
</figure>

<p>模型结构：</p>
<img src="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91xrag/2.jpg" srcset="/img/loading.gif" lazyload class="">

<p>参考项目：<a target="_blank" rel="noopener" href="https://github.com/Hannibal046/xRAG">Hannibal046&#x2F;xRAG</a></p>
<h1 id="1-安装"><a href="#1-安装" class="headerlink" title="1 安装"></a>1 安装</h1><h2 id="1-1-虚拟环境"><a href="#1-1-虚拟环境" class="headerlink" title="1.1 虚拟环境"></a>1.1 虚拟环境</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda create -n xrag python=3.9<br>pip install torch==2.1.1 transformers==4.38.0 accelerate==0.27.2 datasets==2.17.1 deepspeed==0.13.2 sentencepiece wandb <span class="hljs-string">&quot;numpy&lt;2&quot;</span> ipykernel<br>python -m ipykernel install --user --name xrag<br>jupyter kernelspec list<br>pip install flash-attn==2.3.4 --no-build-isolation<br></code></pre></td></tr></table></figure>

<h2 id="1-2-模型"><a href="#1-2-模型" class="headerlink" title="1.2 模型"></a>1.2 模型</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">huggingface-cli download --resume-download Hannibal046/xrag-7b --local-dir model/xrag-7b<br>huggingface-cli download --resume-download Salesforce/SFR-Embedding-Mistral --local-dir model/SFR-Embedding-Mistral<br></code></pre></td></tr></table></figure>

<h2 id="1-3-数据集"><a href="#1-3-数据集" class="headerlink" title="1.3 数据集"></a>1.3 数据集</h2><p><a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/1lFFTklW_0HuR53hLpFdLClgfSAhXn_2f">google drive</a> 可以下载部分数据集，每个数据集都有 <code>train.jsonl</code>、<code>dev.jsonl</code>、<code>test.jsonl</code> 三个子集，数据格式如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;answer&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>str<span class="hljs-punctuation">,</span> ...<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> # fever 数据集的 test.jsonl 的这一字段为空<br>    <span class="hljs-attr">&quot;entity&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # 只有 tqa 数据集有这一字段<br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>

<h2 id="1-4-语料库"><a href="#1-4-语料库" class="headerlink" title="1.4 语料库"></a>1.4 语料库</h2><p><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/atlas?tab=readme-ov-file#corpora">corpora&#x2F;wiki&#x2F;enwiki-dec2021</a>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">https://dl.fbaipublicfiles.com/atlas/corpora/wiki/enwiki-dec2021/text-list-100-sec.jsonl<br>https://dl.fbaipublicfiles.com/atlas/corpora/wiki/enwiki-dec2021/infobox.jsonl<br></code></pre></td></tr></table></figure>

<p><code>infobox.jsonl: 4330888</code> 包含了维基百科页面中的信息框数据，数据格式如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> str<br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>

<p><code>text-list-100-sec.jsonl: 33176581</code> 包含了从维基百科中提取的文本段落，数据格式如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;section&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> str<br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>

<h1 id="2-Projector-的训练过程"><a href="#2-Projector-的训练过程" class="headerlink" title="2 Projector 的训练过程"></a>2 Projector 的训练过程</h1><img src="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E3%80%91xrag/3.jpg" srcset="/img/loading.gif" lazyload class="">

<h2 id="2-1-释义预训练"><a href="#2-1-释义预训练" class="headerlink" title="2.1 释义预训练"></a>2.1 释义预训练</h2><p>这一过程是为了让模型学会理解文档块和对应的嵌入之间的关系，训练数据格式如下：  </p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> str<br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>

<h2 id="2-2-上下文感知指令微调"><a href="#2-2-上下文感知指令微调" class="headerlink" title="2.2 上下文感知指令微调"></a>2.2 上下文感知指令微调</h2><p>类似知识蒸馏的方法，通过学习用检索到的上下文和问题来生成概率分布，让模型学会用对应的嵌入和相关指令来生成相似的概率分布。训练数据的的预处理过程可以参考 <code>prepare_data.ipynb</code>，得到的数据格式如下：  </p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;message&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;user&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> str<br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;assistant&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> str<br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;task_type&quot;</span><span class="hljs-punctuation">:</span> str<span class="hljs-punctuation">,</span> # open_qa（无 background）<span class="hljs-punctuation">,</span> close_qa<span class="hljs-punctuation">,</span> summarization<span class="hljs-punctuation">,</span> fact_checking（无 background）<br>    <span class="hljs-attr">&quot;background&quot;</span><span class="hljs-punctuation">:</span> str # 部分没有这一字段<br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>

<p>不同的任务类型有不同的提示词模板，生成数据时会随机选择，如下：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python">templates_for_qa = [<br>    <span class="hljs-string">&quot;Question: &#123;question&#125;?\nAnswer:&quot;</span>,<br>    <span class="hljs-string">&quot;&#123;question&#125;?&quot;</span>,<br>    <span class="hljs-string">&quot;Answer the following question:\n\n&#123;question&#125;&quot;</span>,<br>    <span class="hljs-string">&quot;Answer this question:\n\n&#123;question&#125;?&quot;</span>,<br>    <span class="hljs-string">&quot;Please answer this question: &#123;question&#125;&quot;</span>,<br>    <span class="hljs-string">&quot;Answer the question...&#123;question&#125;?&quot;</span>,<br>    <span class="hljs-string">&quot;What is the answer to this question? &#123;question&#125;\n\n&quot;</span>,<br>    <span class="hljs-string">&quot;Can you tell me the answer to &#123;question&#125;?&quot;</span>,<br>    <span class="hljs-string">&quot;Next question: &#123;question&#125;\n\n&quot;</span>,<br>    <span class="hljs-string">&quot;Q: &#123;question&#125; A:&quot;</span>,<br>    <span class="hljs-string">&quot;&#123;question&#125;\nWhat is the answer?&quot;</span>,<br>    <span class="hljs-string">&quot;Write the answer: &#123;question&#125;&quot;</span>,<br>    <span class="hljs-string">&quot;&#123;question&#125;???&quot;</span>,<br>]<br><br>templates_for_sum = [<br>    <span class="hljs-string">&quot;Write a short summary for the text\n\nSummary:&quot;</span>,<br>    <span class="hljs-string">&quot;Briefly summarize this article:\nSummary:&quot;</span>, <br>    <span class="hljs-string">&quot;What is a shorter version of this:\n\nSummary:&quot;</span>,<br>    <span class="hljs-string">&quot;Write a brief summary in a sentence or less.&quot;</span>, <br>    <span class="hljs-string">&quot;What is a very short summary of the above text?&quot;</span>,<br>    <span class="hljs-string">&quot;Summarize the aforementioned text in a single phrase.&quot;</span>,<br>    <span class="hljs-string">&quot;Can you generate a short summary of the above paragraph?&quot;</span>,<br>    <span class="hljs-string">&quot;Summarize the above articles\n\ntl;dr:&quot;</span>,<br>]<br><br>template_for_fact_checking = [<br>    <span class="hljs-string">&quot;Verify the following claims with \&quot;True\&quot; or \&quot;False\&quot;:\n&#123;question&#125;&quot;</span>,<br>]<br></code></pre></td></tr></table></figure>

<h1 id="3-示例"><a href="#3-示例" class="headerlink" title="3 示例"></a>3 示例</h1><h2 id="3-1-准备工作"><a href="#3-1-准备工作" class="headerlink" title="3.1 准备工作"></a>3.1 准备工作</h2><ol>
<li>导入必要的包：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> re<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> Tensor<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, MistralForCausalLM, MistralModel<br></code></pre></td></tr></table></figure>

<ol start="2">
<li>加载 <code>src/model/SFR/modeling_sfr.py</code> 的功能：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">last_token_pool</span>(<span class="hljs-params">last_hidden_states: Tensor, attention_mask: Tensor</span>) -&gt; Tensor:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    池化函数：从最后一个隐藏状态中提取每个序列的最后一个有效token的表示。</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    参数:</span><br><span class="hljs-string">        last_hidden_states (Tensor): 模型的最后一个隐藏层输出，形状为[batch_size, sequence_length, hidden_size]</span><br><span class="hljs-string">        attention_mask (Tensor): 注意力掩码，形状为[batch_size, sequence_length]</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    返回:</span><br><span class="hljs-string">        Tensor: 池化后的嵌入向量，形状为[batch_size, hidden_size]</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 检查是否是左填充</span><br>    left_padding = (attention_mask[:, -<span class="hljs-number">1</span>].<span class="hljs-built_in">sum</span>() == attention_mask.shape[<span class="hljs-number">0</span>]) <span class="hljs-comment"># 每个序列的最后一个位置的注意力掩码值都为1，表明最后一个位置是有效内容，而不是填充符号</span><br>    <span class="hljs-keyword">if</span> left_padding:<br>        <span class="hljs-comment"># 如果是左填充，直接取最后一个token</span><br>        <span class="hljs-keyword">return</span> last_hidden_states[:, -<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># 否则计算每个序列的实际长度，并取最后一个有效token</span><br>        sequence_lengths = attention_mask.<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">1</span>) - <span class="hljs-number">1</span><br>        batch_size = last_hidden_states.shape[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">return</span> last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]<br>    <br><br><span class="hljs-comment"># 基于MistralModel的SFR嵌入模型类，用于生成文档和查询的嵌入表示</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SFR</span>(<span class="hljs-title class_ inherited__">MistralModel</span>):<br>    <span class="hljs-comment"># 返回嵌入向量的维度（隐藏层大小）</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_embed_dim</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.config.hidden_size<br>    <br>    <span class="hljs-comment"># 返回嵌入向量的长度（固定为1）</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_embed_length</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <br>    <span class="hljs-comment"># 生成嵌入向量</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_embedding</span>(<span class="hljs-params">self, input_ids, attention_mask</span>):<br>        <span class="hljs-comment"># 前向传播获取模型输出</span><br>        outputs = <span class="hljs-variable language_">self</span>.forward(input_ids=input_ids, attention_mask=attention_mask)<br>        <span class="hljs-comment"># 使用last_token_pool池化最后一个隐藏状态</span><br>        embeddings = last_token_pool(outputs.last_hidden_state, attention_mask)<br>        <span class="hljs-keyword">return</span> embeddings<br>    <br>    <span class="hljs-comment"># 生成文档嵌入向量</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_doc_embedding</span>(<span class="hljs-params">self, input_ids, attention_mask</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.get_embedding(input_ids, attention_mask)<br>    <br>    <span class="hljs-comment"># 生成查询嵌入向量</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_query_embedding</span>(<span class="hljs-params">self, input_ids, attention_mask</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.get_embedding(input_ids, attention_mask)<br></code></pre></td></tr></table></figure>

<ol start="3">
<li>加载 <code>src/model/xMistral/modeling_xmistral.py</code> 的功能：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 投影器</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Projector</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        projector_type = config.projector_type  <span class="hljs-comment"># 获取配置中的投影器类型</span><br>        mlp_gelu_match = re.<span class="hljs-keyword">match</span>(<span class="hljs-string">r&#x27;^mlp(\d+)x_gelu$&#x27;</span>, projector_type)  <span class="hljs-comment"># 使用正则表达式匹配投影器类型</span><br>        <span class="hljs-keyword">if</span> mlp_gelu_match:  <span class="hljs-comment"># 如果匹配成功</span><br>            mlp_depth = <span class="hljs-built_in">int</span>(mlp_gelu_match.group(<span class="hljs-number">1</span>))  <span class="hljs-comment"># 获取MLP的深度</span><br>            modules = [nn.Linear(config.retriever_hidden_size, config.hidden_size)]  <span class="hljs-comment"># 创建第一个线性层</span><br>            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, mlp_depth):  <span class="hljs-comment"># 根据深度添加更多层</span><br>                modules.append(nn.GELU())  <span class="hljs-comment"># 添加GELU激活函数</span><br>                modules.append(nn.Linear(config.hidden_size, config.hidden_size))  <span class="hljs-comment"># 添加线性层</span><br>            <span class="hljs-variable language_">self</span>.projector = nn.Sequential(*modules)  <span class="hljs-comment"># 将模块序列化为投影器</span><br>    <br>    <span class="hljs-comment"># 前向传播：将上下文嵌入通过投影器</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,context_embedding</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>.projector(context_embedding)<br><br>    <br><span class="hljs-comment"># 基于MistralForCausalLM的推理模型</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">XMistralForCausalLM</span>(<span class="hljs-title class_ inherited__">MistralForCausalLM</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config</span>):<br>        <span class="hljs-built_in">super</span>().__init__(config)  <span class="hljs-comment"># 调用父类MistralForCausalLM的初始化方法</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(config,<span class="hljs-string">&quot;retriever_hidden_size&quot;</span>) <span class="hljs-keyword">and</span> config.retriever_hidden_size &gt; <span class="hljs-number">0</span>:  <span class="hljs-comment"># 如果配置中有retriever_hidden_size且大于0</span><br>            <span class="hljs-variable language_">self</span>.projector = Projector(config)  <span class="hljs-comment"># 初始化投影器</span><br>            <span class="hljs-variable language_">self</span>.retriever_hidden_size = config.retriever_hidden_size  <span class="hljs-comment"># 设置检索器隐藏层大小</span><br>        <span class="hljs-variable language_">self</span>.post_init()  <span class="hljs-comment"># 调用父类的后初始化方法</span><br>    <br>    <span class="hljs-comment"># 设置xrag token的ID</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">set_xrag_token_id</span>(<span class="hljs-params">self, token_id</span>):<br>        <span class="hljs-variable language_">self</span>.xrag_token_id = token_id  <br><br>    <span class="hljs-comment"># 准备输入嵌入</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_inputs_embeds</span>(<span class="hljs-params">self, input_ids, retrieval_embeds</span>):<br>        inputs_embeds = <span class="hljs-variable language_">self</span>.model.embed_tokens(input_ids)  <span class="hljs-comment"># 将输入ID转换为嵌入</span><br>        retrieval_embeds = retrieval_embeds.view(-<span class="hljs-number">1</span>, <span class="hljs-variable language_">self</span>.retriever_hidden_size)  <span class="hljs-comment"># 重塑检索嵌入的形状</span><br><br>        <span class="hljs-comment">## 完整性检查</span><br>        num_xrag_tokens = torch.<span class="hljs-built_in">sum</span>(input_ids == <span class="hljs-variable language_">self</span>.xrag_token_id).item()  <span class="hljs-comment"># 计算xrag token的数量</span><br>        num_retrieval_embeds = retrieval_embeds.shape[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 获取检索嵌入的数量</span><br>        <span class="hljs-keyword">assert</span> num_xrag_tokens == num_retrieval_embeds, (num_xrag_tokens, num_retrieval_embeds)  <span class="hljs-comment"># 确保两者数量一致</span><br><br>        retrieval_embeds = <span class="hljs-variable language_">self</span>.projector(retrieval_embeds.to(inputs_embeds.dtype))  <span class="hljs-comment"># 将检索嵌入通过投影器</span><br>        inputs_embeds[input_ids == <span class="hljs-variable language_">self</span>.xrag_token_id] = retrieval_embeds  <span class="hljs-comment"># 用投影后的检索嵌入替换xrag标记位置的嵌入</span><br>        <br>        <span class="hljs-keyword">return</span> inputs_embeds  <span class="hljs-comment"># 返回处理后的输入嵌入</span><br><br>    <span class="hljs-comment"># 前向传播</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        input_ids=<span class="hljs-literal">None</span>,         <span class="hljs-comment"># 输入的token IDs</span></span><br><span class="hljs-params">        retrieval_embeds=<span class="hljs-literal">None</span>,  <span class="hljs-comment"># 检索嵌入，形状为[-1, retrieval_hidden_size]</span></span><br><span class="hljs-params">        attention_mask=<span class="hljs-literal">None</span>,    <span class="hljs-comment"># 注意力掩码</span></span><br><span class="hljs-params">        **kwargs,                 <span class="hljs-comment"># 其他参数</span></span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-comment">## 当传入inputs_embeds（只有生成的第一轮会）时，表示模型正在生成</span><br>        inputs_embeds = kwargs.pop(<span class="hljs-string">&quot;inputs_embeds&quot;</span>, <span class="hljs-literal">None</span>)  <span class="hljs-comment"># 从kwargs中取出inputs_embeds</span><br>        at_the_beginning_of_generation = <span class="hljs-literal">False</span>  <span class="hljs-comment"># 标记是否处于生成开始阶段</span><br>        <span class="hljs-keyword">if</span> inputs_embeds <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:  <span class="hljs-comment"># 如果传入了inputs_embeds，则不允许传入 retrieval_embeds</span><br>            <span class="hljs-keyword">assert</span> <span class="hljs-keyword">not</span> <span class="hljs-variable language_">self</span>.training  <span class="hljs-comment"># 确保不在训练模式下</span><br>            <span class="hljs-keyword">assert</span> retrieval_embeds <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>  <span class="hljs-comment"># 确保没有传入retrieval_embeds</span><br>            at_the_beginning_of_generation = <span class="hljs-literal">True</span>  <span class="hljs-comment"># 标记为生成开始阶段</span><br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> at_the_beginning_of_generation:  <span class="hljs-comment"># 如果不是生成开始阶段</span><br>            <span class="hljs-comment">## 单次前向传播</span><br>            <span class="hljs-keyword">if</span> retrieval_embeds <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:  <span class="hljs-comment"># 如果传入了检索嵌入</span><br>                inputs_embeds = <span class="hljs-variable language_">self</span>.prepare_inputs_embeds(input_ids, retrieval_embeds)  <span class="hljs-comment"># 准备输入嵌入</span><br>                input_ids = <span class="hljs-literal">None</span>  <span class="hljs-comment"># 将input_ids设为None</span><br>                <span class="hljs-keyword">if</span> attention_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:  <span class="hljs-comment"># 如果有注意力掩码</span><br>                    <span class="hljs-keyword">assert</span> inputs_embeds.shape[<span class="hljs-number">1</span>] == attention_mask.shape[<span class="hljs-number">1</span>],(inputs_embeds.shape, attention_mask.shape)  <span class="hljs-comment"># 确保形状匹配</span><br><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">super</span>().forward(  <span class="hljs-comment"># 调用父类的forward方法</span><br>            input_ids=input_ids,<br>            inputs_embeds=inputs_embeds,<br>            attention_mask=attention_mask,<br>            **kwargs,<br>        )<br><br>    <span class="hljs-comment"># 生成</span><br><span class="hljs-meta">    @torch.no_grad()  </span><span class="hljs-comment"># 禁用梯度计算</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">generate</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        input_ids=<span class="hljs-literal">None</span>,         <span class="hljs-comment"># 输入的token IDs</span></span><br><span class="hljs-params">        retrieval_embeds=<span class="hljs-literal">None</span>,  <span class="hljs-comment"># 检索嵌入</span></span><br><span class="hljs-params">        **kwargs,                 <span class="hljs-comment"># 其他参数</span></span><br><span class="hljs-params">    </span>):<br>        attention_mask = kwargs.pop(<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-literal">None</span>)  <span class="hljs-comment"># 从kwargs中取出attention_mask</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;inputs_embeds&quot;</span> <span class="hljs-keyword">in</span> kwargs:  <span class="hljs-comment"># 如果kwargs中包含inputs_embeds</span><br>            <span class="hljs-keyword">raise</span> NotImplementedError(<span class="hljs-string">&quot;`inputs_embeds` is not supported for generate&quot;</span>)  <span class="hljs-comment"># 抛出未实现错误</span><br>        <br>        inputs_embeds=<span class="hljs-literal">None</span><br>        <span class="hljs-keyword">if</span> retrieval_embeds <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:  <span class="hljs-comment"># 如果传入了检索嵌入</span><br>            inputs_embeds = <span class="hljs-variable language_">self</span>.prepare_inputs_embeds(input_ids, retrieval_embeds)  <span class="hljs-comment"># 准备输入嵌入</span><br>            input_ids = <span class="hljs-literal">None</span>  <span class="hljs-comment"># 将input_ids设为None</span><br>            <span class="hljs-keyword">if</span> attention_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:  <span class="hljs-comment"># 如果有注意力掩码</span><br>                <span class="hljs-keyword">assert</span> inputs_embeds.shape[<span class="hljs-number">1</span>] == attention_mask.shape[<span class="hljs-number">1</span>], (inputs_embeds.shape, attention_mask.shape)  <span class="hljs-comment"># 确保形状匹配</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">super</span>().generate(  <span class="hljs-comment"># 调用父类的generate方法</span><br>                attention_mask=attention_mask,<br>                inputs_embeds=inputs_embeds,<br>                **kwargs<br>            )<br>        <br>        <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># 如果没有传入检索嵌入</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">super</span>().generate(  <span class="hljs-comment"># 调用父类的generate方法</span><br>                attention_mask=attention_mask,<br>                input_ids=input_ids,<br>                **kwargs<br>            )<br></code></pre></td></tr></table></figure>

<ol start="4">
<li>加载 <code>src/language_modeling/utils.py</code> 的功能：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">XRAG_TOKEN = <span class="hljs-string">&quot;&lt;xRAG&gt;&quot;</span><br><br><span class="hljs-comment"># 提取检索文本的嵌入</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_retrieval_embeds</span>(<span class="hljs-params">model, input_ids, attention_mask=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-keyword">with</span> torch.no_grad(): <span class="hljs-comment"># 推理阶段禁用梯度计算</span><br>        embeds = model.get_doc_embedding( <span class="hljs-comment"># 调用模型的get_doc_embedding方法</span><br>            input_ids=input_ids,<br>            attention_mask=attention_mask,<br>        )<br>    embeds = embeds.view(-<span class="hljs-number">1</span>, embeds.shape[-<span class="hljs-number">1</span>]) <span class="hljs-comment"># 重塑嵌入的形状</span><br>    <span class="hljs-keyword">return</span> embeds<br></code></pre></td></tr></table></figure>

<ol start="5">
<li>加载模型和分词器：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span>)<br>llm_name_or_path = <span class="hljs-string">&quot;../model/xrag-7b&quot;</span><br>llm = XMistralForCausalLM.from_pretrained(llm_name_or_path, torch_dtype=torch.bfloat16, low_cpu_mem_usage=<span class="hljs-literal">True</span>,).to(device).<span class="hljs-built_in">eval</span>() <span class="hljs-comment"># 启用低CPU内存占用模式</span><br>llm_tokenizer = AutoTokenizer.from_pretrained(llm_name_or_path, add_eos_token=<span class="hljs-literal">False</span>, use_fast=<span class="hljs-literal">False</span>, padding_side=<span class="hljs-string">&#x27;left&#x27;</span>) <span class="hljs-comment"># 不自动在文本末尾添加结束符，禁用快速分词器，左填充策略</span><br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">Loading checkpoint shards: 100%|██████████| 3/3 [00:00&lt;00:00,  5.52it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
</code></pre>
<ol start="6">
<li>此时，<code>XRAG_TOKEN</code> 只是一个占位符：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">llm.set_xrag_token_id(llm_tokenizer.convert_tokens_to_ids(XRAG_TOKEN)) <span class="hljs-comment"># 调用模型的set_xrag_token_id方法，设置一个特殊的token ID；</span><br><span class="hljs-built_in">print</span>(XRAG_TOKEN)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">&lt;xRAG&gt;
</code></pre>
<h2 id="3-2-无-RAG"><a href="#3-2-无-RAG" class="headerlink" title="3.2 无 RAG"></a>3.2 无 RAG</h2><ol>
<li>根据问题构建 prompt：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">question = <span class="hljs-string">&quot;&quot;&quot;What company advertised itself with the slogan &quot;We&#x27;ll leave a light on for you&quot;?&quot;&quot;&quot;</span> <span class="hljs-comment"># 哪家公司用“我们会为您留下一盏灯”的口号来宣传自己（答案是“Motel 6”）</span><br>template = <span class="hljs-string">&quot;[INST] Answer the questions:\n\nQuestion: &#123;question&#125; [/INST] The answer is:&quot;</span><br>prompt = template.format_map(<span class="hljs-built_in">dict</span>(question=question)) <span class="hljs-comment"># format_map将问题插入到模板</span><br><span class="hljs-built_in">print</span>(prompt)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[INST] Answer the questions:

Question: What company advertised itself with the slogan &quot;We&#39;ll leave a light on for you&quot;? [/INST] The answer is:
</code></pre>
<ol start="2">
<li>进行推理（不同的精度会得到不同的答案）：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">input_ids = llm_tokenizer(prompt, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).input_ids.to(device) <span class="hljs-comment"># return_tensors=&#x27;pt&#x27;：指定返回的张量类型为PyTorch张量</span><br>generated_output = llm.generate(<br>        input_ids=input_ids,<br>        do_sample=<span class="hljs-literal">False</span>,    <span class="hljs-comment"># 禁用采样，使用贪心解码</span><br>        max_new_tokens=<span class="hljs-number">20</span>,  <span class="hljs-comment"># 指定生成的最大新Token数量</span><br>        pad_token_id=llm_tokenizer.pad_token_id, <span class="hljs-comment"># 指定填充Token的ID</span><br>    )<br>result = llm_tokenizer.batch_decode(generated_output[:, input_ids.shape[<span class="hljs-number">1</span>]:], skip_special_tokens=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>] <span class="hljs-comment"># 提取生成的新增部分</span><br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">Holiday Inn. Holiday Inn is a global hotel chain that has used the slogan &quot;We
</code></pre>
<ol start="3">
<li>测量运行时间：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">%%time<br>batch_size = <span class="hljs-number">24</span><br>num_batch = <span class="hljs-number">50</span><br>input_ids = input_ids.repeat(batch_size, <span class="hljs-number">1</span>) <span class="hljs-comment"># 每个输入在批次中重复batch_size次</span><br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_batch): <span class="hljs-comment"># 批量生成文本</span><br>    generated_output = llm.generate(<br>            input_ids=input_ids,<br>            do_sample=<span class="hljs-literal">False</span>,<br>            max_new_tokens=<span class="hljs-number">20</span>,<br>            pad_token_id=llm_tokenizer.pad_token_id,<br>        )<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">CPU times: user 28.6 s, sys: 1.37 s, total: 29.9 s
Wall time: 30 s
</code></pre>
<h2 id="3-3-传统-RAG"><a href="#3-3-传统-RAG" class="headerlink" title="3.3 传统 RAG"></a>3.3 传统 RAG</h2><ol>
<li>模拟数据库：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">documents = [<br>    <span class="hljs-string">&#x27;Alvin and the Chipmunks | &quot; Alvin and the Chipmunks, originally David Seville and the Chipmunks or simply The Chipmunks, are an American animated virtual band created by Ross Bagdasarian for a novelty record in 1958. The group consists of three singing animated anthropomorphic chipmunks named Alvin, Simon, and Theodore. They are managed by their human adoptive father, David &quot;&quot;Dave&quot;&quot; Seville. Bagdasarian provided the group\&#x27;s voices sped up to create high-pitched squeaky voices (which wasn\&#x27;t entirely new to him, having worked on &quot;&quot;Witch Doctor&quot;&quot; earned the record two Grammy Awards for engineering). &quot;&quot;The Chipmunk Song&quot;&quot; became a number-one single in the United States. After Bagdasarian died in 1972, the characters’ voices were provided by his son Ross Bagdasarian Jr. and the latter\&#x27;s wife Janice Karman in the subsequent incarnations of &quot;&#x27;</span>,<br>    <span class="hljs-string">&quot;Jamie Lee Curtis |  Jamie Lee Curtis (born November 22, 1958) is an American actress and writer. She is the recipient of several accolades, including a British Academy Film Award, two Golden Globe Awards and a star on the Hollywood Walk of Fame in 1998. Curtis made her film acting debut as Laurie Strode in John Carpenter&#x27;s horror film Halloween (1978), which established her as a scream queen, and she thereafter appeared in a string of horror films, including The Fog, Prom Night, Terror Train (all 1980) and Roadgames (1981). She reprised the role of Laurie in the sequels Halloween II (1981), Halloween H20: 20 Years Later (1998), Halloween: Resurrection (2002), Halloween (2018), and Halloween Kills (2021). Her filmography is largely characterized by independent film that have been box-office successes, with 8 of her lead-actress credits &quot;</span>,<br>    <span class="hljs-string">&#x27;Sunset Boulevard (musical) | &quot; The American premiere was at the Shubert Theatre in Century City, Los Angeles, California, on 9 December 1993, with Close as Norma and Alan Campbell as Joe. Featured were George Hearn as Max and Judy Kuhn as Betty. Lloyd Webber had reworked both the book and score, tightening the production, better organising the orchestrations, and adding the song &quot;&quot;Every Movie\&#x27;s a Circus&quot;&quot;. This new production was better received by the critics and was an instant success, running for 369 performances. The Los Angeles production also recorded a new cast album that is well regarded. It is also the only unabridged cast recording of the show, since the original London recording was trimmed by over thirty minutes. A controversy arose with this production after Faye Dunaway was hired to replace Glenn Close. Dunaway went into rehearsals with Rex Smith as Joe and Jon Cypher as Max. Tickets &quot;&#x27;</span>,<br>    <span class="hljs-string">&#x27;Arthur Balfour |  Balfour was appointed prime minister on 12 July 1902 while the King was recovering from his recent appendicitis operation. Changes to the Cabinet were thus not announced until 9 August, when the King was back in London. The new ministers were received in audience and took their oaths on 11 August.&#x27;</span>,<br>    <span class="hljs-string">&#x27;Motel 6 | &quot; Beginning in 1986, Motel 6 has advertised through radio commercials featuring the voice of writer and National Public Radio commentator Tom Bodett, with the tagline &quot;We\&#x27;ll leave the light on for you.&quot; The ads were created by Dallas advertising agency The Richards Group. They feature a tune composed by Tom Faulkner, performed by him on guitar and Milo Deering on fiddle. The first spots were conceived and written by David Fowler. In 1996, the ads won a Clio Award. The campaign itself has won numerous national and international awards and was selected by Advertising Age magazine as one of the Top 100 Advertising Campaigns of the Twentieth Century.&quot;&#x27;</span>,<br>]<br></code></pre></td></tr></table></figure>

<ol start="2">
<li>加载检索模型：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">retriever_name_or_path = <span class="hljs-string">&quot;../model/SFR-Embedding-Mistral&quot;</span><br>retriever = SFR.from_pretrained(retriever_name_or_path, torch_dtype=torch.bfloat16).<span class="hljs-built_in">eval</span>().to(device)<br>retriever_tokenizer = AutoTokenizer.from_pretrained(retriever_name_or_path)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">Loading checkpoint shards: 100%|██████████| 3/3 [00:23&lt;00:00,  7.69s/it]
</code></pre>
<ol start="3">
<li>计算每个文档的嵌入：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">retriever_input = retriever_tokenizer(documents, max_length=<span class="hljs-number">180</span>, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).to(device) <span class="hljs-comment"># padding：对不足max_length的文档进行填充；truncation：对超过max_length的文档进行截断</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    doc_embeds = retriever.get_doc_embedding(input_ids=retriever_input.input_ids, attention_mask=retriever_input.attention_mask)<br>doc_embeds.shape<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">torch.Size([5, 4096])
</code></pre>
<ol start="4">
<li>建立索引：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">datastore = (documents, doc_embeds)<br></code></pre></td></tr></table></figure>

<ol start="5">
<li>计算问题的嵌入：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">retriever_input = retriever_tokenizer(question, max_length=<span class="hljs-number">180</span>, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).to(device)<br><span class="hljs-keyword">with</span> torch.no_grad():<br>    query_embed = retriever.get_query_embedding(input_ids=retriever_input.input_ids, attention_mask=retriever_input.attention_mask)<br>query_embed.shape<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">torch.Size([1, 4096])
</code></pre>
<ol start="6">
<li>获取相似度最高的文档索引：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">_, index = torch.topk(torch.matmul(query_embed, doc_embeds.T), k=<span class="hljs-number">1</span>) <span class="hljs-comment"># 向量点积</span><br>top1_doc_index = index[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].item()<br>top1_doc_index<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">4
</code></pre>
<ol start="7">
<li>根据索引获得对应的文档：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">relevant_doc = datastore[<span class="hljs-number">0</span>][top1_doc_index]<br><span class="hljs-built_in">print</span>(relevant_doc)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">Motel 6 | &quot; Beginning in 1986, Motel 6 has advertised through radio commercials featuring the voice of writer and National Public Radio commentator Tom Bodett, with the tagline &quot;We&#39;ll leave the light on for you.&quot; The ads were created by Dallas advertising agency The Richards Group. They feature a tune composed by Tom Faulkner, performed by him on guitar and Milo Deering on fiddle. The first spots were conceived and written by David Fowler. In 1996, the ads won a Clio Award. The campaign itself has won numerous national and international awards and was selected by Advertising Age magazine as one of the Top 100 Advertising Campaigns of the Twentieth Century.&quot;
</code></pre>
<ol start="8">
<li>根据问题和检索到的文档构建新的 prompt：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">rag_template = <span class="hljs-string">&quot;&quot;&quot;[INST] Refer to the background document and answer the questions:</span><br><span class="hljs-string"></span><br><span class="hljs-string">Background: &#123;document&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">Question: &#123;question&#125; [/INST] The answer is:&quot;&quot;&quot;</span><br>prompt = rag_template.format_map(<span class="hljs-built_in">dict</span>(document=relevant_doc, question=question))<br><span class="hljs-built_in">print</span>(prompt)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[INST] Refer to the background document and answer the questions:

Background: Motel 6 | &quot; Beginning in 1986, Motel 6 has advertised through radio commercials featuring the voice of writer and National Public Radio commentator Tom Bodett, with the tagline &quot;We&#39;ll leave the light on for you.&quot; The ads were created by Dallas advertising agency The Richards Group. They feature a tune composed by Tom Faulkner, performed by him on guitar and Milo Deering on fiddle. The first spots were conceived and written by David Fowler. In 1996, the ads won a Clio Award. The campaign itself has won numerous national and international awards and was selected by Advertising Age magazine as one of the Top 100 Advertising Campaigns of the Twentieth Century.&quot;

Question: What company advertised itself with the slogan &quot;We&#39;ll leave a light on for you&quot;? [/INST] The answer is:
</code></pre>
<ol start="9">
<li>进行推理：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">input_ids = llm_tokenizer(prompt, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).input_ids.to(device)<br>generated_output = llm.generate(<br>        input_ids=input_ids,<br>        do_sample=<span class="hljs-literal">False</span>,<br>        max_new_tokens=<span class="hljs-number">20</span>,<br>        pad_token_id=llm_tokenizer.pad_token_id,<br>    )<br>result = llm_tokenizer.batch_decode(generated_output[:, input_ids.shape[<span class="hljs-number">1</span>]:], skip_special_tokens=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]<br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">Motel 6

Explanation: Motel 6 is the company that advertised
</code></pre>
<ol start="10">
<li>测量运行时间：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">%%time<br>batch_size = <span class="hljs-number">24</span><br>num_batch = <span class="hljs-number">50</span><br>input_ids = input_ids.repeat(batch_size, <span class="hljs-number">1</span>)<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_batch):<br>    generated_output = llm.generate(<br>            input_ids=input_ids,<br>            do_sample=<span class="hljs-literal">False</span>,<br>            max_new_tokens=<span class="hljs-number">20</span>,<br>            pad_token_id=llm_tokenizer.pad_token_id,<br>        )<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">CPU times: user 42.3 s, sys: 9.36 s, total: 51.7 s
Wall time: 51.7 s
</code></pre>
<ol start="11">
<li>查看问题和文档的长度：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">question_len = llm_tokenizer(question, return_length=<span class="hljs-literal">True</span>, add_special_tokens=<span class="hljs-literal">False</span>).length<br>doc_len = llm_tokenizer(relevant_doc, return_length=<span class="hljs-literal">True</span>, add_special_tokens=<span class="hljs-literal">False</span>).length<br>question_len, doc_len<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">(20, 163)
</code></pre>
<h2 id="3-4-xRAG"><a href="#3-4-xRAG" class="headerlink" title="3.4 xRAG"></a>3.4 xRAG</h2><ol>
<li>根据索引获得对应的嵌入，并进行推理：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">relevant_embedding = datastore[<span class="hljs-number">1</span>][top1_doc_index]<br><br>prompt = rag_template.format_map(<span class="hljs-built_in">dict</span>(question=question, document=XRAG_TOKEN)) <span class="hljs-comment"># 检索文档换成了一个 token</span><br><span class="hljs-built_in">print</span>(prompt)<br>input_ids = llm_tokenizer(prompt,return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).input_ids.to(device)<br>generated_output = llm.generate(<br>        input_ids=input_ids,<br>        do_sample=<span class="hljs-literal">False</span>,<br>        max_new_tokens=<span class="hljs-number">20</span>,<br>        pad_token_id=llm_tokenizer.pad_token_id,<br>        retrieval_embeds = relevant_embedding.unsqueeze(<span class="hljs-number">0</span>),<br>    )<br>result = llm_tokenizer.batch_decode(generated_output, skip_special_tokens=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]<br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">[INST] Refer to the background document and answer the questions:

Background: &lt;xRAG&gt;

Question: What company advertised itself with the slogan &quot;We&#39;ll leave a light on for you&quot;? [/INST] The answer is:
Motel 6. The slogan was created in 1962 by Tom Bodett
</code></pre>
<ol start="2">
<li>测量运行时间：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">%%time<br>batch_size = <span class="hljs-number">24</span><br>num_batch = <span class="hljs-number">50</span><br>input_ids = input_ids.repeat(batch_size, <span class="hljs-number">1</span>)<br>retrieval_embeds = relevant_embedding.unsqueeze(<span class="hljs-number">0</span>).repeat(batch_size, <span class="hljs-number">1</span>)<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_batch):<br>    generated_output = llm.generate(<br>            input_ids=input_ids,<br>            do_sample=<span class="hljs-literal">False</span>,<br>            max_new_tokens=<span class="hljs-number">20</span>,<br>            pad_token_id=llm_tokenizer.pad_token_id,<br>            retrieval_embeds=retrieval_embeds,<br>        )<br></code></pre></td></tr></table></figure>
<br/>

<pre><code class="hljs">CPU times: user 30.5 s, sys: 2.07 s, total: 32.5 s
Wall time: 32.5 s
</code></pre>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/" class="category-chain-item">代码复现</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/RAG/" class="print-no-link">#RAG</a>
      
        <a href="/tags/LLM/" class="print-no-link">#LLM</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>【论文复现】xRAG</div>
      <div>http://xuan-van.github.io/代码复现/【论文复现】xrag/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>文晋</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年4月26日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="NC - 非商业性使用">
                    <i class="iconfont icon-cc-nc"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - 相同方式共享">
                    <i class="iconfont icon-cc-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/%E3%80%90%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87%E3%80%91%E5%B8%B8%E7%94%A8%E9%97%AE%E7%AD%94%E6%95%B0%E6%8D%AE%E9%9B%86/" title="【数据准备】常用问答数据集">
                        <span class="hidden-mobile">【数据准备】常用问答数据集</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  





  <script>
  Fluid.utils.createScript('https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js', function() {
    mermaid.initialize({"theme":"default"});

    Fluid.utils.listenDOMLoaded(function() {
      Fluid.events.registerRefreshCallback(function() {
        if ('mermaid' in window) {
          mermaid.init();
        }
      });
    });
  });
</script>






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>




  
<script src="/background/background.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<!-- hexo injector body_end start --><script src="/background/background.js"></script><!-- hexo injector body_end end --></body>
</html>
